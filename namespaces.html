<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>fortran-lapack: Modules List</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="doxygen-awesome.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">fortran-lapack
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('namespaces.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">Modules List</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock">Here is a list of all modules with brief descriptions:</div><div class="directory">
<div class="levels">[detail level <span onclick="javascript:toggleLevel(1);">1</span><span onclick="javascript:toggleLevel(2);">2</span>]</div><table class="directory">
<tr id="row_0_" class="even"><td class="entry"><span style="width:0px;display:inline-block;">&#160;</span><span id="arr_0_" class="arrow" onclick="toggleFolder('0_')">&#9658;</span><span class="icona"><span class="icon">M</span></span><a class="el" href="namespacela__blas.html" target="_self">la_blas</a></td><td class="desc"></td></tr>
<tr id="row_0_0_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1axpy.html" target="_self">axpy</a></td><td class="desc">AXPY: constant times a vector plus a vector </td></tr>
<tr id="row_0_1_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1copy.html" target="_self">copy</a></td><td class="desc">COPY: copies a vector x to a vector y </td></tr>
<tr id="row_0_2_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1dot.html" target="_self">dot</a></td><td class="desc">DOT: forms the dot product of two vectors. uses unrolled loops for increments equal to one </td></tr>
<tr id="row_0_3_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1dotc.html" target="_self">dotc</a></td><td class="desc">DOTC: forms the dot product of two complex vectors DOTC = X^H * Y </td></tr>
<tr id="row_0_4_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1dotu.html" target="_self">dotu</a></td><td class="desc">DOTU: forms the dot product of two complex vectors DOTU = X^T * Y </td></tr>
<tr id="row_0_5_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1gbmv.html" target="_self">gbmv</a></td><td class="desc">GBMV: performs one of the matrix-vector operations y := alpha*A*x + beta*y, or y := alpha*A**T*x + beta*y, or y := alpha*A**H*x + beta*y, where alpha and beta are scalars, x and y are vectors and A is an m by n band matrix, with kl sub-diagonals and ku super-diagonals </td></tr>
<tr id="row_0_6_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1gemm.html" target="_self">gemm</a></td><td class="desc">GEMM: performs one of the matrix-matrix operations C := alpha*op( A )*op( B ) + beta*C, where op( X ) is one of op( X ) = X or op( X ) = X**T or op( X ) = X**H, alpha and beta are scalars, and A, B and C are matrices, with op( A ) an m by k matrix, op( B ) a k by n matrix and C an m by n matrix </td></tr>
<tr id="row_0_7_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1gemv.html" target="_self">gemv</a></td><td class="desc">GEMV: performs one of the matrix-vector operations y := alpha*A*x + beta*y, or y := alpha*A**T*x + beta*y, or y := alpha*A**H*x + beta*y, where alpha and beta are scalars, x and y are vectors and A is an m by n matrix </td></tr>
<tr id="row_0_8_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1ger.html" target="_self">ger</a></td><td class="desc">GER: performs the rank 1 operation A := alpha*x*y**T + A, where alpha is a scalar, x is an m element vector, y is an n element vector and A is an m by n matrix </td></tr>
<tr id="row_0_9_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1gerc.html" target="_self">gerc</a></td><td class="desc">GERC: performs the rank 1 operation A := alpha*x*y**H + A, where alpha is a scalar, x is an m element vector, y is an n element vector and A is an m by n matrix </td></tr>
<tr id="row_0_10_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1geru.html" target="_self">geru</a></td><td class="desc">GERU: performs the rank 1 operation A := alpha*x*y**T + A, where alpha is a scalar, x is an m element vector, y is an n element vector and A is an m by n matrix </td></tr>
<tr id="row_0_11_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1hbmv.html" target="_self">hbmv</a></td><td class="desc">HBMV: performs the matrix-vector operation y := alpha*A*x + beta*y, where alpha and beta are scalars, x and y are n element vectors and A is an n by n hermitian band matrix, with k super-diagonals </td></tr>
<tr id="row_0_12_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1hemm.html" target="_self">hemm</a></td><td class="desc">HEMM: performs one of the matrix-matrix operations C := alpha*A*B + beta*C, or C := alpha*B*A + beta*C, where alpha and beta are scalars, A is an hermitian matrix and B and C are m by n matrices </td></tr>
<tr id="row_0_13_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1hemv.html" target="_self">hemv</a></td><td class="desc">HEMV: performs the matrix-vector operation y := alpha*A*x + beta*y, where alpha and beta are scalars, x and y are n element vectors and A is an n by n hermitian matrix </td></tr>
<tr id="row_0_14_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1her.html" target="_self">her</a></td><td class="desc">HER: performs the hermitian rank 1 operation A := alpha*x*x**H + A, where alpha is a real scalar, x is an n element vector and A is an n by n hermitian matrix </td></tr>
<tr id="row_0_15_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1her2.html" target="_self">her2</a></td><td class="desc">HER2: performs the hermitian rank 2 operation A := alpha*x*y**H + conjg( alpha )*y*x**H + A, where alpha is a scalar, x and y are n element vectors and A is an n by n hermitian matrix </td></tr>
<tr id="row_0_16_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1her2k.html" target="_self">her2k</a></td><td class="desc">HER2K: performs one of the hermitian rank 2k operations C := alpha*A*B**H + conjg( alpha )*B*A**H + beta*C, or C := alpha*A**H*B + conjg( alpha )*B**H*A + beta*C, where alpha and beta are scalars with beta real, C is an n by n hermitian matrix and A and B are n by k matrices in the first case and k by n matrices in the second case </td></tr>
<tr id="row_0_17_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1herk.html" target="_self">herk</a></td><td class="desc">HERK: performs one of the hermitian rank k operations C := alpha*A*A**H + beta*C, or C := alpha*A**H*A + beta*C, where alpha and beta are real scalars, C is an n by n hermitian matrix and A is an n by k matrix in the first case and a k by n matrix in the second case </td></tr>
<tr id="row_0_18_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1hpmv.html" target="_self">hpmv</a></td><td class="desc">HPMV: performs the matrix-vector operation y := alpha*A*x + beta*y, where alpha and beta are scalars, x and y are n element vectors and A is an n by n hermitian matrix, supplied in packed form </td></tr>
<tr id="row_0_19_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1hpr.html" target="_self">hpr</a></td><td class="desc">HPR: performs the hermitian rank 1 operation A := alpha*x*x**H + A, where alpha is a real scalar, x is an n element vector and A is an n by n hermitian matrix, supplied in packed form </td></tr>
<tr id="row_0_20_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1hpr2.html" target="_self">hpr2</a></td><td class="desc">HPR2: performs the hermitian rank 2 operation A := alpha*x*y**H + conjg( alpha )*y*x**H + A, where alpha is a scalar, x and y are n element vectors and A is an n by n hermitian matrix, supplied in packed form </td></tr>
<tr id="row_0_21_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1nrm2.html" target="_self">nrm2</a></td><td class="desc">! </td></tr>
<tr id="row_0_22_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1rot.html" target="_self">rot</a></td><td class="desc">ROT: applies a plane rotation </td></tr>
<tr id="row_0_23_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1rotg.html" target="_self">rotg</a></td><td class="desc">! </td></tr>
<tr id="row_0_24_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1rotm.html" target="_self">rotm</a></td><td class="desc">APPLY THE MODIFIED GIVENS TRANSFORMATION, H, TO THE 2 BY N MATRIX (DX**T) , WHERE **T INDICATES TRANSPOSE. THE ELEMENTS OF DX ARE IN (DY**T) DX(LX+I*INCX), I = 0 TO N-1, WHERE LX = 1 IF INCX &gt;= 0, ELSE LX = (-INCX)*N, AND SIMILARLY FOR SY USING LY AND INCY. WITH DPARAM(1)=DFLAG, H HAS ONE OF THE FOLLOWING FORMS.. DFLAG=-1._dp DFLAG=0._dp DFLAG=1._dp DFLAG=-2.D0 (DH11 DH12) (1._dp DH12) (DH11 1._dp) (1._dp 0._dp) H=( ) ( ) ( ) ( ) (DH21 DH22), (DH21 1._dp), (-1._dp DH22), (0._dp 1._dp). SEE ROTMG FOR A DESCRIPTION OF DATA STORAGE IN DPARAM </td></tr>
<tr id="row_0_25_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1rotmg.html" target="_self">rotmg</a></td><td class="desc">CONSTRUCT THE MODIFIED GIVENS TRANSFORMATION MATRIX H WHICH ZEROS THE SECOND COMPONENT OF THE 2-VECTOR (SQRT(DD1)*DX1,SQRT(DD2) DY2)**T. WITH DPARAM(1)=DFLAG, H HAS ONE OF THE FOLLOWING FORMS.. DFLAG=-1._dp DFLAG=0._dp DFLAG=1._dp DFLAG=-2.D0 (DH11 DH12) (1._dp DH12) (DH11 1._dp) (1._dp 0._dp) H=( ) ( ) ( ) ( ) (DH21 DH22), (DH21 1._dp), (-1._dp DH22), (0._dp 1._dp). LOCATIONS 2-4 OF DPARAM CONTAIN DH11, DH21, DH12, AND DH22 RESPECTIVELY. (VALUES OF 1._dp, -1._dp, OR 0._dp IMPLIED BY THE VALUE OF DPARAM(1) ARE NOT STORED IN DPARAM.) THE VALUES OF GAMSQ AND RGAMSQ SET IN THE DATA STATEMENT MAY BE INEXACT. THIS IS OK AS THEY ARE ONLY USED FOR TESTING THE SIZE OF DD1 AND DD2. ALL ACTUAL SCALING OF DATA IS DONE USING GAM </td></tr>
<tr id="row_0_26_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1sbmv.html" target="_self">sbmv</a></td><td class="desc">SBMV: performs the matrix-vector operation y := alpha*A*x + beta*y, where alpha and beta are scalars, x and y are n element vectors and A is an n by n symmetric band matrix, with k super-diagonals </td></tr>
<tr id="row_0_27_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1scal.html" target="_self">scal</a></td><td class="desc">SCAL: scales a vector by a constant </td></tr>
<tr id="row_0_28_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1sdot.html" target="_self">sdot</a></td><td class="desc">Compute the inner product of two vectors with extended precision accumulation and result. Returns D.P. dot product accumulated in D.P., for S.P. SX and SY SDOT: = sum for I = 0 to N-1 of SX(LX+I*INCX) * SY(LY+I*INCY), where LX = 1 if INCX &gt;= 0, else LX = 1+(1-N)*INCX, and LY is defined in a similar way using INCY </td></tr>
<tr id="row_0_29_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1spmv.html" target="_self">spmv</a></td><td class="desc">SPMV: performs the matrix-vector operation y := alpha*A*x + beta*y, where alpha and beta are scalars, x and y are n element vectors and A is an n by n symmetric matrix, supplied in packed form </td></tr>
<tr id="row_0_30_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1spr.html" target="_self">spr</a></td><td class="desc">SPR: performs the symmetric rank 1 operation A := alpha*x*x**T + A, where alpha is a real scalar, x is an n element vector and A is an n by n symmetric matrix, supplied in packed form </td></tr>
<tr id="row_0_31_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1spr2.html" target="_self">spr2</a></td><td class="desc">SPR2: performs the symmetric rank 2 operation A := alpha*x*y**T + alpha*y*x**T + A, where alpha is a scalar, x and y are n element vectors and A is an n by n symmetric matrix, supplied in packed form </td></tr>
<tr id="row_0_32_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1srot.html" target="_self">srot</a></td><td class="desc">SROT: applies a plane rotation, where the cos and sin (c and s) are real and the vectors cx and cy are complex. jack dongarra, linpack, 3/11/78 </td></tr>
<tr id="row_0_33_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1sscal.html" target="_self">sscal</a></td><td class="desc">SSCAL: scales a complex vector by a real constant </td></tr>
<tr id="row_0_34_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1swap.html" target="_self">swap</a></td><td class="desc">SWAP: interchanges two vectors </td></tr>
<tr id="row_0_35_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1symm.html" target="_self">symm</a></td><td class="desc">SYMM: performs one of the matrix-matrix operations C := alpha*A*B + beta*C, or C := alpha*B*A + beta*C, where alpha and beta are scalars, A is a symmetric matrix and B and C are m by n matrices </td></tr>
<tr id="row_0_36_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1symv.html" target="_self">symv</a></td><td class="desc">SYMV: performs the matrix-vector operation y := alpha*A*x + beta*y, where alpha and beta are scalars, x and y are n element vectors and A is an n by n symmetric matrix </td></tr>
<tr id="row_0_37_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1syr.html" target="_self">syr</a></td><td class="desc">SYR: performs the symmetric rank 1 operation A := alpha*x*x**T + A, where alpha is a real scalar, x is an n element vector and A is an n by n symmetric matrix </td></tr>
<tr id="row_0_38_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1syr2.html" target="_self">syr2</a></td><td class="desc">SYR2: performs the symmetric rank 2 operation A := alpha*x*y**T + alpha*y*x**T + A, where alpha is a scalar, x and y are n element vectors and A is an n by n symmetric matrix </td></tr>
<tr id="row_0_39_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1syr2k.html" target="_self">syr2k</a></td><td class="desc">SYR2K: performs one of the symmetric rank 2k operations C := alpha*A*B**T + alpha*B*A**T + beta*C, or C := alpha*A**T*B + alpha*B**T*A + beta*C, where alpha and beta are scalars, C is an n by n symmetric matrix and A and B are n by k matrices in the first case and k by n matrices in the second case </td></tr>
<tr id="row_0_40_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1syrk.html" target="_self">syrk</a></td><td class="desc">SYRK: performs one of the symmetric rank k operations C := alpha*A*A**T + beta*C, or C := alpha*A**T*A + beta*C, where alpha and beta are scalars, C is an n by n symmetric matrix and A is an n by k matrix in the first case and a k by n matrix in the second case </td></tr>
<tr id="row_0_41_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1tbmv.html" target="_self">tbmv</a></td><td class="desc">TBMV: performs one of the matrix-vector operations x := A*x, or x := A**T*x, or x := A**H*x, where x is an n element vector and A is an n by n unit, or non-unit, upper or lower triangular band matrix, with ( k + 1 ) diagonals </td></tr>
<tr id="row_0_42_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1tbsv.html" target="_self">tbsv</a></td><td class="desc">TBSV: solves one of the systems of equations A*x = b, or A**T*x = b, or A**H*x = b, where b and x are n element vectors and A is an n by n unit, or non-unit, upper or lower triangular band matrix, with ( k + 1 ) diagonals. No test for singularity or near-singularity is included in this routine. Such tests must be performed before calling this routine </td></tr>
<tr id="row_0_43_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1tpmv.html" target="_self">tpmv</a></td><td class="desc">TPMV: performs one of the matrix-vector operations x := A*x, or x := A**T*x, or x := A**H*x, where x is an n element vector and A is an n by n unit, or non-unit, upper or lower triangular matrix, supplied in packed form </td></tr>
<tr id="row_0_44_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1tpsv.html" target="_self">tpsv</a></td><td class="desc">TPSV: solves one of the systems of equations A*x = b, or A**T*x = b, or A**H*x = b, where b and x are n element vectors and A is an n by n unit, or non-unit, upper or lower triangular matrix, supplied in packed form. No test for singularity or near-singularity is included in this routine. Such tests must be performed before calling this routine </td></tr>
<tr id="row_0_45_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1trmm.html" target="_self">trmm</a></td><td class="desc">TRMM: performs one of the matrix-matrix operations B := alpha*op( A )*B, or B := alpha*B*op( A ) where alpha is a scalar, B is an m by n matrix, A is a unit, or non-unit, upper or lower triangular matrix and op( A ) is one of op( A ) = A or op( A ) = A**T or op( A ) = A**H </td></tr>
<tr id="row_0_46_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1trmv.html" target="_self">trmv</a></td><td class="desc">TRMV: performs one of the matrix-vector operations x := A*x, or x := A**T*x, or x := A**H*x, where x is an n element vector and A is an n by n unit, or non-unit, upper or lower triangular matrix </td></tr>
<tr id="row_0_47_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1trsm.html" target="_self">trsm</a></td><td class="desc">TRSM: solves one of the matrix equations op( A )*X = alpha*B, or X*op( A ) = alpha*B, where alpha is a scalar, X and B are m by n matrices, A is a unit, or non-unit, upper or lower triangular matrix and op( A ) is one of op( A ) = A or op( A ) = A**T or op( A ) = A**H. The matrix X is overwritten on B </td></tr>
<tr id="row_0_48_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__blas_1_1trsv.html" target="_self">trsv</a></td><td class="desc">TRSV: solves one of the systems of equations A*x = b, or A**T*x = b, or A**H*x = b, where b and x are n element vectors and A is an n by n unit, or non-unit, upper or lower triangular matrix. No test for singularity or near-singularity is included in this routine. Such tests must be performed before calling this routine </td></tr>
<tr id="row_1_" class="odd"><td class="entry"><span style="width:16px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">M</span></span><a class="el" href="namespacela__constants.html" target="_self">la_constants</a></td><td class="desc"></td></tr>
<tr id="row_2_" class="even"><td class="entry"><span style="width:0px;display:inline-block;">&#160;</span><span id="arr_2_" class="arrow" onclick="toggleFolder('2_')">&#9658;</span><span class="icona"><span class="icon">M</span></span><a class="el" href="namespacela__determinant.html" target="_self">la_determinant</a></td><td class="desc"></td></tr>
<tr id="row_2_0_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__determinant_1_1det.html" target="_self">det</a></td><td class="desc"></td></tr>
<tr id="row_3_" class="odd"><td class="entry"><span style="width:0px;display:inline-block;">&#160;</span><span id="arr_3_" class="arrow" onclick="toggleFolder('3_')">&#9658;</span><span class="icona"><span class="icon">M</span></span><a class="el" href="namespacela__eig.html" target="_self">la_eig</a></td><td class="desc"></td></tr>
<tr id="row_3_0_" class="even" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__eig_1_1eig.html" target="_self">eig</a></td><td class="desc">Eigendecomposition of a square matrix: return eigenvalues, and optionally eigenvectors </td></tr>
<tr id="row_3_1_" class="even" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__eig_1_1eigh.html" target="_self">eigh</a></td><td class="desc"></td></tr>
<tr id="row_3_2_" class="even" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__eig_1_1eigvals.html" target="_self">eigvals</a></td><td class="desc"></td></tr>
<tr id="row_3_3_" class="even" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__eig_1_1eigvalsh.html" target="_self">eigvalsh</a></td><td class="desc"></td></tr>
<tr id="row_4_" class="even"><td class="entry"><span style="width:0px;display:inline-block;">&#160;</span><span id="arr_4_" class="arrow" onclick="toggleFolder('4_')">&#9658;</span><span class="icona"><span class="icon">M</span></span><a class="el" href="namespacela__eye.html" target="_self">la_eye</a></td><td class="desc"></td></tr>
<tr id="row_4_0_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__eye_1_1diag.html" target="_self">diag</a></td><td class="desc"></td></tr>
<tr id="row_4_1_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__eye_1_1eye.html" target="_self">eye</a></td><td class="desc">Constructs the identity matrix. This interface provides procedures to generate an identity matrix of a given size. The resulting matrix has 1s on the diagonal and 0s elsewhere </td></tr>
<tr id="row_5_" class="odd"><td class="entry"><span style="width:0px;display:inline-block;">&#160;</span><span id="arr_5_" class="arrow" onclick="toggleFolder('5_')">&#9658;</span><span class="icona"><span class="icon">M</span></span><a class="el" href="namespacela__inverse.html" target="_self">la_inverse</a></td><td class="desc"></td></tr>
<tr id="row_5_0_" class="even" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__inverse_1_1inv.html" target="_self">inv</a></td><td class="desc">Function interface return the matrix inverse </td></tr>
<tr id="row_5_1_" class="even" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__inverse_1_1invert.html" target="_self">invert</a></td><td class="desc"></td></tr>
<tr id="row_5_2_" class="even" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__inverse_1_1operator_07_8inv_8_08.html" target="_self">operator(.inv.)</a></td><td class="desc"></td></tr>
<tr id="row_6_" class="even"><td class="entry"><span style="width:0px;display:inline-block;">&#160;</span><span id="arr_6_" class="arrow" onclick="toggleFolder('6_')">&#9658;</span><span class="icona"><span class="icon">M</span></span><a class="el" href="namespacela__lapack.html" target="_self">la_lapack</a></td><td class="desc"></td></tr>
<tr id="row_6_0_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1bbcsd.html" target="_self">bbcsd</a></td><td class="desc">BBCSD: computes the CS decomposition of a unitary matrix in bidiagonal-block form, [ B11 | B12 0 0 ] [ 0 | 0 -I 0 ] X = [-------------&mdash;] [ B21 | B22 0 0 ] [ 0 | 0 0 I ] [ C | -S 0 0 ] [ U1 | ] [ 0 | 0 -I 0 ] [ V1 | ]**H = [------&mdash;] [------------&mdash;] [------&mdash;] . [ | U2 ] [ S | C 0 0 ] [ | V2 ] [ 0 | 0 0 I ] X is M-by-M, its top-left block is P-by-Q, and Q must be no larger than P, M-P, or M-Q. (If Q is not the smallest index, then X must be transposed and/or permuted. This can be done in constant time using the TRANS and SIGNS options. See CUNCSD for details.) The bidiagonal matrices B11, B12, B21, and B22 are represented implicitly by angles THETA(1:Q) and PHI(1:Q-1). The unitary matrices U1, U2, V1T, and V2T are input/output. The input matrices are pre- or post-multiplied by the appropriate singular vector matrices </td></tr>
<tr id="row_6_1_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1bdsdc.html" target="_self">bdsdc</a></td><td class="desc">BDSDC: computes the singular value decomposition (SVD) of a real N-by-N (upper or lower) bidiagonal matrix B: B = U * S * VT, using a divide and conquer method, where S is a diagonal matrix with non-negative diagonal elements (the singular values of B), and U and VT are orthogonal matrices of left and right singular vectors, respectively. BDSDC can be used to compute all singular values, and optionally, singular vectors or singular vectors in compact form. This code makes very mild assumptions about floating point arithmetic. It will work on machines with a guard digit in add/subtract, or on those binary machines without guard digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2. It could conceivably fail on hexadecimal or decimal machines without guard digits, but we know of none. See DLASD3 for details. The code currently calls DLASDQ if singular values only are desired. However, it can be slightly modified to compute singular values using the divide and conquer method </td></tr>
<tr id="row_6_2_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1bdsqr.html" target="_self">bdsqr</a></td><td class="desc">BDSQR: computes the singular values and, optionally, the right and/or left singular vectors from the singular value decomposition (SVD) of a real N-by-N (upper or lower) bidiagonal matrix B using the implicit zero-shift QR algorithm. The SVD of B has the form B = Q * S * P**H where S is the diagonal matrix of singular values, Q is an orthogonal matrix of left singular vectors, and P is an orthogonal matrix of right singular vectors. If left singular vectors are requested, this subroutine actually returns U*Q instead of Q, and, if right singular vectors are requested, this subroutine returns P**H*VT instead of P**H, for given complex input matrices U and VT. When U and VT are the unitary matrices that reduce a general matrix A to bidiagonal form: A = U*B*VT, as computed by CGEBRD, then A = (U*Q) * S * (P**H*VT) is the SVD of A. Optionally, the subroutine may also compute Q**H*C for a given complex input matrix C. See "Computing  Small Singular Values of Bidiagonal Matrices With
 Guaranteed High Relative Accuracy," by J. Demmel and W. Kahan, LAPACK Working Note #3 (or SIAM J. Sci. Statist. Comput. vol. 11, no. 5, pp. 873-912, Sept 1990) and "Accurate singular values and differential qd algorithms," by B. Parlett and V. Fernando, Technical Report CPAM-554, Mathematics Department, University of California at Berkeley, July 1992 for a detailed description of the algorithm </td></tr>
<tr id="row_6_3_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1disna.html" target="_self">disna</a></td><td class="desc">DISNA: computes the reciprocal condition numbers for the eigenvectors of a real symmetric or complex Hermitian matrix or for the left or right singular vectors of a general m-by-n matrix. The reciprocal condition number is the 'gap' between the corresponding eigenvalue or singular value and the nearest other one. The bound on the error, measured by angle in radians, in the I-th computed vector is given by DLAMCH( 'E' ) * ( ANORM / SEP( I ) ) where ANORM = 2-norm(A) = max( abs( D(j) ) ). SEP(I) is not allowed to be smaller than DLAMCH( 'E' )*ANORM in order to limit the size of the error bound. DISNA may also be used to compute error bounds for eigenvectors of the generalized symmetric definite eigenproblem </td></tr>
<tr id="row_6_4_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gbbrd.html" target="_self">gbbrd</a></td><td class="desc">GBBRD: reduces a complex general m-by-n band matrix A to real upper bidiagonal form B by a unitary transformation: Q**H * A * P = B. The routine computes B, and optionally forms Q or P**H, or computes Q**H*C for a given matrix C </td></tr>
<tr id="row_6_5_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gbcon.html" target="_self">gbcon</a></td><td class="desc">GBCON: estimates the reciprocal of the condition number of a complex general band matrix A, in either the 1-norm or the infinity-norm, using the LU factorization computed by CGBTRF. An estimate is obtained for norm(inv(A)), and the reciprocal of the condition number is computed as RCOND = 1 / ( norm(A) * norm(inv(A)) ) </td></tr>
<tr id="row_6_6_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gbequ.html" target="_self">gbequ</a></td><td class="desc">GBEQU: computes row and column scalings intended to equilibrate an M-by-N band matrix A and reduce its condition number. R returns the row scale factors and C the column scale factors, chosen to try to make the largest element in each row and column of the matrix B with elements B(i,j)=R(i)*A(i,j)*C(j) have absolute value 1. R(i) and C(j) are restricted to be between SMLNUM = smallest safe number and BIGNUM = largest safe number. Use of these scaling factors is not guaranteed to reduce the condition number of A but works well in practice </td></tr>
<tr id="row_6_7_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gbequb.html" target="_self">gbequb</a></td><td class="desc">GBEQUB: computes row and column scalings intended to equilibrate an M-by-N matrix A and reduce its condition number. R returns the row scale factors and C the column scale factors, chosen to try to make the largest element in each row and column of the matrix B with elements B(i,j)=R(i)*A(i,j)*C(j) have an absolute value of at most the radix. R(i) and C(j) are restricted to be a power of the radix between SMLNUM = smallest safe number and BIGNUM = largest safe number. Use of these scaling factors is not guaranteed to reduce the condition number of A but works well in practice. This routine differs from CGEEQU by restricting the scaling factors to a power of the radix. Barring over- and underflow, scaling by these factors introduces no additional rounding errors. However, the scaled entries' magnitudes are no longer approximately 1 but lie between sqrt(radix) and 1/sqrt(radix) </td></tr>
<tr id="row_6_8_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gbrfs.html" target="_self">gbrfs</a></td><td class="desc">GBRFS: improves the computed solution to a system of linear equations when the coefficient matrix is banded, and provides error bounds and backward error estimates for the solution </td></tr>
<tr id="row_6_9_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gbsv.html" target="_self">gbsv</a></td><td class="desc">GBSV: computes the solution to a complex system of linear equations A * X = B, where A is a band matrix of order N with KL subdiagonals and KU superdiagonals, and X and B are N-by-NRHS matrices. The LU decomposition with partial pivoting and row interchanges is used to factor A as A = L * U, where L is a product of permutation and unit lower triangular matrices with KL subdiagonals, and U is upper triangular with KL+KU superdiagonals. The factored form of A is then used to solve the system of equations A * X = B </td></tr>
<tr id="row_6_10_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gbtrf.html" target="_self">gbtrf</a></td><td class="desc">GBTRF: computes an LU factorization of a complex m-by-n band matrix A using partial pivoting with row interchanges. This is the blocked version of the algorithm, calling Level 3 BLAS </td></tr>
<tr id="row_6_11_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gbtrs.html" target="_self">gbtrs</a></td><td class="desc">GBTRS: solves a system of linear equations A * X = B, A**T * X = B, or A**H * X = B with a general band matrix A using the LU factorization computed by CGBTRF </td></tr>
<tr id="row_6_12_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gebak.html" target="_self">gebak</a></td><td class="desc">GEBAK: forms the right or left eigenvectors of a complex general matrix by backward transformation on the computed eigenvectors of the balanced matrix output by CGEBAL </td></tr>
<tr id="row_6_13_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gebal.html" target="_self">gebal</a></td><td class="desc">GEBAL: balances a general complex matrix A. This involves, first, permuting A by a similarity transformation to isolate eigenvalues in the first 1 to ILO-1 and last IHI+1 to N elements on the diagonal; and second, applying a diagonal similarity transformation to rows and columns ILO to IHI to make the rows and columns as close in norm as possible. Both steps are optional. Balancing may reduce the 1-norm of the matrix, and improve the accuracy of the computed eigenvalues and/or eigenvectors </td></tr>
<tr id="row_6_14_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gebrd.html" target="_self">gebrd</a></td><td class="desc">GEBRD: reduces a general complex M-by-N matrix A to upper or lower bidiagonal form B by a unitary transformation: Q**H * A * P = B. If m &gt;= n, B is upper bidiagonal; if m &lt; n, B is lower bidiagonal </td></tr>
<tr id="row_6_15_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gecon.html" target="_self">gecon</a></td><td class="desc">GECON: estimates the reciprocal of the condition number of a general complex matrix A, in either the 1-norm or the infinity-norm, using the LU factorization computed by CGETRF. An estimate is obtained for norm(inv(A)), and the reciprocal of the condition number is computed as RCOND = 1 / ( norm(A) * norm(inv(A)) ) </td></tr>
<tr id="row_6_16_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1geequ.html" target="_self">geequ</a></td><td class="desc">GEEQU: computes row and column scalings intended to equilibrate an M-by-N matrix A and reduce its condition number. R returns the row scale factors and C the column scale factors, chosen to try to make the largest element in each row and column of the matrix B with elements B(i,j)=R(i)*A(i,j)*C(j) have absolute value 1. R(i) and C(j) are restricted to be between SMLNUM = smallest safe number and BIGNUM = largest safe number. Use of these scaling factors is not guaranteed to reduce the condition number of A but works well in practice </td></tr>
<tr id="row_6_17_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1geequb.html" target="_self">geequb</a></td><td class="desc">GEEQUB: computes row and column scalings intended to equilibrate an M-by-N matrix A and reduce its condition number. R returns the row scale factors and C the column scale factors, chosen to try to make the largest element in each row and column of the matrix B with elements B(i,j)=R(i)*A(i,j)*C(j) have an absolute value of at most the radix. R(i) and C(j) are restricted to be a power of the radix between SMLNUM = smallest safe number and BIGNUM = largest safe number. Use of these scaling factors is not guaranteed to reduce the condition number of A but works well in practice. This routine differs from CGEEQU by restricting the scaling factors to a power of the radix. Barring over- and underflow, scaling by these factors introduces no additional rounding errors. However, the scaled entries' magnitudes are no longer approximately 1 but lie between sqrt(radix) and 1/sqrt(radix) </td></tr>
<tr id="row_6_18_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gees.html" target="_self">gees</a></td><td class="desc">GEES: computes for an N-by-N complex nonsymmetric matrix A, the eigenvalues, the Schur form T, and, optionally, the matrix of Schur vectors Z. This gives the Schur factorization A = Z*T*(Z**H). Optionally, it also orders the eigenvalues on the diagonal of the Schur form so that selected eigenvalues are at the top left. The leading columns of Z then form an orthonormal basis for the invariant subspace corresponding to the selected eigenvalues. A complex matrix is in Schur form if it is upper triangular </td></tr>
<tr id="row_6_19_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1geev.html" target="_self">geev</a></td><td class="desc">GEEV: computes for an N-by-N complex nonsymmetric matrix A, the eigenvalues and, optionally, the left and/or right eigenvectors. The right eigenvector v(j) of A satisfies A * v(j) = lambda(j) * v(j) where lambda(j) is its eigenvalue. The left eigenvector u(j) of A satisfies u(j)**H * A = lambda(j) * u(j)**H where u(j)**H denotes the conjugate transpose of u(j). The computed eigenvectors are normalized to have Euclidean norm equal to 1 and largest component real </td></tr>
<tr id="row_6_20_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gehrd.html" target="_self">gehrd</a></td><td class="desc">GEHRD: reduces a complex general matrix A to upper Hessenberg form H by an unitary similarity transformation: Q**H * A * Q = H </td></tr>
<tr id="row_6_21_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gejsv.html" target="_self">gejsv</a></td><td class="desc">GEJSV: computes the singular value decomposition (SVD) of a complex M-by-N matrix [A], where M &gt;= N. The SVD of [A] is written as [A] = [U] * [SIGMA] * [V]^*, where [SIGMA] is an N-by-N (M-by-N) matrix which is zero except for its N diagonal elements, [U] is an M-by-N (or M-by-M) unitary matrix, and [V] is an N-by-N unitary matrix. The diagonal elements of [SIGMA] are the singular values of [A]. The columns of [U] and [V] are the left and the right singular vectors of [A], respectively. The matrices [U] and [V] are computed and stored in the arrays U and V, respectively. The diagonal of [SIGMA] is computed and stored in the array SVA </td></tr>
<tr id="row_6_22_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gelq.html" target="_self">gelq</a></td><td class="desc">GELQ: computes an LQ factorization of a complex M-by-N matrix A: A = ( L 0 ) * Q where: Q is a N-by-N orthogonal matrix; L is a lower-triangular M-by-M matrix; 0 is a M-by-(N-M) zero matrix, if M &lt; N </td></tr>
<tr id="row_6_23_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gelqf.html" target="_self">gelqf</a></td><td class="desc">GELQF: computes an LQ factorization of a complex M-by-N matrix A: A = ( L 0 ) * Q where: Q is a N-by-N orthogonal matrix; L is a lower-triangular M-by-M matrix; 0 is a M-by-(N-M) zero matrix, if M &lt; N </td></tr>
<tr id="row_6_24_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gelqt.html" target="_self">gelqt</a></td><td class="desc">GELQT: computes a blocked LQ factorization of a complex M-by-N matrix A using the compact WY representation of Q </td></tr>
<tr id="row_6_25_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gelqt3.html" target="_self">gelqt3</a></td><td class="desc">GELQT3: recursively computes a LQ factorization of a complex M-by-N matrix A, using the compact WY representation of Q. Based on the algorithm of Elmroth and Gustavson, IBM J. Res. Develop. Vol 44 No. 4 July 2000 </td></tr>
<tr id="row_6_26_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gels.html" target="_self">gels</a></td><td class="desc">GELS: solves overdetermined or underdetermined complex linear systems involving an M-by-N matrix A, or its conjugate-transpose, using a QR or LQ factorization of A. It is assumed that A has full rank. The following options are provided: </td></tr>
<tr id="row_6_27_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gelsd.html" target="_self">gelsd</a></td><td class="desc">GELSD: computes the minimum-norm solution to a real linear least squares problem: minimize 2-norm(| b - A*x |) using the singular value decomposition (SVD) of A. A is an M-by-N matrix which may be rank-deficient. Several right hand side vectors b and solution vectors x can be handled in a single call; they are stored as the columns of the M-by-NRHS right hand side matrix B and the N-by-NRHS solution matrix X. The problem is solved in three steps: (1) Reduce the coefficient matrix A to bidiagonal form with Householder transformations, reducing the original problem into a "bidiagonal least squares problem" (BLS) (2) Solve the BLS using a divide and conquer approach. (3) Apply back all the Householder transformations to solve the original least squares problem. The effective rank of A is determined by treating as zero those singular values which are less than RCOND times the largest singular value. The divide and conquer algorithm makes very mild assumptions about floating point arithmetic. It will work on machines with a guard digit in add/subtract, or on those binary machines without guard digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2. It could conceivably fail on hexadecimal or decimal machines without guard digits, but we know of none </td></tr>
<tr id="row_6_28_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gelss.html" target="_self">gelss</a></td><td class="desc">GELSS: computes the minimum norm solution to a complex linear least squares problem: Minimize 2-norm(| b - A*x |). using the singular value decomposition (SVD) of A. A is an M-by-N matrix which may be rank-deficient. Several right hand side vectors b and solution vectors x can be handled in a single call; they are stored as the columns of the M-by-NRHS right hand side matrix B and the N-by-NRHS solution matrix X. The effective rank of A is determined by treating as zero those singular values which are less than RCOND times the largest singular value </td></tr>
<tr id="row_6_29_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gelsy.html" target="_self">gelsy</a></td><td class="desc">GELSY: computes the minimum-norm solution to a complex linear least squares problem: minimize || A * X - B || using a complete orthogonal factorization of A. A is an M-by-N matrix which may be rank-deficient. Several right hand side vectors b and solution vectors x can be handled in a single call; they are stored as the columns of the M-by-NRHS right hand side matrix B and the N-by-NRHS solution matrix X. The routine first computes a QR factorization with column pivoting: A * P = Q * [ R11 R12 ] [ 0 R22 ] with R11 defined as the largest leading submatrix whose estimated condition number is less than 1/RCOND. The order of R11, RANK, is the effective rank of A. Then, R22 is considered to be negligible, and R12 is annihilated by unitary transformations from the right, arriving at the complete orthogonal factorization: A * P = Q * [ T11 0 ] * Z [ 0 0 ] The minimum-norm solution is then X = P * Z**H [ inv(T11)*Q1**H*B ] [ 0 ] where Q1 consists of the first RANK columns of Q. This routine is basically identical to the original xGELSX except three differences: o The permutation of matrix B (the right hand side) is faster and more simple. o The call to the subroutine xGEQPF has been substituted by the the call to the subroutine xGEQP3. This subroutine is a Blas-3 version of the QR factorization with column pivoting. o Matrix B (the right hand side) is updated with Blas-3 </td></tr>
<tr id="row_6_30_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gemlq.html" target="_self">gemlq</a></td><td class="desc">GEMLQ: overwrites the general real M-by-N matrix C with SIDE = 'L' SIDE = 'R' TRANS = 'N': Q * C C * Q TRANS = 'C': Q**H * C C * Q**H where Q is a complex unitary matrix defined as the product of blocked elementary reflectors computed by short wide LQ factorization (CGELQ) </td></tr>
<tr id="row_6_31_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gemlqt.html" target="_self">gemlqt</a></td><td class="desc">GEMLQT: overwrites the general complex M-by-N matrix C with SIDE = 'L' SIDE = 'R' TRANS = 'N': Q C C Q TRANS = 'C': Q**H C C Q**H where Q is a complex unitary matrix defined as the product of K elementary reflectors: Q = H(1) H(2) . . . H(K) = I - V T V**H generated using the compact WY representation as returned by CGELQT. Q is of order M if SIDE = 'L' and of order N if SIDE = 'R' </td></tr>
<tr id="row_6_32_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gemqr.html" target="_self">gemqr</a></td><td class="desc">GEMQR: overwrites the general real M-by-N matrix C with SIDE = 'L' SIDE = 'R' TRANS = 'N': Q * C C * Q TRANS = 'T': Q**H * C C * Q**H where Q is a complex unitary matrix defined as the product of blocked elementary reflectors computed by tall skinny QR factorization (CGEQR) </td></tr>
<tr id="row_6_33_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gemqrt.html" target="_self">gemqrt</a></td><td class="desc">GEMQRT: overwrites the general complex M-by-N matrix C with SIDE = 'L' SIDE = 'R' TRANS = 'N': Q C C Q TRANS = 'C': Q**H C C Q**H where Q is a complex orthogonal matrix defined as the product of K elementary reflectors: Q = H(1) H(2) . . . H(K) = I - V T V**H generated using the compact WY representation as returned by CGEQRT. Q is of order M if SIDE = 'L' and of order N if SIDE = 'R' </td></tr>
<tr id="row_6_34_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1geqlf.html" target="_self">geqlf</a></td><td class="desc">GEQLF: computes a QL factorization of a complex M-by-N matrix A: A = Q * L </td></tr>
<tr id="row_6_35_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1geqr.html" target="_self">geqr</a></td><td class="desc">GEQR: computes a QR factorization of a complex M-by-N matrix A: A = Q * ( R ), ( 0 ) where: Q is a M-by-M orthogonal matrix; R is an upper-triangular N-by-N matrix; 0 is a (M-N)-by-N zero matrix, if M &gt; N </td></tr>
<tr id="row_6_36_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1geqr2p.html" target="_self">geqr2p</a></td><td class="desc">GEQR2P: computes a QR factorization of a complex m-by-n matrix A: A = Q * ( R ), ( 0 ) where: Q is a m-by-m orthogonal matrix; R is an upper-triangular n-by-n matrix with nonnegative diagonal entries; 0 is a (m-n)-by-n zero matrix, if m &gt; n </td></tr>
<tr id="row_6_37_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1geqrf.html" target="_self">geqrf</a></td><td class="desc">GEQRF: computes a QR factorization of a complex M-by-N matrix A: A = Q * ( R ), ( 0 ) where: Q is a M-by-M orthogonal matrix; R is an upper-triangular N-by-N matrix; 0 is a (M-N)-by-N zero matrix, if M &gt; N </td></tr>
<tr id="row_6_38_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1geqrfp.html" target="_self">geqrfp</a></td><td class="desc">CGEQR2P computes a QR factorization of a complex M-by-N matrix A: A = Q * ( R ), ( 0 ) where: Q is a M-by-M orthogonal matrix; R is an upper-triangular N-by-N matrix with nonnegative diagonal entries; 0 is a (M-N)-by-N zero matrix, if M &gt; N </td></tr>
<tr id="row_6_39_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1geqrt.html" target="_self">geqrt</a></td><td class="desc">GEQRT: computes a blocked QR factorization of a complex M-by-N matrix A using the compact WY representation of Q </td></tr>
<tr id="row_6_40_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1geqrt2.html" target="_self">geqrt2</a></td><td class="desc">GEQRT2: computes a QR factorization of a complex M-by-N matrix A, using the compact WY representation of Q </td></tr>
<tr id="row_6_41_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1geqrt3.html" target="_self">geqrt3</a></td><td class="desc">GEQRT3: recursively computes a QR factorization of a complex M-by-N matrix A, using the compact WY representation of Q. Based on the algorithm of Elmroth and Gustavson, IBM J. Res. Develop. Vol 44 No. 4 July 2000 </td></tr>
<tr id="row_6_42_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gerfs.html" target="_self">gerfs</a></td><td class="desc">GERFS: improves the computed solution to a system of linear equations and provides error bounds and backward error estimates for the solution </td></tr>
<tr id="row_6_43_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gerqf.html" target="_self">gerqf</a></td><td class="desc">GERQF: computes an RQ factorization of a complex M-by-N matrix A: A = R * Q </td></tr>
<tr id="row_6_44_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gesdd.html" target="_self">gesdd</a></td><td class="desc">GESDD: computes the singular value decomposition (SVD) of a complex M-by-N matrix A, optionally computing the left and/or right singular vectors, by using divide-and-conquer method. The SVD is written A = U * SIGMA * conjugate-transpose(V) where SIGMA is an M-by-N matrix which is zero except for its min(m,n) diagonal elements, U is an M-by-M unitary matrix, and V is an N-by-N unitary matrix. The diagonal elements of SIGMA are the singular values of A; they are real and non-negative, and are returned in descending order. The first min(m,n) columns of U and V are the left and right singular vectors of A. Note that the routine returns VT = V**H, not V. The divide and conquer algorithm makes very mild assumptions about floating point arithmetic. It will work on machines with a guard digit in add/subtract, or on those binary machines without guard digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2. It could conceivably fail on hexadecimal or decimal machines without guard digits, but we know of none </td></tr>
<tr id="row_6_45_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gesv.html" target="_self">gesv</a></td><td class="desc">GESV: computes the solution to a complex system of linear equations A * X = B, where A is an N-by-N matrix and X and B are N-by-NRHS matrices. The LU decomposition with partial pivoting and row interchanges is used to factor A as A = P * L * U, where P is a permutation matrix, L is unit lower triangular, and U is upper triangular. The factored form of A is then used to solve the system of equations A * X = B </td></tr>
<tr id="row_6_46_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gesvd.html" target="_self">gesvd</a></td><td class="desc">GESVD: computes the singular value decomposition (SVD) of a complex M-by-N matrix A, optionally computing the left and/or right singular vectors. The SVD is written A = U * SIGMA * conjugate-transpose(V) where SIGMA is an M-by-N matrix which is zero except for its min(m,n) diagonal elements, U is an M-by-M unitary matrix, and V is an N-by-N unitary matrix. The diagonal elements of SIGMA are the singular values of A; they are real and non-negative, and are returned in descending order. The first min(m,n) columns of U and V are the left and right singular vectors of A. Note that the routine returns V**H, not V </td></tr>
<tr id="row_6_47_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gesvdq.html" target="_self">gesvdq</a></td><td class="desc">GESVDQ: computes the singular value decomposition (SVD) of a complex M-by-N matrix A, where M &gt;= N. The SVD of A is written as [++] [xx] [x0] [xx] A = U * SIGMA * V^*, [++] = [xx] * [ox] * [xx] [++] [xx] where SIGMA is an N-by-N diagonal matrix, U is an M-by-N orthonormal matrix, and V is an N-by-N unitary matrix. The diagonal elements of SIGMA are the singular values of A. The columns of U and V are the left and the right singular vectors of A, respectively </td></tr>
<tr id="row_6_48_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gesvj.html" target="_self">gesvj</a></td><td class="desc">GESVJ: computes the singular value decomposition (SVD) of a complex M-by-N matrix A, where M &gt;= N. The SVD of A is written as [++] [xx] [x0] [xx] A = U * SIGMA * V^*, [++] = [xx] * [ox] * [xx] [++] [xx] where SIGMA is an N-by-N diagonal matrix, U is an M-by-N orthonormal matrix, and V is an N-by-N unitary matrix. The diagonal elements of SIGMA are the singular values of A. The columns of U and V are the left and the right singular vectors of A, respectively </td></tr>
<tr id="row_6_49_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1getrf.html" target="_self">getrf</a></td><td class="desc">GETRF: computes an LU factorization of a general M-by-N matrix A using partial pivoting with row interchanges. The factorization has the form A = P * L * U where P is a permutation matrix, L is lower triangular with unit diagonal elements (lower trapezoidal if m &gt; n), and U is upper triangular (upper trapezoidal if m &lt; n). This is the right-looking Level 3 BLAS version of the algorithm </td></tr>
<tr id="row_6_50_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1getrf2.html" target="_self">getrf2</a></td><td class="desc">GETRF2: computes an LU factorization of a general M-by-N matrix A using partial pivoting with row interchanges. The factorization has the form A = P * L * U where P is a permutation matrix, L is lower triangular with unit diagonal elements (lower trapezoidal if m &gt; n), and U is upper triangular (upper trapezoidal if m &lt; n). This is the recursive version of the algorithm. It divides the matrix into four submatrices: [ A11 | A12 ] where A11 is n1 by n1 and A22 is n2 by n2 A = [ --&mdash;|--&mdash; ] with n1 = min(m,n)/2 [ A21 | A22 ] n2 = n-n1 [ A11 ] The subroutine calls itself to factor [ &mdash; ], [ A12 ] [ A12 ] do the swaps on [ &mdash; ], solve A12, update A22, [ A22 ] then calls itself to factor A22 and do the swaps on A21 </td></tr>
<tr id="row_6_51_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1getri.html" target="_self">getri</a></td><td class="desc">GETRI: computes the inverse of a matrix using the LU factorization computed by CGETRF. This method inverts U and then computes inv(A) by solving the system inv(A)*L = inv(U) for inv(A) </td></tr>
<tr id="row_6_52_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1getrs.html" target="_self">getrs</a></td><td class="desc">GETRS: solves a system of linear equations A * X = B, A**T * X = B, or A**H * X = B with a general N-by-N matrix A using the LU factorization computed by CGETRF </td></tr>
<tr id="row_6_53_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1getsls.html" target="_self">getsls</a></td><td class="desc">GETSLS: solves overdetermined or underdetermined complex linear systems involving an M-by-N matrix A, using a tall skinny QR or short wide LQ factorization of A. It is assumed that A has full rank. The following options are provided: </td></tr>
<tr id="row_6_54_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1getsqrhrt.html" target="_self">getsqrhrt</a></td><td class="desc">GETSQRHRT: computes a NB2-sized column blocked QR-factorization of a complex M-by-N matrix A with M &gt;= N, A = Q * R. The routine uses internally a NB1-sized column blocked and MB1-sized row blocked TSQR-factorization and perfors the reconstruction of the Householder vectors from the TSQR output. The routine also converts the R_tsqr factor from the TSQR-factorization output into the R factor that corresponds to the Householder QR-factorization, A = Q_tsqr * R_tsqr = Q * R. The output Q and R factors are stored in the same format as in CGEQRT (Q is in blocked compact WY-representation). See the documentation of CGEQRT for more details on the format </td></tr>
<tr id="row_6_55_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ggbak.html" target="_self">ggbak</a></td><td class="desc">GGBAK: forms the right or left eigenvectors of a complex generalized eigenvalue problem A*x = lambda*B*x, by backward transformation on the computed eigenvectors of the balanced pair of matrices output by CGGBAL </td></tr>
<tr id="row_6_56_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ggbal.html" target="_self">ggbal</a></td><td class="desc">GGBAL: balances a pair of general complex matrices (A,B). This involves, first, permuting A and B by similarity transformations to isolate eigenvalues in the first 1 to ILO$-$1 and last IHI+1 to N elements on the diagonal; and second, applying a diagonal similarity transformation to rows and columns ILO to IHI to make the rows and columns as close in norm as possible. Both steps are optional. Balancing may reduce the 1-norm of the matrices, and improve the accuracy of the computed eigenvalues and/or eigenvectors in the generalized eigenvalue problem A*x = lambda*B*x </td></tr>
<tr id="row_6_57_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gges.html" target="_self">gges</a></td><td class="desc">GGES: computes for a pair of N-by-N complex nonsymmetric matrices (A,B), the generalized eigenvalues, the generalized complex Schur form (S, T), and optionally left and/or right Schur vectors (VSL and VSR). This gives the generalized Schur factorization (A,B) = ( (VSL)*S*(VSR)**H, (VSL)*T*(VSR)**H ) where (VSR)**H is the conjugate-transpose of VSR. Optionally, it also orders the eigenvalues so that a selected cluster of eigenvalues appears in the leading diagonal blocks of the upper triangular matrix S and the upper triangular matrix T. The leading columns of VSL and VSR then form an unitary basis for the corresponding left and right eigenspaces (deflating subspaces). (If only the generalized eigenvalues are needed, use the driver CGGEV instead, which is faster.) A generalized eigenvalue for a pair of matrices (A,B) is a scalar w or a ratio alpha/beta = w, such that A - w*B is singular. It is usually represented as the pair (alpha,beta), as there is a reasonable interpretation for beta=0, and even for both being zero. A pair of matrices (S,T) is in generalized complex Schur form if S and T are upper triangular and, in addition, the diagonal elements of T are non-negative real numbers </td></tr>
<tr id="row_6_58_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ggev.html" target="_self">ggev</a></td><td class="desc">GGEV: computes for a pair of N-by-N complex nonsymmetric matrices (A,B), the generalized eigenvalues, and optionally, the left and/or right generalized eigenvectors. A generalized eigenvalue for a pair of matrices (A,B) is a scalar lambda or a ratio alpha/beta = lambda, such that A - lambda*B is singular. It is usually represented as the pair (alpha,beta), as there is a reasonable interpretation for beta=0, and even for both being zero. The right generalized eigenvector v(j) corresponding to the generalized eigenvalue lambda(j) of (A,B) satisfies A * v(j) = lambda(j) * B * v(j). The left generalized eigenvector u(j) corresponding to the generalized eigenvalues lambda(j) of (A,B) satisfies u(j)**H * A = lambda(j) * u(j)**H * B where u(j)**H is the conjugate-transpose of u(j) </td></tr>
<tr id="row_6_59_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ggglm.html" target="_self">ggglm</a></td><td class="desc">GGGLM: solves a general Gauss-Markov linear model (GLM) problem: minimize || y ||_2 subject to d = A*x + B*y x where A is an N-by-M matrix, B is an N-by-P matrix, and d is a given N-vector. It is assumed that M &lt;= N &lt;= M+P, and rank(A) = M and rank( A B ) = N. Under these assumptions, the constrained equation is always consistent, and there is a unique solution x and a minimal 2-norm solution y, which is obtained using a generalized QR factorization of the matrices (A, B) given by A = Q*(R), B = Q*T*Z. (0) In particular, if matrix B is square nonsingular, then the problem GLM is equivalent to the following weighted linear least squares problem minimize || inv(B)*(d-A*x) ||_2 x where inv(B) denotes the inverse of B </td></tr>
<tr id="row_6_60_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gghrd.html" target="_self">gghrd</a></td><td class="desc">GGHRD: reduces a pair of complex matrices (A,B) to generalized upper Hessenberg form using unitary transformations, where A is a general matrix and B is upper triangular. The form of the generalized eigenvalue problem is A*x = lambda*B*x, and B is typically made upper triangular by computing its QR factorization and moving the unitary matrix Q to the left side of the equation. This subroutine simultaneously reduces A to a Hessenberg matrix H: Q**H*A*Z = H and transforms B to another upper triangular matrix T: Q**H*B*Z = T in order to reduce the problem to its standard form H*y = lambda*T*y where y = Z**H*x. The unitary matrices Q and Z are determined as products of Givens rotations. They may either be formed explicitly, or they may be postmultiplied into input matrices Q1 and Z1, so that Q1 * A * Z1**H = (Q1*Q) * H * (Z1*Z)**H Q1 * B * Z1**H = (Q1*Q) * T * (Z1*Z)**H If Q1 is the unitary matrix from the QR factorization of B in the original equation A*x = lambda*B*x, then GGHRD reduces the original problem to generalized Hessenberg form </td></tr>
<tr id="row_6_61_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gglse.html" target="_self">gglse</a></td><td class="desc">GGLSE: solves the linear equality-constrained least squares (LSE) problem: minimize || c - A*x ||_2 subject to B*x = d where A is an M-by-N matrix, B is a P-by-N matrix, c is a given M-vector, and d is a given P-vector. It is assumed that P &lt;= N &lt;= M+P, and rank(B) = P and rank( (A) ) = N. ( (B) ) These conditions ensure that the LSE problem has a unique solution, which is obtained using a generalized RQ factorization of the matrices (B, A) given by B = (0 R)*Q, A = Z*T*Q </td></tr>
<tr id="row_6_62_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ggqrf.html" target="_self">ggqrf</a></td><td class="desc">GGQRF: computes a generalized QR factorization of an N-by-M matrix A and an N-by-P matrix B: A = Q*R, B = Q*T*Z, where Q is an N-by-N unitary matrix, Z is a P-by-P unitary matrix, and R and T assume one of the forms: if N &gt;= M, R = ( R11 ) M , or if N &lt; M, R = ( R11 R12 ) N, ( 0 ) N-M N M-N M where R11 is upper triangular, and if N &lt;= P, T = ( 0 T12 ) N, or if N &gt; P, T = ( T11 ) N-P, P-N N ( T21 ) P P where T12 or T21 is upper triangular. In particular, if B is square and nonsingular, the GQR factorization of A and B implicitly gives the QR factorization of inv(B)*A: inv(B)*A = Z**H * (inv(T)*R) where inv(B) denotes the inverse of the matrix B, and Z' denotes the conjugate transpose of matrix Z </td></tr>
<tr id="row_6_63_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ggrqf.html" target="_self">ggrqf</a></td><td class="desc">GGRQF: computes a generalized RQ factorization of an M-by-N matrix A and a P-by-N matrix B: A = R*Q, B = Z*T*Q, where Q is an N-by-N unitary matrix, Z is a P-by-P unitary matrix, and R and T assume one of the forms: if M &lt;= N, R = ( 0 R12 ) M, or if M &gt; N, R = ( R11 ) M-N, N-M M ( R21 ) N N where R12 or R21 is upper triangular, and if P &gt;= N, T = ( T11 ) N , or if P &lt; N, T = ( T11 T12 ) P, ( 0 ) P-N P N-P N where T11 is upper triangular. In particular, if B is square and nonsingular, the GRQ factorization of A and B implicitly gives the RQ factorization of A*inv(B): A*inv(B) = (R*inv(T))*Z**H where inv(B) denotes the inverse of the matrix B, and Z**H denotes the conjugate transpose of the matrix Z </td></tr>
<tr id="row_6_64_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gsvj0.html" target="_self">gsvj0</a></td><td class="desc">GSVJ0: is called from CGESVJ as a pre-processor and that is its main purpose. It applies Jacobi rotations in the same way as CGESVJ does, but it does not check convergence (stopping criterion). Few tuning parameters (marked by [TP]) are available for the implementer </td></tr>
<tr id="row_6_65_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gsvj1.html" target="_self">gsvj1</a></td><td class="desc">GSVJ1: is called from CGESVJ as a pre-processor and that is its main purpose. It applies Jacobi rotations in the same way as CGESVJ does, but it targets only particular pivots and it does not check convergence (stopping criterion). Few tuning parameters (marked by [TP]) are available for the implementer. Further Details ~~~~~~~~~~~~~~~ GSVJ1 applies few sweeps of Jacobi rotations in the column space of the input M-by-N matrix A. The pivot pairs are taken from the (1,2) off-diagonal block in the corresponding N-by-N Gram matrix A^T * A. The block-entries (tiles) of the (1,2) off-diagonal block are marked by the [x]'s in the following scheme: | * * * [x] [x] [x]| | * * * [x] [x] [x]| Row-cycling in the nblr-by-nblc [x] blocks. | * * * [x] [x] [x]| Row-cyclic pivoting inside each [x] block. |[x] [x] [x] * * * | |[x] [x] [x] * * * | |[x] [x] [x] * * * | In terms of the columns of A, the first N1 columns are rotated 'against' the remaining N-N1 columns, trying to increase the angle between the corresponding subspaces. The off-diagonal block is N1-by(N-N1) and it is tiled using quadratic tiles of side KBL. Here, KBL is a tuning parameter. The number of sweeps is given in NSWEEP and the orthogonality threshold is given in TOL </td></tr>
<tr id="row_6_66_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gtcon.html" target="_self">gtcon</a></td><td class="desc">GTCON: estimates the reciprocal of the condition number of a complex tridiagonal matrix A using the LU factorization as computed by CGTTRF. An estimate is obtained for norm(inv(A)), and the reciprocal of the condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))) </td></tr>
<tr id="row_6_67_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gtrfs.html" target="_self">gtrfs</a></td><td class="desc">GTRFS: improves the computed solution to a system of linear equations when the coefficient matrix is tridiagonal, and provides error bounds and backward error estimates for the solution </td></tr>
<tr id="row_6_68_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gtsv.html" target="_self">gtsv</a></td><td class="desc">GTSV: solves the equation A*X = B, where A is an N-by-N tridiagonal matrix, by Gaussian elimination with partial pivoting. Note that the equation A**T *X = B may be solved by interchanging the order of the arguments DU and DL </td></tr>
<tr id="row_6_69_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gttrf.html" target="_self">gttrf</a></td><td class="desc">GTTRF: computes an LU factorization of a complex tridiagonal matrix A using elimination with partial pivoting and row interchanges. The factorization has the form A = L * U where L is a product of permutation and unit lower bidiagonal matrices and U is upper triangular with nonzeros in only the main diagonal and first two superdiagonals </td></tr>
<tr id="row_6_70_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1gttrs.html" target="_self">gttrs</a></td><td class="desc">GTTRS: solves one of the systems of equations A * X = B, A**T * X = B, or A**H * X = B, with a tridiagonal matrix A using the LU factorization computed by CGTTRF </td></tr>
<tr id="row_6_71_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hb2st__kernels.html" target="_self">hb2st_kernels</a></td><td class="desc">HB2ST_KERNELS: is an internal routine used by the CHETRD_HB2ST subroutine </td></tr>
<tr id="row_6_72_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hbev.html" target="_self">hbev</a></td><td class="desc">HBEV: computes all the eigenvalues and, optionally, eigenvectors of a complex Hermitian band matrix A </td></tr>
<tr id="row_6_73_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hbevd.html" target="_self">hbevd</a></td><td class="desc">HBEVD: computes all the eigenvalues and, optionally, eigenvectors of a complex Hermitian band matrix A. If eigenvectors are desired, it uses a divide and conquer algorithm. The divide and conquer algorithm makes very mild assumptions about floating point arithmetic. It will work on machines with a guard digit in add/subtract, or on those binary machines without guard digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2. It could conceivably fail on hexadecimal or decimal machines without guard digits, but we know of none </td></tr>
<tr id="row_6_74_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hbgst.html" target="_self">hbgst</a></td><td class="desc">HBGST: reduces a complex Hermitian-definite banded generalized eigenproblem A*x = lambda*B*x to standard form C*y = lambda*y, such that C has the same bandwidth as A. B must have been previously factorized as S**H*S by CPBSTF, using a split Cholesky factorization. A is overwritten by C = X**H*A*X, where X = S**(-1)*Q and Q is a unitary matrix chosen to preserve the bandwidth of A </td></tr>
<tr id="row_6_75_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hbgv.html" target="_self">hbgv</a></td><td class="desc">HBGV: computes all the eigenvalues, and optionally, the eigenvectors of a complex generalized Hermitian-definite banded eigenproblem, of the form A*x=(lambda)*B*x. Here A and B are assumed to be Hermitian and banded, and B is also positive definite </td></tr>
<tr id="row_6_76_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hbgvd.html" target="_self">hbgvd</a></td><td class="desc">HBGVD: computes all the eigenvalues, and optionally, the eigenvectors of a complex generalized Hermitian-definite banded eigenproblem, of the form A*x=(lambda)*B*x. Here A and B are assumed to be Hermitian and banded, and B is also positive definite. If eigenvectors are desired, it uses a divide and conquer algorithm. The divide and conquer algorithm makes very mild assumptions about floating point arithmetic. It will work on machines with a guard digit in add/subtract, or on those binary machines without guard digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2. It could conceivably fail on hexadecimal or decimal machines without guard digits, but we know of none </td></tr>
<tr id="row_6_77_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hbtrd.html" target="_self">hbtrd</a></td><td class="desc">HBTRD: reduces a complex Hermitian band matrix A to real symmetric tridiagonal form T by a unitary similarity transformation: Q**H * A * Q = T </td></tr>
<tr id="row_6_78_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hecon.html" target="_self">hecon</a></td><td class="desc">HECON: estimates the reciprocal of the condition number of a complex Hermitian matrix A using the factorization A = U*D*U**H or A = L*D*L**H computed by CHETRF. An estimate is obtained for norm(inv(A)), and the reciprocal of the condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))) </td></tr>
<tr id="row_6_79_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hecon__rook.html" target="_self">hecon_rook</a></td><td class="desc">HECON_ROOK: estimates the reciprocal of the condition number of a complex Hermitian matrix A using the factorization A = U*D*U**H or A = L*D*L**H computed by CHETRF_ROOK. An estimate is obtained for norm(inv(A)), and the reciprocal of the condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))) </td></tr>
<tr id="row_6_80_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1heequb.html" target="_self">heequb</a></td><td class="desc">HEEQUB: computes row and column scalings intended to equilibrate a Hermitian matrix A (with respect to the Euclidean norm) and reduce its condition number. The scale factors S are computed by the BIN algorithm (see references) so that the scaled matrix B with elements B(i,j) = S(i)*A(i,j)*S(j) has a condition number within a factor N of the smallest possible condition number over all possible diagonal scalings </td></tr>
<tr id="row_6_81_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1heev.html" target="_self">heev</a></td><td class="desc">HEEV: computes all eigenvalues and, optionally, eigenvectors of a complex Hermitian matrix A </td></tr>
<tr id="row_6_82_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1heevd.html" target="_self">heevd</a></td><td class="desc">HEEVD: computes all eigenvalues and, optionally, eigenvectors of a complex Hermitian matrix A. If eigenvectors are desired, it uses a divide and conquer algorithm. The divide and conquer algorithm makes very mild assumptions about floating point arithmetic. It will work on machines with a guard digit in add/subtract, or on those binary machines without guard digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2. It could conceivably fail on hexadecimal or decimal machines without guard digits, but we know of none </td></tr>
<tr id="row_6_83_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1heevr.html" target="_self">heevr</a></td><td class="desc">HEEVR: computes selected eigenvalues and, optionally, eigenvectors of a complex Hermitian matrix A. Eigenvalues and eigenvectors can be selected by specifying either a range of values or a range of indices for the desired eigenvalues. HEEVR first reduces the matrix A to tridiagonal form T with a call to CHETRD. Then, whenever possible, HEEVR calls CSTEMR to compute the eigenspectrum using Relatively Robust Representations. CSTEMR computes eigenvalues by the dqds algorithm, while orthogonal eigenvectors are computed from various "good" L D L^T representations (also known as Relatively Robust Representations). Gram-Schmidt orthogonalization is avoided as far as possible. More specifically, the various steps of the algorithm are as follows. For each unreduced block (submatrix) of T, (a) Compute T - sigma I = L D L^T, so that L and D define all the wanted eigenvalues to high relative accuracy. This means that small relative changes in the entries of D and L cause only small relative changes in the eigenvalues and eigenvectors. The standard (unfactored) representation of the tridiagonal matrix T does not have this property in general. (b) Compute the eigenvalues to suitable accuracy. If the eigenvectors are desired, the algorithm attains full accuracy of the computed eigenvalues only right before the corresponding vectors have to be computed, see steps c) and d). (c) For each cluster of close eigenvalues, select a new shift close to the cluster, find a new factorization, and refine the shifted eigenvalues to suitable accuracy. (d) For each eigenvalue with a large enough relative separation compute the corresponding eigenvector by forming a rank revealing twisted factorization. Go back to (c) for any clusters that remain. The desired accuracy of the output can be specified by the input parameter ABSTOL. For more details, see CSTEMR's documentation and: </td></tr>
<tr id="row_6_84_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hegst.html" target="_self">hegst</a></td><td class="desc">HEGST: reduces a complex Hermitian-definite generalized eigenproblem to standard form. If ITYPE = 1, the problem is A*x = lambda*B*x, and A is overwritten by inv(U**H)*A*inv(U) or inv(L)*A*inv(L**H) If ITYPE = 2 or 3, the problem is A*B*x = lambda*x or B*A*x = lambda*x, and A is overwritten by U*A*U**H or L**H*A*L. B must have been previously factorized as U**H*U or L*L**H by CPOTRF </td></tr>
<tr id="row_6_85_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hegv.html" target="_self">hegv</a></td><td class="desc">HEGV: computes all the eigenvalues, and optionally, the eigenvectors of a complex generalized Hermitian-definite eigenproblem, of the form A*x=(lambda)*B*x, A*Bx=(lambda)*x, or B*A*x=(lambda)*x. Here A and B are assumed to be Hermitian and B is also positive definite </td></tr>
<tr id="row_6_86_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hegvd.html" target="_self">hegvd</a></td><td class="desc">HEGVD: computes all the eigenvalues, and optionally, the eigenvectors of a complex generalized Hermitian-definite eigenproblem, of the form A*x=(lambda)*B*x, A*Bx=(lambda)*x, or B*A*x=(lambda)*x. Here A and B are assumed to be Hermitian and B is also positive definite. If eigenvectors are desired, it uses a divide and conquer algorithm. The divide and conquer algorithm makes very mild assumptions about floating point arithmetic. It will work on machines with a guard digit in add/subtract, or on those binary machines without guard digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2. It could conceivably fail on hexadecimal or decimal machines without guard digits, but we know of none </td></tr>
<tr id="row_6_87_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1herfs.html" target="_self">herfs</a></td><td class="desc">HERFS: improves the computed solution to a system of linear equations when the coefficient matrix is Hermitian indefinite, and provides error bounds and backward error estimates for the solution </td></tr>
<tr id="row_6_88_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hesv.html" target="_self">hesv</a></td><td class="desc">HESV: computes the solution to a complex system of linear equations A * X = B, where A is an N-by-N Hermitian matrix and X and B are N-by-NRHS matrices. The diagonal pivoting method is used to factor A as A = U * D * U**H, if UPLO = 'U', or A = L * D * L**H, if UPLO = 'L', where U (or L) is a product of permutation and unit upper (lower) triangular matrices, and D is Hermitian and block diagonal with 1-by-1 and 2-by-2 diagonal blocks. The factored form of A is then used to solve the system of equations A * X = B </td></tr>
<tr id="row_6_89_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hesv__aa.html" target="_self">hesv_aa</a></td><td class="desc">HESV_AA: computes the solution to a complex system of linear equations A * X = B, where A is an N-by-N Hermitian matrix and X and B are N-by-NRHS matrices. Aasen's algorithm is used to factor A as A = U**H * T * U, if UPLO = 'U', or A = L * T * L**H, if UPLO = 'L', where U (or L) is a product of permutation and unit upper (lower) triangular matrices, and T is Hermitian and tridiagonal. The factored form of A is then used to solve the system of equations A * X = B </td></tr>
<tr id="row_6_90_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hesv__rk.html" target="_self">hesv_rk</a></td><td class="desc">HESV_RK: computes the solution to a complex system of linear equations A * X = B, where A is an N-by-N Hermitian matrix and X and B are N-by-NRHS matrices. The bounded Bunch-Kaufman (rook) diagonal pivoting method is used to factor A as A = P*U*D*(U**H)*(P**T), if UPLO = 'U', or A = P*L*D*(L**H)*(P**T), if UPLO = 'L', where U (or L) is unit upper (or lower) triangular matrix, U**H (or L**H) is the conjugate of U (or L), P is a permutation matrix, P**T is the transpose of P, and D is Hermitian and block diagonal with 1-by-1 and 2-by-2 diagonal blocks. CHETRF_RK is called to compute the factorization of a complex Hermitian matrix. The factored form of A is then used to solve the system of equations A * X = B by calling BLAS3 routine CHETRS_3 </td></tr>
<tr id="row_6_91_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hesv__rook.html" target="_self">hesv_rook</a></td><td class="desc">HESV_ROOK: computes the solution to a complex system of linear equations A * X = B, where A is an N-by-N Hermitian matrix and X and B are N-by-NRHS matrices. The bounded Bunch-Kaufman ("rook") diagonal pivoting method is used to factor A as A = U * D * U**T, if UPLO = 'U', or A = L * D * L**T, if UPLO = 'L', where U (or L) is a product of permutation and unit upper (lower) triangular matrices, and D is Hermitian and block diagonal with 1-by-1 and 2-by-2 diagonal blocks. CHETRF_ROOK is called to compute the factorization of a complex Hermition matrix A using the bounded Bunch-Kaufman ("rook") diagonal pivoting method. The factored form of A is then used to solve the system of equations A * X = B by calling CHETRS_ROOK (uses BLAS 2) </td></tr>
<tr id="row_6_92_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1heswapr.html" target="_self">heswapr</a></td><td class="desc">HESWAPR: applies an elementary permutation on the rows and the columns of a hermitian matrix </td></tr>
<tr id="row_6_93_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hetf2__rk.html" target="_self">hetf2_rk</a></td><td class="desc">HETF2_RK: computes the factorization of a complex Hermitian matrix A using the bounded Bunch-Kaufman (rook) diagonal pivoting method: A = P*U*D*(U**H)*(P**T) or A = P*L*D*(L**H)*(P**T), where U (or L) is unit upper (or lower) triangular matrix, U**H (or L**H) is the conjugate of U (or L), P is a permutation matrix, P**T is the transpose of P, and D is Hermitian and block diagonal with 1-by-1 and 2-by-2 diagonal blocks. This is the unblocked version of the algorithm, calling Level 2 BLAS. For more information see Further Details section </td></tr>
<tr id="row_6_94_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hetf2__rook.html" target="_self">hetf2_rook</a></td><td class="desc">HETF2_ROOK: computes the factorization of a complex Hermitian matrix A using the bounded Bunch-Kaufman ("rook") diagonal pivoting method: A = U*D*U**H or A = L*D*L**H where U (or L) is a product of permutation and unit upper (lower) triangular matrices, U**H is the conjugate transpose of U, and D is Hermitian and block diagonal with 1-by-1 and 2-by-2 diagonal blocks. This is the unblocked version of the algorithm, calling Level 2 BLAS </td></tr>
<tr id="row_6_95_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hetrd.html" target="_self">hetrd</a></td><td class="desc">HETRD: reduces a complex Hermitian matrix A to real symmetric tridiagonal form T by a unitary similarity transformation: Q**H * A * Q = T </td></tr>
<tr id="row_6_96_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hetrd__hb2st.html" target="_self">hetrd_hb2st</a></td><td class="desc">HETRD_HB2ST: reduces a complex Hermitian band matrix A to real symmetric tridiagonal form T by a unitary similarity transformation: Q**H * A * Q = T </td></tr>
<tr id="row_6_97_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hetrd__he2hb.html" target="_self">hetrd_he2hb</a></td><td class="desc">HETRD_HE2HB: reduces a complex Hermitian matrix A to complex Hermitian band-diagonal form AB by a unitary similarity transformation: Q**H * A * Q = AB </td></tr>
<tr id="row_6_98_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hetrf.html" target="_self">hetrf</a></td><td class="desc">HETRF: computes the factorization of a complex Hermitian matrix A using the Bunch-Kaufman diagonal pivoting method. The form of the factorization is A = U*D*U**H or A = L*D*L**H where U (or L) is a product of permutation and unit upper (lower) triangular matrices, and D is Hermitian and block diagonal with 1-by-1 and 2-by-2 diagonal blocks. This is the blocked version of the algorithm, calling Level 3 BLAS </td></tr>
<tr id="row_6_99_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hetrf__aa.html" target="_self">hetrf_aa</a></td><td class="desc">HETRF_AA: computes the factorization of a complex hermitian matrix A using the Aasen's algorithm. The form of the factorization is A = U**H*T*U or A = L*T*L**H where U (or L) is a product of permutation and unit upper (lower) triangular matrices, and T is a hermitian tridiagonal matrix. This is the blocked version of the algorithm, calling Level 3 BLAS </td></tr>
<tr id="row_6_100_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hetrf__rk.html" target="_self">hetrf_rk</a></td><td class="desc">HETRF_RK: computes the factorization of a complex Hermitian matrix A using the bounded Bunch-Kaufman (rook) diagonal pivoting method: A = P*U*D*(U**H)*(P**T) or A = P*L*D*(L**H)*(P**T), where U (or L) is unit upper (or lower) triangular matrix, U**H (or L**H) is the conjugate of U (or L), P is a permutation matrix, P**T is the transpose of P, and D is Hermitian and block diagonal with 1-by-1 and 2-by-2 diagonal blocks. This is the blocked version of the algorithm, calling Level 3 BLAS. For more information see Further Details section </td></tr>
<tr id="row_6_101_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hetrf__rook.html" target="_self">hetrf_rook</a></td><td class="desc">HETRF_ROOK: computes the factorization of a complex Hermitian matrix A using the bounded Bunch-Kaufman ("rook") diagonal pivoting method. The form of the factorization is A = U*D*U**T or A = L*D*L**T where U (or L) is a product of permutation and unit upper (lower) triangular matrices, and D is Hermitian and block diagonal with 1-by-1 and 2-by-2 diagonal blocks. This is the blocked version of the algorithm, calling Level 3 BLAS </td></tr>
<tr id="row_6_102_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hetri.html" target="_self">hetri</a></td><td class="desc">HETRI: computes the inverse of a complex Hermitian indefinite matrix A using the factorization A = U*D*U**H or A = L*D*L**H computed by CHETRF </td></tr>
<tr id="row_6_103_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hetri__rook.html" target="_self">hetri_rook</a></td><td class="desc">HETRI_ROOK: computes the inverse of a complex Hermitian indefinite matrix A using the factorization A = U*D*U**H or A = L*D*L**H computed by CHETRF_ROOK </td></tr>
<tr id="row_6_104_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hetrs.html" target="_self">hetrs</a></td><td class="desc">HETRS: solves a system of linear equations A*X = B with a complex Hermitian matrix A using the factorization A = U*D*U**H or A = L*D*L**H computed by CHETRF </td></tr>
<tr id="row_6_105_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hetrs2.html" target="_self">hetrs2</a></td><td class="desc">HETRS2: solves a system of linear equations A*X = B with a complex Hermitian matrix A using the factorization A = U*D*U**H or A = L*D*L**H computed by CHETRF and converted by CSYCONV </td></tr>
<tr id="row_6_106_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hetrs__3.html" target="_self">hetrs_3</a></td><td class="desc">HETRS_3: solves a system of linear equations A * X = B with a complex Hermitian matrix A using the factorization computed by CHETRF_RK or CHETRF_BK: A = P*U*D*(U**H)*(P**T) or A = P*L*D*(L**H)*(P**T), where U (or L) is unit upper (or lower) triangular matrix, U**H (or L**H) is the conjugate of U (or L), P is a permutation matrix, P**T is the transpose of P, and D is Hermitian and block diagonal with 1-by-1 and 2-by-2 diagonal blocks. This algorithm is using Level 3 BLAS </td></tr>
<tr id="row_6_107_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hetrs__aa.html" target="_self">hetrs_aa</a></td><td class="desc">HETRS_AA: solves a system of linear equations A*X = B with a complex hermitian matrix A using the factorization A = U**H*T*U or A = L*T*L**H computed by CHETRF_AA </td></tr>
<tr id="row_6_108_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hetrs__rook.html" target="_self">hetrs_rook</a></td><td class="desc">HETRS_ROOK: solves a system of linear equations A*X = B with a complex Hermitian matrix A using the factorization A = U*D*U**H or A = L*D*L**H computed by CHETRF_ROOK </td></tr>
<tr id="row_6_109_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hfrk.html" target="_self">hfrk</a></td><td class="desc">Level 3 BLAS like routine for C in RFP Format. HFRK: performs one of the Hermitian rank&ndash;k operations C := alpha*A*A**H + beta*C, or C := alpha*A**H*A + beta*C, where alpha and beta are real scalars, C is an n&ndash;by&ndash;n Hermitian matrix and A is an n&ndash;by&ndash;k matrix in the first case and a k&ndash;by&ndash;n matrix in the second case </td></tr>
<tr id="row_6_110_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hgeqz.html" target="_self">hgeqz</a></td><td class="desc">HGEQZ: computes the eigenvalues of a complex matrix pair (H,T), where H is an upper Hessenberg matrix and T is upper triangular, using the single-shift QZ method. Matrix pairs of this type are produced by the reduction to generalized upper Hessenberg form of a complex matrix pair (A,B): A = Q1*H*Z1**H, B = Q1*T*Z1**H, as computed by CGGHRD. If JOB='S', then the Hessenberg-triangular pair (H,T) is also reduced to generalized Schur form, H = Q*S*Z**H, T = Q*P*Z**H, where Q and Z are unitary matrices and S and P are upper triangular. Optionally, the unitary matrix Q from the generalized Schur factorization may be postmultiplied into an input matrix Q1, and the unitary matrix Z may be postmultiplied into an input matrix Z1. If Q1 and Z1 are the unitary matrices from CGGHRD that reduced the matrix pair (A,B) to generalized Hessenberg form, then the output matrices Q1*Q and Z1*Z are the unitary factors from the generalized Schur factorization of (A,B): A = (Q1*Q)*S*(Z1*Z)**H, B = (Q1*Q)*P*(Z1*Z)**H. To avoid overflow, eigenvalues of the matrix pair (H,T) (equivalently, of (A,B)) are computed as a pair of complex values (alpha,beta). If beta is nonzero, lambda = alpha / beta is an eigenvalue of the generalized nonsymmetric eigenvalue problem (GNEP) A*x = lambda*B*x and if alpha is nonzero, mu = beta / alpha is an eigenvalue of the alternate form of the GNEP mu*A*y = B*y. The values of alpha and beta for the i-th eigenvalue can be read directly from the generalized Schur form: alpha = S(i,i), beta = P(i,i). Ref: C.B. Moler Eigenvalue Problems", SIAM J. Numer. Anal., 10(1973), pp. 241&ndash;256 </td></tr>
<tr id="row_6_111_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hpcon.html" target="_self">hpcon</a></td><td class="desc">HPCON: estimates the reciprocal of the condition number of a complex Hermitian packed matrix A using the factorization A = U*D*U**H or A = L*D*L**H computed by CHPTRF. An estimate is obtained for norm(inv(A)), and the reciprocal of the condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))) </td></tr>
<tr id="row_6_112_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hpev.html" target="_self">hpev</a></td><td class="desc">HPEV: computes all the eigenvalues and, optionally, eigenvectors of a complex Hermitian matrix in packed storage </td></tr>
<tr id="row_6_113_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hpevd.html" target="_self">hpevd</a></td><td class="desc">HPEVD: computes all the eigenvalues and, optionally, eigenvectors of a complex Hermitian matrix A in packed storage. If eigenvectors are desired, it uses a divide and conquer algorithm. The divide and conquer algorithm makes very mild assumptions about floating point arithmetic. It will work on machines with a guard digit in add/subtract, or on those binary machines without guard digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2. It could conceivably fail on hexadecimal or decimal machines without guard digits, but we know of none </td></tr>
<tr id="row_6_114_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hpgst.html" target="_self">hpgst</a></td><td class="desc">HPGST: reduces a complex Hermitian-definite generalized eigenproblem to standard form, using packed storage. If ITYPE = 1, the problem is A*x = lambda*B*x, and A is overwritten by inv(U**H)*A*inv(U) or inv(L)*A*inv(L**H) If ITYPE = 2 or 3, the problem is A*B*x = lambda*x or B*A*x = lambda*x, and A is overwritten by U*A*U**H or L**H*A*L. B must have been previously factorized as U**H*U or L*L**H by CPPTRF </td></tr>
<tr id="row_6_115_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hpgv.html" target="_self">hpgv</a></td><td class="desc">HPGV: computes all the eigenvalues and, optionally, the eigenvectors of a complex generalized Hermitian-definite eigenproblem, of the form A*x=(lambda)*B*x, A*Bx=(lambda)*x, or B*A*x=(lambda)*x. Here A and B are assumed to be Hermitian, stored in packed format, and B is also positive definite </td></tr>
<tr id="row_6_116_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hpgvd.html" target="_self">hpgvd</a></td><td class="desc">HPGVD: computes all the eigenvalues and, optionally, the eigenvectors of a complex generalized Hermitian-definite eigenproblem, of the form A*x=(lambda)*B*x, A*Bx=(lambda)*x, or B*A*x=(lambda)*x. Here A and B are assumed to be Hermitian, stored in packed format, and B is also positive definite. If eigenvectors are desired, it uses a divide and conquer algorithm. The divide and conquer algorithm makes very mild assumptions about floating point arithmetic. It will work on machines with a guard digit in add/subtract, or on those binary machines without guard digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2. It could conceivably fail on hexadecimal or decimal machines without guard digits, but we know of none </td></tr>
<tr id="row_6_117_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hprfs.html" target="_self">hprfs</a></td><td class="desc">HPRFS: improves the computed solution to a system of linear equations when the coefficient matrix is Hermitian indefinite and packed, and provides error bounds and backward error estimates for the solution </td></tr>
<tr id="row_6_118_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hpsv.html" target="_self">hpsv</a></td><td class="desc">HPSV: computes the solution to a complex system of linear equations A * X = B, where A is an N-by-N Hermitian matrix stored in packed format and X and B are N-by-NRHS matrices. The diagonal pivoting method is used to factor A as A = U * D * U**H, if UPLO = 'U', or A = L * D * L**H, if UPLO = 'L', where U (or L) is a product of permutation and unit upper (lower) triangular matrices, D is Hermitian and block diagonal with 1-by-1 and 2-by-2 diagonal blocks. The factored form of A is then used to solve the system of equations A * X = B </td></tr>
<tr id="row_6_119_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hptrd.html" target="_self">hptrd</a></td><td class="desc">HPTRD: reduces a complex Hermitian matrix A stored in packed form to real symmetric tridiagonal form T by a unitary similarity transformation: Q**H * A * Q = T </td></tr>
<tr id="row_6_120_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hptrf.html" target="_self">hptrf</a></td><td class="desc">HPTRF: computes the factorization of a complex Hermitian packed matrix A using the Bunch-Kaufman diagonal pivoting method: A = U*D*U**H or A = L*D*L**H where U (or L) is a product of permutation and unit upper (lower) triangular matrices, and D is Hermitian and block diagonal with 1-by-1 and 2-by-2 diagonal blocks </td></tr>
<tr id="row_6_121_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hptri.html" target="_self">hptri</a></td><td class="desc">HPTRI: computes the inverse of a complex Hermitian indefinite matrix A in packed storage using the factorization A = U*D*U**H or A = L*D*L**H computed by CHPTRF </td></tr>
<tr id="row_6_122_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hptrs.html" target="_self">hptrs</a></td><td class="desc">HPTRS: solves a system of linear equations A*X = B with a complex Hermitian matrix A stored in packed format using the factorization A = U*D*U**H or A = L*D*L**H computed by CHPTRF </td></tr>
<tr id="row_6_123_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hsein.html" target="_self">hsein</a></td><td class="desc">HSEIN: uses inverse iteration to find specified right and/or left eigenvectors of a complex upper Hessenberg matrix H. The right eigenvector x and the left eigenvector y of the matrix H corresponding to an eigenvalue w are defined by: H * x = w * x, y**h * H = w * y**h where y**h denotes the conjugate transpose of the vector y </td></tr>
<tr id="row_6_124_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1hseqr.html" target="_self">hseqr</a></td><td class="desc">HSEQR: computes the eigenvalues of a Hessenberg matrix H and, optionally, the matrices T and Z from the Schur decomposition H = Z T Z**H, where T is an upper triangular matrix (the Schur form), and Z is the unitary matrix of Schur vectors. Optionally Z may be postmultiplied into an input unitary matrix Q so that this routine can give the Schur factorization of a matrix A which has been reduced to the Hessenberg form H by the unitary matrix Q: A = Q*H*Q**H = (QZ)*T*(QZ)**H </td></tr>
<tr id="row_6_125_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1isnan.html" target="_self">isnan</a></td><td class="desc">ISNAN: returns .TRUE. if its argument is NaN, and .FALSE. otherwise. To be replaced by the Fortran 2003 intrinsic in the future </td></tr>
<tr id="row_6_126_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1la__gbamv.html" target="_self">la_gbamv</a></td><td class="desc">LA_GBAMV: performs one of the matrix-vector operations y := alpha*abs(A)*abs(x) + beta*abs(y), or y := alpha*abs(A)**T*abs(x) + beta*abs(y), where alpha and beta are scalars, x and y are vectors and A is an m by n matrix. This function is primarily used in calculating error bounds. To protect against underflow during evaluation, components in the resulting vector are perturbed away from zero by (N+1) times the underflow threshold. To prevent unnecessarily large errors for block-structure embedded in general matrices, "symbolically" zero components are not perturbed. A zero entry is considered "symbolic" if all multiplications involved in computing that entry have at least one zero multiplicand </td></tr>
<tr id="row_6_127_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1la__gbrcond.html" target="_self">la_gbrcond</a></td><td class="desc">LA_GBRCOND: Estimates the Skeel condition number of op(A) * op2(C) where op2 is determined by CMODE as follows CMODE = 1 op2(C) = C CMODE = 0 op2(C) = I CMODE = -1 op2(C) = inv(C) The Skeel condition number cond(A) = norminf( |inv(A)||A| ) is computed by computing scaling factors R such that diag(R)*A*op2(C) is row equilibrated and computing the standard infinity-norm condition number </td></tr>
<tr id="row_6_128_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1la__gbrcond__c.html" target="_self">la_gbrcond_c</a></td><td class="desc">LA_GBRCOND_C: Computes the infinity norm condition number of op(A) * inv(diag(C)) where C is a REAL vector </td></tr>
<tr id="row_6_129_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1la__gbrpvgrw.html" target="_self">la_gbrpvgrw</a></td><td class="desc">LA_GBRPVGRW: computes the reciprocal pivot growth factor norm(A)/norm(U). The "max absolute element" norm is used. If this is much less than 1, the stability of the LU factorization of the (equilibrated) matrix A could be poor. This also means that the solution X, estimated condition numbers, and error bounds could be unreliable </td></tr>
<tr id="row_6_130_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1la__geamv.html" target="_self">la_geamv</a></td><td class="desc">LA_GEAMV: performs one of the matrix-vector operations y := alpha*abs(A)*abs(x) + beta*abs(y), or y := alpha*abs(A)**T*abs(x) + beta*abs(y), where alpha and beta are scalars, x and y are vectors and A is an m by n matrix. This function is primarily used in calculating error bounds. To protect against underflow during evaluation, components in the resulting vector are perturbed away from zero by (N+1) times the underflow threshold. To prevent unnecessarily large errors for block-structure embedded in general matrices, "symbolically" zero components are not perturbed. A zero entry is considered "symbolic" if all multiplications involved in computing that entry have at least one zero multiplicand </td></tr>
<tr id="row_6_131_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1la__gercond.html" target="_self">la_gercond</a></td><td class="desc">LA_GERCOND: estimates the Skeel condition number of op(A) * op2(C) where op2 is determined by CMODE as follows CMODE = 1 op2(C) = C CMODE = 0 op2(C) = I CMODE = -1 op2(C) = inv(C) The Skeel condition number cond(A) = norminf( |inv(A)||A| ) is computed by computing scaling factors R such that diag(R)*A*op2(C) is row equilibrated and computing the standard infinity-norm condition number </td></tr>
<tr id="row_6_132_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1la__gercond__c.html" target="_self">la_gercond_c</a></td><td class="desc">LA_GERCOND_C: computes the infinity norm condition number of op(A) * inv(diag(C)) where C is a REAL vector </td></tr>
<tr id="row_6_133_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1la__gerpvgrw.html" target="_self">la_gerpvgrw</a></td><td class="desc">LA_GERPVGRW: computes the reciprocal pivot growth factor norm(A)/norm(U). The "max absolute element" norm is used. If this is much less than 1, the stability of the LU factorization of the (equilibrated) matrix A could be poor. This also means that the solution X, estimated condition numbers, and error bounds could be unreliable </td></tr>
<tr id="row_6_134_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1la__heamv.html" target="_self">la_heamv</a></td><td class="desc">CLA_SYAMV performs the matrix-vector operation y := alpha*abs(A)*abs(x) + beta*abs(y), where alpha and beta are scalars, x and y are vectors and A is an n by n symmetric matrix. This function is primarily used in calculating error bounds. To protect against underflow during evaluation, components in the resulting vector are perturbed away from zero by (N+1) times the underflow threshold. To prevent unnecessarily large errors for block-structure embedded in general matrices, "symbolically" zero components are not perturbed. A zero entry is considered "symbolic" if all multiplications involved in computing that entry have at least one zero multiplicand </td></tr>
<tr id="row_6_135_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1la__hercond__c.html" target="_self">la_hercond_c</a></td><td class="desc">LA_HERCOND_C: computes the infinity norm condition number of op(A) * inv(diag(C)) where C is a REAL vector </td></tr>
<tr id="row_6_136_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1la__herpvgrw.html" target="_self">la_herpvgrw</a></td><td class="desc">LA_HERPVGRW: computes the reciprocal pivot growth factor norm(A)/norm(U). The "max absolute element" norm is used. If this is much less than 1, the stability of the LU factorization of the (equilibrated) matrix A could be poor. This also means that the solution X, estimated condition numbers, and error bounds could be unreliable </td></tr>
<tr id="row_6_137_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1la__lin__berr.html" target="_self">la_lin_berr</a></td><td class="desc">LA_LIN_BERR: computes componentwise relative backward error from the formula max(i) ( abs(R(i)) / ( abs(op(A_s))*abs(Y) + abs(B_s) )(i) ) where abs(Z) is the componentwise absolute value of the matrix or vector Z </td></tr>
<tr id="row_6_138_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1la__porcond.html" target="_self">la_porcond</a></td><td class="desc">LA_PORCOND: Estimates the Skeel condition number of op(A) * op2(C) where op2 is determined by CMODE as follows CMODE = 1 op2(C) = C CMODE = 0 op2(C) = I CMODE = -1 op2(C) = inv(C) The Skeel condition number cond(A) = norminf( |inv(A)||A| ) is computed by computing scaling factors R such that diag(R)*A*op2(C) is row equilibrated and computing the standard infinity-norm condition number </td></tr>
<tr id="row_6_139_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1la__porcond__c.html" target="_self">la_porcond_c</a></td><td class="desc">LA_PORCOND_C: Computes the infinity norm condition number of op(A) * inv(diag(C)) where C is a REAL vector </td></tr>
<tr id="row_6_140_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1la__porpvgrw.html" target="_self">la_porpvgrw</a></td><td class="desc">LA_PORPVGRW: computes the reciprocal pivot growth factor norm(A)/norm(U). The "max absolute element" norm is used. If this is much less than 1, the stability of the LU factorization of the (equilibrated) matrix A could be poor. This also means that the solution X, estimated condition numbers, and error bounds could be unreliable </td></tr>
<tr id="row_6_141_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1la__syamv.html" target="_self">la_syamv</a></td><td class="desc">LA_SYAMV: performs the matrix-vector operation y := alpha*abs(A)*abs(x) + beta*abs(y), where alpha and beta are scalars, x and y are vectors and A is an n by n symmetric matrix. This function is primarily used in calculating error bounds. To protect against underflow during evaluation, components in the resulting vector are perturbed away from zero by (N+1) times the underflow threshold. To prevent unnecessarily large errors for block-structure embedded in general matrices, "symbolically" zero components are not perturbed. A zero entry is considered "symbolic" if all multiplications involved in computing that entry have at least one zero multiplicand </td></tr>
<tr id="row_6_142_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1la__syrcond.html" target="_self">la_syrcond</a></td><td class="desc">LA_SYRCOND: estimates the Skeel condition number of op(A) * op2(C) where op2 is determined by CMODE as follows CMODE = 1 op2(C) = C CMODE = 0 op2(C) = I CMODE = -1 op2(C) = inv(C) The Skeel condition number cond(A) = norminf( |inv(A)||A| ) is computed by computing scaling factors R such that diag(R)*A*op2(C) is row equilibrated and computing the standard infinity-norm condition number </td></tr>
<tr id="row_6_143_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1la__syrcond__c.html" target="_self">la_syrcond_c</a></td><td class="desc">LA_SYRCOND_C: Computes the infinity norm condition number of op(A) * inv(diag(C)) where C is a REAL vector </td></tr>
<tr id="row_6_144_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1la__syrpvgrw.html" target="_self">la_syrpvgrw</a></td><td class="desc">LA_SYRPVGRW: computes the reciprocal pivot growth factor norm(A)/norm(U). The "max absolute element" norm is used. If this is much less than 1, the stability of the LU factorization of the (equilibrated) matrix A could be poor. This also means that the solution X, estimated condition numbers, and error bounds could be unreliable </td></tr>
<tr id="row_6_145_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1la__wwaddw.html" target="_self">la_wwaddw</a></td><td class="desc">LA_WWADDW: adds a vector W into a doubled-single vector (X, Y). This works for all extant IBM's hex and binary floating point arithmetic, but not for decimal </td></tr>
<tr id="row_6_146_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1labad.html" target="_self">labad</a></td><td class="desc">LABAD: takes as input the values computed by DLAMCH for underflow and overflow, and returns the square root of each of these values if the log of LARGE is sufficiently large. This subroutine is intended to identify machines with a large exponent range, such as the Crays, and redefine the underflow and overflow limits to be the square roots of the values computed by DLAMCH. This subroutine is needed because DLAMCH does not compensate for poor arithmetic in the upper half of the exponent range, as is found on a Cray </td></tr>
<tr id="row_6_147_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1labrd.html" target="_self">labrd</a></td><td class="desc">LABRD: reduces the first NB rows and columns of a complex general m by n matrix A to upper or lower real bidiagonal form by a unitary transformation Q**H * A * P, and returns the matrices X and Y which are needed to apply the transformation to the unreduced part of A. If m &gt;= n, A is reduced to upper bidiagonal form; if m &lt; n, to lower bidiagonal form. This is an auxiliary routine called by CGEBRD </td></tr>
<tr id="row_6_148_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lacgv.html" target="_self">lacgv</a></td><td class="desc">LACGV: conjugates a complex vector of length N </td></tr>
<tr id="row_6_149_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lacon.html" target="_self">lacon</a></td><td class="desc">LACON: estimates the 1-norm of a square, complex matrix A. Reverse communication is used for evaluating matrix-vector products </td></tr>
<tr id="row_6_150_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lacpy.html" target="_self">lacpy</a></td><td class="desc">LACPY: copies all or part of a two-dimensional matrix A to another matrix B </td></tr>
<tr id="row_6_151_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lacrm.html" target="_self">lacrm</a></td><td class="desc">LACRM: performs a very simple matrix-matrix multiplication: C := A * B, where A is M by N and complex; B is N by N and real; C is M by N and complex </td></tr>
<tr id="row_6_152_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lacrt.html" target="_self">lacrt</a></td><td class="desc">LACRT: performs the operation ( c s )( x ) ==&gt; ( x ) ( -s c )( y ) ( y ) where c and s are complex and the vectors x and y are complex </td></tr>
<tr id="row_6_153_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ladiv1.html" target="_self">ladiv1</a></td><td class="desc"></td></tr>
<tr id="row_6_154_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ladiv2.html" target="_self">ladiv2</a></td><td class="desc"></td></tr>
<tr id="row_6_155_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ladiv__f.html" target="_self">ladiv_f</a></td><td class="desc">LADIV_F: := X / Y, where X and Y are complex. The computation of X / Y will not overflow on an intermediary step unless the results overflows </td></tr>
<tr id="row_6_156_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ladiv__s.html" target="_self">ladiv_s</a></td><td class="desc">LADIV_S: performs complex division in real arithmetic a + i*b p + i*q = ------&mdash; c + i*d The algorithm is due to Michael Baudin and Robert L. Smith and can be found in the paper "A Robust Complex Division in Scilab" </td></tr>
<tr id="row_6_157_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laebz.html" target="_self">laebz</a></td><td class="desc">LAEBZ: contains the iteration loops which compute and use the function N(w), which is the count of eigenvalues of a symmetric tridiagonal matrix T less than or equal to its argument w. It performs a choice of two types of loops: IJOB=1, followed by IJOB=2: It takes as input a list of intervals and returns a list of sufficiently small intervals whose union contains the same eigenvalues as the union of the original intervals. The input intervals are (AB(j,1),AB(j,2)], j=1,...,MINP. The output interval (AB(j,1),AB(j,2)] will contain eigenvalues NAB(j,1)+1,...,NAB(j,2), where 1 &lt;= j &lt;= MOUT. IJOB=3: It performs a binary search in each input interval (AB(j,1),AB(j,2)] for a point w(j) such that N(w(j))=NVAL(j), and uses C(j) as the starting point of the search. If such a w(j) is found, then on output AB(j,1)=AB(j,2)=w. If no such w(j) is found, then on output (AB(j,1),AB(j,2)] will be a small interval containing the point where N(w) jumps through NVAL(j), unless that point lies outside the initial interval. Note that the intervals are in all cases half-open intervals, i.e., of the form (a,b] , which includes b but not a . To avoid underflow, the matrix should be scaled so that its largest element is no greater than overflow**(1/2) * underflow**(1/4) in absolute value. To assure the most accurate computation of small eigenvalues, the matrix should be scaled to be not much smaller than that, either. See W. Kahan "Accurate Eigenvalues of a Symmetric Tridiagonal
 Matrix", Report CS41, Computer Science Dept., Stanford University, July 21, 1966 Note: the arguments are, in general, <em>not</em> checked for unreasonable values </td></tr>
<tr id="row_6_158_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laed0.html" target="_self">laed0</a></td><td class="desc">Using the divide and conquer method, LAED0: computes all eigenvalues of a symmetric tridiagonal matrix which is one diagonal block of those from reducing a dense or band Hermitian matrix and corresponding eigenvectors of the dense or band matrix </td></tr>
<tr id="row_6_159_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laed1.html" target="_self">laed1</a></td><td class="desc">LAED1: computes the updated eigensystem of a diagonal matrix after modification by a rank-one symmetric matrix. This routine is used only for the eigenproblem which requires all eigenvalues and eigenvectors of a tridiagonal matrix. DLAED7 handles the case in which eigenvalues only or eigenvalues and eigenvectors of a full symmetric matrix (which was reduced to tridiagonal form) are desired. T = Q(in) ( D(in) + RHO * Z*Z**T ) Q**T(in) = Q(out) * D(out) * Q**T(out) where Z = Q**T*u, u is a vector of length N with ones in the CUTPNT and CUTPNT + 1 th elements and zeros elsewhere. The eigenvectors of the original matrix are stored in Q, and the eigenvalues are in D. The algorithm consists of three stages: The first stage consists of deflating the size of the problem when there are multiple eigenvalues or if there is a zero in the Z vector. For each such occurrence the dimension of the secular equation problem is reduced by one. This stage is performed by the routine DLAED2. The second stage consists of calculating the updated eigenvalues. This is done by finding the roots of the secular equation via the routine DLAED4 (as called by DLAED3). This routine also calculates the eigenvectors of the current problem. The final stage consists of computing the updated eigenvectors directly using the updated eigenvalues. The eigenvectors for the current problem are multiplied with the eigenvectors from the overall problem </td></tr>
<tr id="row_6_160_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laed4.html" target="_self">laed4</a></td><td class="desc">This subroutine computes the I-th updated eigenvalue of a symmetric rank-one modification to a diagonal matrix whose elements are given in the array d, and that D(i) &lt; D(j) for i &lt; j and that RHO &gt; 0. This is arranged by the calling routine, and is no loss in generality. The rank-one modified system is thus diag( D ) + RHO * Z * Z_transpose. where we assume the Euclidean norm of Z is 1. The method consists of approximating the rational functions in the secular equation by simpler interpolating rational functions </td></tr>
<tr id="row_6_161_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laed5.html" target="_self">laed5</a></td><td class="desc">This subroutine computes the I-th eigenvalue of a symmetric rank-one modification of a 2-by-2 diagonal matrix diag( D ) + RHO * Z * transpose(Z) . The diagonal elements in the array D are assumed to satisfy D(i) &lt; D(j) for i &lt; j . We also assume RHO &gt; 0 and that the Euclidean norm of the vector Z is one </td></tr>
<tr id="row_6_162_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laed6.html" target="_self">laed6</a></td><td class="desc">LAED6: computes the positive or negative root (closest to the origin) of z(1) z(2) z(3) f(x) = rho + ------&mdash; + -------&mdash; + ------&mdash; d(1)-x d(2)-x d(3)-x It is assumed that if ORGATI = .true. the root is between d(2) and d(3); otherwise it is between d(1) and d(2) This routine will be called by DLAED4 when necessary. In most cases, the root sought is the smallest in magnitude, though it might not be in some extremely rare situations </td></tr>
<tr id="row_6_163_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laed7.html" target="_self">laed7</a></td><td class="desc">LAED7: computes the updated eigensystem of a diagonal matrix after modification by a rank-one symmetric matrix. This routine is used only for the eigenproblem which requires all eigenvalues and optionally eigenvectors of a dense or banded Hermitian matrix that has been reduced to tridiagonal form. T = Q(in) ( D(in) + RHO * Z*Z**H ) Q**H(in) = Q(out) * D(out) * Q**H(out) where Z = Q**Hu, u is a vector of length N with ones in the CUTPNT and CUTPNT + 1 th elements and zeros elsewhere. The eigenvectors of the original matrix are stored in Q, and the eigenvalues are in D. The algorithm consists of three stages: The first stage consists of deflating the size of the problem when there are multiple eigenvalues or if there is a zero in the Z vector. For each such occurrence the dimension of the secular equation problem is reduced by one. This stage is performed by the routine SLAED2. The second stage consists of calculating the updated eigenvalues. This is done by finding the roots of the secular equation via the routine SLAED4 (as called by SLAED3). This routine also calculates the eigenvectors of the current problem. The final stage consists of computing the updated eigenvectors directly using the updated eigenvalues. The eigenvectors for the current problem are multiplied with the eigenvectors from the overall problem </td></tr>
<tr id="row_6_164_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laed8.html" target="_self">laed8</a></td><td class="desc">LAED8: merges the two sets of eigenvalues together into a single sorted set. Then it tries to deflate the size of the problem. There are two ways in which deflation can occur: when two or more eigenvalues are close together or if there is a tiny element in the Z vector. For each such occurrence the order of the related secular equation problem is reduced by one </td></tr>
<tr id="row_6_165_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laed9.html" target="_self">laed9</a></td><td class="desc">LAED9: finds the roots of the secular equation, as defined by the values in D, Z, and RHO, between KSTART and KSTOP. It makes the appropriate calls to DLAED4 and then stores the new matrix of eigenvectors for use in calculating the next level of Z vectors </td></tr>
<tr id="row_6_166_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laeda.html" target="_self">laeda</a></td><td class="desc">LAEDA: computes the Z vector corresponding to the merge step in the CURLVLth step of the merge process with TLVLS steps for the CURPBMth problem </td></tr>
<tr id="row_6_167_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laein.html" target="_self">laein</a></td><td class="desc">LAEIN: uses inverse iteration to find a right or left eigenvector corresponding to the eigenvalue W of a complex upper Hessenberg matrix H </td></tr>
<tr id="row_6_168_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laesy.html" target="_self">laesy</a></td><td class="desc">LAESY: computes the eigendecomposition of a 2-by-2 symmetric matrix ( ( A, B );( B, C ) ) provided the norm of the matrix of eigenvectors is larger than some threshold value. RT1 is the eigenvalue of larger absolute value, and RT2 of smaller absolute value. If the eigenvectors are computed, then on return ( CS1, SN1 ) is the unit eigenvector for RT1, hence [ CS1 SN1 ] . [ A B ] . [ CS1 -SN1 ] = [ RT1 0 ] [ -SN1 CS1 ] [ B C ] [ SN1 CS1 ] [ 0 RT2 ] </td></tr>
<tr id="row_6_169_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laexc.html" target="_self">laexc</a></td><td class="desc">LAEXC: swaps adjacent diagonal blocks T11 and T22 of order 1 or 2 in an upper quasi-triangular matrix T by an orthogonal similarity transformation. T must be in Schur canonical form, that is, block upper triangular with 1-by-1 and 2-by-2 diagonal blocks; each 2-by-2 diagonal block has its diagonal elements equal and its off-diagonal elements of opposite sign </td></tr>
<tr id="row_6_170_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lagtf.html" target="_self">lagtf</a></td><td class="desc">LAGTF: factorizes the matrix (T - lambda*I), where T is an n by n tridiagonal matrix and lambda is a scalar, as T - lambda*I = PLU, where P is a permutation matrix, L is a unit lower tridiagonal matrix with at most one non-zero sub-diagonal elements per column and U is an upper triangular matrix with at most two non-zero super-diagonal elements per column. The factorization is obtained by Gaussian elimination with partial pivoting and implicit row scaling. The parameter LAMBDA is included in the routine so that LAGTF may be used, in conjunction with DLAGTS, to obtain eigenvectors of T by inverse iteration </td></tr>
<tr id="row_6_171_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lagtm.html" target="_self">lagtm</a></td><td class="desc">LAGTM: performs a matrix-vector product of the form B := alpha * A * X + beta * B where A is a tridiagonal matrix of order N, B and X are N by NRHS matrices, and alpha and beta are real scalars, each of which may be 0., 1., or -1 </td></tr>
<tr id="row_6_172_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lagts.html" target="_self">lagts</a></td><td class="desc">LAGTS: may be used to solve one of the systems of equations (T - lambda*I)*x = y or (T - lambda*I)**T*x = y, where T is an n by n tridiagonal matrix, for x, following the factorization of (T - lambda*I) as (T - lambda*I) = P*L*U , by routine DLAGTF. The choice of equation to be solved is controlled by the argument JOB, and in each case there is an option to perturb zero or very small diagonal elements of U, this option being intended for use in applications such as inverse iteration </td></tr>
<tr id="row_6_173_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lahef.html" target="_self">lahef</a></td><td class="desc">LAHEF: computes a partial factorization of a complex Hermitian matrix A using the Bunch-Kaufman diagonal pivoting method. The partial factorization has the form: A = ( I U12 ) ( A11 0 ) ( I 0 ) if UPLO = 'U', or: ( 0 U22 ) ( 0 D ) ( U12**H U22**H ) A = ( L11 0 ) ( D 0 ) ( L11**H L21**H ) if UPLO = 'L' ( L21 I ) ( 0 A22 ) ( 0 I ) where the order of D is at most NB. The actual order is returned in the argument KB, and is either NB or NB-1, or N if N &lt;= NB. Note that U**H denotes the conjugate transpose of U. LAHEF is an auxiliary routine called by CHETRF. It uses blocked code (calling Level 3 BLAS) to update the submatrix A11 (if UPLO = 'U') or A22 (if UPLO = 'L') </td></tr>
<tr id="row_6_174_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lahef__aa.html" target="_self">lahef_aa</a></td><td class="desc">LAHEF_AA: factorizes a panel of a complex hermitian matrix A using the Aasen's algorithm. The panel consists of a set of NB rows of A when UPLO is U, or a set of NB columns when UPLO is L. In order to factorize the panel, the Aasen's algorithm requires the last row, or column, of the previous panel. The first row, or column, of A is set to be the first row, or column, of an identity matrix, which is used to factorize the first panel. The resulting J-th row of U, or J-th column of L, is stored in the (J-1)-th row, or column, of A (without the unit diagonals), while the diagonal and subdiagonal of A are overwritten by those of T </td></tr>
<tr id="row_6_175_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lahef__rk.html" target="_self">lahef_rk</a></td><td class="desc">LAHEF_RK: computes a partial factorization of a complex Hermitian matrix A using the bounded Bunch-Kaufman (rook) diagonal pivoting method. The partial factorization has the form: A = ( I U12 ) ( A11 0 ) ( I 0 ) if UPLO = 'U', or: ( 0 U22 ) ( 0 D ) ( U12**H U22**H ) A = ( L11 0 ) ( D 0 ) ( L11**H L21**H ) if UPLO = 'L', ( L21 I ) ( 0 A22 ) ( 0 I ) where the order of D is at most NB. The actual order is returned in the argument KB, and is either NB or NB-1, or N if N &lt;= NB. LAHEF_RK is an auxiliary routine called by CHETRF_RK. It uses blocked code (calling Level 3 BLAS) to update the submatrix A11 (if UPLO = 'U') or A22 (if UPLO = 'L') </td></tr>
<tr id="row_6_176_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lahef__rook.html" target="_self">lahef_rook</a></td><td class="desc">LAHEF_ROOK: computes a partial factorization of a complex Hermitian matrix A using the bounded Bunch-Kaufman ("rook") diagonal pivoting method. The partial factorization has the form: A = ( I U12 ) ( A11 0 ) ( I 0 ) if UPLO = 'U', or: ( 0 U22 ) ( 0 D ) ( U12**H U22**H ) A = ( L11 0 ) ( D 0 ) ( L11**H L21**H ) if UPLO = 'L' ( L21 I ) ( 0 A22 ) ( 0 I ) where the order of D is at most NB. The actual order is returned in the argument KB, and is either NB or NB-1, or N if N &lt;= NB. Note that U**H denotes the conjugate transpose of U. LAHEF_ROOK is an auxiliary routine called by CHETRF_ROOK. It uses blocked code (calling Level 3 BLAS) to update the submatrix A11 (if UPLO = 'U') or A22 (if UPLO = 'L') </td></tr>
<tr id="row_6_177_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lahqr.html" target="_self">lahqr</a></td><td class="desc">LAHQR: is an auxiliary routine called by CHSEQR to update the eigenvalues and Schur decomposition already computed by CHSEQR, by dealing with the Hessenberg submatrix in rows and columns ILO to IHI </td></tr>
<tr id="row_6_178_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laic1.html" target="_self">laic1</a></td><td class="desc">LAIC1: applies one step of incremental condition estimation in its simplest version: Let x, twonorm(x) = 1, be an approximate singular vector of an j-by-j lower triangular matrix L, such that twonorm(L*x) = sest Then LAIC1 computes sestpr, s, c such that the vector [ s*x ] xhat = [ c ] is an approximate singular vector of [ L 0 ] Lhat = [ w**H gamma ] in the sense that twonorm(Lhat*xhat) = sestpr. Depending on JOB, an estimate for the largest or smallest singular value is computed. Note that [s c]**H and sestpr**2 is an eigenpair of the system diag(sest*sest, 0) + [alpha gamma] * [ conjg(alpha) ] [ conjg(gamma) ] where alpha = x**H*w </td></tr>
<tr id="row_6_179_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laisnan.html" target="_self">laisnan</a></td><td class="desc">This routine is not for general use. It exists solely to avoid over-optimization in DISNAN. LAISNAN: checks for NaNs by comparing its two arguments for inequality. NaN is the only floating-point value where NaN != NaN returns .TRUE. To check for NaNs, pass the same variable as both arguments. A compiler must assume that the two arguments are not the same variable, and the test will not be optimized away. Interprocedural or whole-program optimization may delete this test. The ISNAN functions will be replaced by the correct Fortran 03 intrinsic once the intrinsic is widely available </td></tr>
<tr id="row_6_180_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lals0.html" target="_self">lals0</a></td><td class="desc">LALS0: applies back the multiplying factors of either the left or the right singular vector matrix of a diagonal matrix appended by a row to the right hand side matrix B in solving the least squares problem using the divide-and-conquer SVD approach. For the left singular vector matrix, three types of orthogonal matrices are involved: (1L) Givens rotations: the number of such rotations is GIVPTR; the pairs of columns/rows they were applied to are stored in GIVCOL; and the C- and S-values of these rotations are stored in GIVNUM. (2L) Permutation. The (NL+1)-st row of B is to be moved to the first row, and for J=2:N, PERM(J)-th row of B is to be moved to the J-th row. (3L) The left singular vector matrix of the remaining matrix. For the right singular vector matrix, four types of orthogonal matrices are involved: (1R) The right singular vector matrix of the remaining matrix. (2R) If SQRE = 1, one extra Givens rotation to generate the right null space. (3R) The inverse transformation of (2L). (4R) The inverse transformation of (1L) </td></tr>
<tr id="row_6_181_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lalsa.html" target="_self">lalsa</a></td><td class="desc">LALSA: is an itermediate step in solving the least squares problem by computing the SVD of the coefficient matrix in compact form (The singular vectors are computed as products of simple orthorgonal matrices.). If ICOMPQ = 0, LALSA applies the inverse of the left singular vector matrix of an upper bidiagonal matrix to the right hand side; and if ICOMPQ = 1, LALSA applies the right singular vector matrix to the right hand side. The singular vector matrices were generated in compact form by LALSA </td></tr>
<tr id="row_6_182_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lalsd.html" target="_self">lalsd</a></td><td class="desc">LALSD: uses the singular value decomposition of A to solve the least squares problem of finding X to minimize the Euclidean norm of each column of A*X-B, where A is N-by-N upper bidiagonal, and X and B are N-by-NRHS. The solution X overwrites B. The singular values of A smaller than RCOND times the largest singular value are treated as zero in solving the least squares problem; in this case a minimum norm solution is returned. The actual singular values are returned in D in ascending order. This code makes very mild assumptions about floating point arithmetic. It will work on machines with a guard digit in add/subtract, or on those binary machines without guard digits which subtract like the Cray XMP, Cray YMP, Cray C 90, or Cray 2. It could conceivably fail on hexadecimal or decimal machines without guard digits, but we know of none </td></tr>
<tr id="row_6_183_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lamrg.html" target="_self">lamrg</a></td><td class="desc">LAMRG: will create a permutation list which will merge the elements of A (which is composed of two independently sorted sets) into a single set which is sorted in ascending order </td></tr>
<tr id="row_6_184_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lamswlq.html" target="_self">lamswlq</a></td><td class="desc">LAMSWLQ: overwrites the general complex M-by-N matrix C with SIDE = 'L' SIDE = 'R' TRANS = 'N': Q * C C * Q TRANS = 'T': Q**H * C C * Q**H where Q is a complex unitary matrix defined as the product of blocked elementary reflectors computed by short wide LQ factorization (CLASWLQ) </td></tr>
<tr id="row_6_185_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lamtsqr.html" target="_self">lamtsqr</a></td><td class="desc">LAMTSQR: overwrites the general complex M-by-N matrix C with SIDE = 'L' SIDE = 'R' TRANS = 'N': Q * C C * Q TRANS = 'C': Q**H * C C * Q**H where Q is a complex unitary matrix defined as the product of blocked elementary reflectors computed by tall skinny QR factorization (CLATSQR) </td></tr>
<tr id="row_6_186_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laneg.html" target="_self">laneg</a></td><td class="desc">LANEG: computes the Sturm count, the number of negative pivots encountered while factoring tridiagonal T - sigma I = L D L^T. This implementation works directly on the factors without forming the tridiagonal matrix T. The Sturm count is also the number of eigenvalues of T less than sigma. This routine is called from DLARRB. The current routine does not use the PIVMIN parameter but rather requires IEEE-754 propagation of Infinities and NaNs. This routine also has no input range restrictions but does require default exception handling such that x/0 produces Inf when x is non-zero, and Inf/Inf produces NaN. For more information, see: Marques, Riedy, and Voemel, "Benefits of IEEE-754 Features in
 Modern Symmetric Tridiagonal Eigensolvers," SIAM Journal on Scientific Computing, v28, n5, 2006. DOI 10.1137/050641624 (Tech report version in LAWN 172 with the same title.) </td></tr>
<tr id="row_6_187_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1langb.html" target="_self">langb</a></td><td class="desc">LANGB: returns the value of the one norm, or the Frobenius norm, or the infinity norm, or the element of largest absolute value of an n by n band matrix A, with kl sub-diagonals and ku super-diagonals </td></tr>
<tr id="row_6_188_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lange.html" target="_self">lange</a></td><td class="desc">LANGE: returns the value of the one norm, or the Frobenius norm, or the infinity norm, or the element of largest absolute value of a complex matrix A </td></tr>
<tr id="row_6_189_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1langt.html" target="_self">langt</a></td><td class="desc">LANGT: returns the value of the one norm, or the Frobenius norm, or the infinity norm, or the element of largest absolute value of a complex tridiagonal matrix A </td></tr>
<tr id="row_6_190_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lanhb.html" target="_self">lanhb</a></td><td class="desc">LANHB: returns the value of the one norm, or the Frobenius norm, or the infinity norm, or the element of largest absolute value of an n by n hermitian band matrix A, with k super-diagonals </td></tr>
<tr id="row_6_191_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lanhe.html" target="_self">lanhe</a></td><td class="desc">LANHE: returns the value of the one norm, or the Frobenius norm, or the infinity norm, or the element of largest absolute value of a complex hermitian matrix A </td></tr>
<tr id="row_6_192_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lanhf.html" target="_self">lanhf</a></td><td class="desc">LANHF: returns the value of the one norm, or the Frobenius norm, or the infinity norm, or the element of largest absolute value of a complex Hermitian matrix A in RFP format </td></tr>
<tr id="row_6_193_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lanhp.html" target="_self">lanhp</a></td><td class="desc">LANHP: returns the value of the one norm, or the Frobenius norm, or the infinity norm, or the element of largest absolute value of a complex hermitian matrix A, supplied in packed form </td></tr>
<tr id="row_6_194_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lanhs.html" target="_self">lanhs</a></td><td class="desc">LANHS: returns the value of the one norm, or the Frobenius norm, or the infinity norm, or the element of largest absolute value of a Hessenberg matrix A </td></tr>
<tr id="row_6_195_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lanht.html" target="_self">lanht</a></td><td class="desc">LANHT: returns the value of the one norm, or the Frobenius norm, or the infinity norm, or the element of largest absolute value of a complex Hermitian tridiagonal matrix A </td></tr>
<tr id="row_6_196_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lansb.html" target="_self">lansb</a></td><td class="desc">LANSB: returns the value of the one norm, or the Frobenius norm, or the infinity norm, or the element of largest absolute value of an n by n symmetric band matrix A, with k super-diagonals </td></tr>
<tr id="row_6_197_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lansf.html" target="_self">lansf</a></td><td class="desc">LANSF: returns the value of the one norm, or the Frobenius norm, or the infinity norm, or the element of largest absolute value of a real symmetric matrix A in RFP format </td></tr>
<tr id="row_6_198_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lansp.html" target="_self">lansp</a></td><td class="desc">LANSP: returns the value of the one norm, or the Frobenius norm, or the infinity norm, or the element of largest absolute value of a complex symmetric matrix A, supplied in packed form </td></tr>
<tr id="row_6_199_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lanst.html" target="_self">lanst</a></td><td class="desc">LANST: returns the value of the one norm, or the Frobenius norm, or the infinity norm, or the element of largest absolute value of a real symmetric tridiagonal matrix A </td></tr>
<tr id="row_6_200_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lansy.html" target="_self">lansy</a></td><td class="desc">LANSY: returns the value of the one norm, or the Frobenius norm, or the infinity norm, or the element of largest absolute value of a complex symmetric matrix A </td></tr>
<tr id="row_6_201_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lantb.html" target="_self">lantb</a></td><td class="desc">LANTB: returns the value of the one norm, or the Frobenius norm, or the infinity norm, or the element of largest absolute value of an n by n triangular band matrix A, with ( k + 1 ) diagonals </td></tr>
<tr id="row_6_202_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lantp.html" target="_self">lantp</a></td><td class="desc">LANTP: returns the value of the one norm, or the Frobenius norm, or the infinity norm, or the element of largest absolute value of a triangular matrix A, supplied in packed form </td></tr>
<tr id="row_6_203_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lantr.html" target="_self">lantr</a></td><td class="desc">LANTR: returns the value of the one norm, or the Frobenius norm, or the infinity norm, or the element of largest absolute value of a trapezoidal or triangular matrix A </td></tr>
<tr id="row_6_204_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laorhr__col__getrfnp.html" target="_self">laorhr_col_getrfnp</a></td><td class="desc">LAORHR_COL_GETRFNP: computes the modified LU factorization without pivoting of a real general M-by-N matrix A. The factorization has the form: A - S = L * U, where: S is a m-by-n diagonal sign matrix with the diagonal D, so that D(i) = S(i,i), 1 &lt;= i &lt;= min(M,N). The diagonal D is constructed as D(i)=-SIGN(A(i,i)), where A(i,i) is the value after performing i-1 steps of Gaussian elimination. This means that the diagonal element at each step of "modified" Gaussian elimination is at least one in absolute value (so that division-by-zero not not possible during the division by the diagonal element); L is a M-by-N lower triangular matrix with unit diagonal elements (lower trapezoidal if M &gt; N); and U is a M-by-N upper triangular matrix (upper trapezoidal if M &lt; N). This routine is an auxiliary routine used in the Householder reconstruction routine DORHR_COL. In DORHR_COL, this routine is applied to an M-by-N matrix A with orthonormal columns, where each element is bounded by one in absolute value. With the choice of the matrix S above, one can show that the diagonal element at each step of Gaussian elimination is the largest (in absolute value) in the column on or below the diagonal, so that no pivoting is required for numerical stability [1]. For more details on the Householder reconstruction algorithm, including the modified LU factorization, see [1]. This is the blocked right-looking version of the algorithm, calling Level 3 BLAS to update the submatrix. To factorize a block, this routine calls the recursive routine LAORHR_COL_GETRFNP2. [1] "Reconstructing Householder vectors from tall-skinny QR", G. Ballard, J. Demmel, L. Grigori, M. Jacquelin, H.D. Nguyen, E. Solomonik, J. Parallel Distrib. Comput., vol. 85, pp. 3-31, 2015 </td></tr>
<tr id="row_6_205_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laorhr__col__getrfnp2.html" target="_self">laorhr_col_getrfnp2</a></td><td class="desc">LAORHR_COL_GETRFNP2: computes the modified LU factorization without pivoting of a real general M-by-N matrix A. The factorization has the form: A - S = L * U, where: S is a m-by-n diagonal sign matrix with the diagonal D, so that D(i) = S(i,i), 1 &lt;= i &lt;= min(M,N). The diagonal D is constructed as D(i)=-SIGN(A(i,i)), where A(i,i) is the value after performing i-1 steps of Gaussian elimination. This means that the diagonal element at each step of "modified" Gaussian elimination is at least one in absolute value (so that division-by-zero not possible during the division by the diagonal element); L is a M-by-N lower triangular matrix with unit diagonal elements (lower trapezoidal if M &gt; N); and U is a M-by-N upper triangular matrix (upper trapezoidal if M &lt; N). This routine is an auxiliary routine used in the Householder reconstruction routine DORHR_COL. In DORHR_COL, this routine is applied to an M-by-N matrix A with orthonormal columns, where each element is bounded by one in absolute value. With the choice of the matrix S above, one can show that the diagonal element at each step of Gaussian elimination is the largest (in absolute value) in the column on or below the diagonal, so that no pivoting is required for numerical stability [1]. For more details on the Householder reconstruction algorithm, including the modified LU factorization, see [1]. This is the recursive version of the LU factorization algorithm. Denote A - S by B. The algorithm divides the matrix B into four submatrices: [ B11 | B12 ] where B11 is n1 by n1, B = [ --&mdash;|--&mdash; ] B21 is (m-n1) by n1, [ B21 | B22 ] B12 is n1 by n2, B22 is (m-n1) by n2, with n1 = min(m,n)/2, n2 = n-n1. The subroutine calls itself to factor B11, solves for B21, solves for B12, updates B22, then calls itself to factor B22. For more details on the recursive LU algorithm, see [2]. LAORHR_COL_GETRFNP2 is called to factorize a block by the blocked routine DLAORHR_COL_GETRFNP, which uses blocked code calling Level 3 BLAS to update the submatrix. However, LAORHR_COL_GETRFNP2 is self-sufficient and can be used without DLAORHR_COL_GETRFNP. [1] "Reconstructing Householder vectors from tall-skinny QR", G. Ballard, J. Demmel, L. Grigori, M. Jacquelin, H.D. Nguyen, E. Solomonik, J. Parallel Distrib. Comput., vol. 85, pp. 3-31, 2015. [2] "Recursion leads to automatic variable blocking for dense linear
 algebra algorithms", F. Gustavson, IBM J. of Res. and Dev., vol. 41, no. 6, pp. 737-755, 1997 </td></tr>
<tr id="row_6_206_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lapll.html" target="_self">lapll</a></td><td class="desc">Given two column vectors X and Y, let A = ( X Y ). The subroutine first computes the QR factorization of A = Q*R, and then computes the SVD of the 2-by-2 upper triangular matrix R. The smaller singular value of R is returned in SSMIN, which is used as the measurement of the linear dependency of the vectors X and Y </td></tr>
<tr id="row_6_207_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lapmr.html" target="_self">lapmr</a></td><td class="desc">LAPMR: rearranges the rows of the M by N matrix X as specified by the permutation K(1),K(2),...,K(M) of the integers 1,...,M. If FORWRD = .TRUE., forward permutation: X(K(I),*) is moved X(I,*) for I = 1,2,...,M. If FORWRD = .FALSE., backward permutation: X(I,*) is moved to X(K(I),*) for I = 1,2,...,M </td></tr>
<tr id="row_6_208_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lapmt.html" target="_self">lapmt</a></td><td class="desc">LAPMT: rearranges the columns of the M by N matrix X as specified by the permutation K(1),K(2),...,K(N) of the integers 1,...,N. If FORWRD = .TRUE., forward permutation: X(*,K(J)) is moved X(*,J) for J = 1,2,...,N. If FORWRD = .FALSE., backward permutation: X(*,J) is moved to X(*,K(J)) for J = 1,2,...,N </td></tr>
<tr id="row_6_209_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laqgb.html" target="_self">laqgb</a></td><td class="desc">LAQGB: equilibrates a general M by N band matrix A with KL subdiagonals and KU superdiagonals using the row and scaling factors in the vectors R and C </td></tr>
<tr id="row_6_210_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laqge.html" target="_self">laqge</a></td><td class="desc">LAQGE: equilibrates a general M by N matrix A using the row and column scaling factors in the vectors R and C </td></tr>
<tr id="row_6_211_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laqhb.html" target="_self">laqhb</a></td><td class="desc">LAQHB: equilibrates an Hermitian band matrix A using the scaling factors in the vector S </td></tr>
<tr id="row_6_212_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laqhe.html" target="_self">laqhe</a></td><td class="desc">LAQHE: equilibrates a Hermitian matrix A using the scaling factors in the vector S </td></tr>
<tr id="row_6_213_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laqhp.html" target="_self">laqhp</a></td><td class="desc">LAQHP: equilibrates a Hermitian matrix A using the scaling factors in the vector S </td></tr>
<tr id="row_6_214_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laqps.html" target="_self">laqps</a></td><td class="desc">LAQPS: computes a step of QR factorization with column pivoting of a complex M-by-N matrix A by using Blas-3. It tries to factorize NB columns from A starting from the row OFFSET+1, and updates all of the matrix with Blas-3 xGEMM. In some cases, due to catastrophic cancellations, it cannot factorize NB columns. Hence, the actual number of factorized columns is returned in KB. Block A(1:OFFSET,1:N) is accordingly pivoted, but not factorized </td></tr>
<tr id="row_6_215_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laqr0.html" target="_self">laqr0</a></td><td class="desc">LAQR0: computes the eigenvalues of a Hessenberg matrix H and, optionally, the matrices T and Z from the Schur decomposition H = Z T Z**H, where T is an upper triangular matrix (the Schur form), and Z is the unitary matrix of Schur vectors. Optionally Z may be postmultiplied into an input unitary matrix Q so that this routine can give the Schur factorization of a matrix A which has been reduced to the Hessenberg form H by the unitary matrix Q: A = Q*H*Q**H = (QZ)*H*(QZ)**H </td></tr>
<tr id="row_6_216_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laqr1.html" target="_self">laqr1</a></td><td class="desc">Given a 2-by-2 or 3-by-3 matrix H, LAQR1: sets v to a scalar multiple of the first column of the product (*) K = (H - s1*I)*(H - s2*I) scaling to avoid overflows and most underflows. This is useful for starting double implicit shift bulges in the QR algorithm </td></tr>
<tr id="row_6_217_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laqr4.html" target="_self">laqr4</a></td><td class="desc">LAQR4: implements one level of recursion for CLAQR0. It is a complete implementation of the small bulge multi-shift QR algorithm. It may be called by CLAQR0 and, for large enough deflation window size, it may be called by CLAQR3. This subroutine is identical to CLAQR0 except that it calls CLAQR2 instead of CLAQR3. LAQR4 computes the eigenvalues of a Hessenberg matrix H and, optionally, the matrices T and Z from the Schur decomposition H = Z T Z**H, where T is an upper triangular matrix (the Schur form), and Z is the unitary matrix of Schur vectors. Optionally Z may be postmultiplied into an input unitary matrix Q so that this routine can give the Schur factorization of a matrix A which has been reduced to the Hessenberg form H by the unitary matrix Q: A = Q*H*Q**H = (QZ)*H*(QZ)**H </td></tr>
<tr id="row_6_218_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laqr5.html" target="_self">laqr5</a></td><td class="desc">LAQR5: called by CLAQR0 performs a single small-bulge multi-shift QR sweep </td></tr>
<tr id="row_6_219_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laqsb.html" target="_self">laqsb</a></td><td class="desc">LAQSB: equilibrates a symmetric band matrix A using the scaling factors in the vector S </td></tr>
<tr id="row_6_220_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laqsp.html" target="_self">laqsp</a></td><td class="desc">LAQSP: equilibrates a symmetric matrix A using the scaling factors in the vector S </td></tr>
<tr id="row_6_221_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laqsy.html" target="_self">laqsy</a></td><td class="desc">LAQSY: equilibrates a symmetric matrix A using the scaling factors in the vector S </td></tr>
<tr id="row_6_222_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laqtr.html" target="_self">laqtr</a></td><td class="desc">LAQTR: solves the real quasi-triangular system op(T)*p = scale*c, if LREAL = .TRUE. or the complex quasi-triangular systems op(T + iB)*(p+iq) = scale*(c+id), if LREAL = .FALSE. in real arithmetic, where T is upper quasi-triangular. If LREAL = .FALSE., then the first diagonal block of T must be 1 by 1, B is the specially structured matrix B = [ b(1) b(2) ... b(n) ] [ w ] [ w ] [ . ] [ w ] op(A) = A or A**T, A**T denotes the transpose of matrix A. On input, X = [ c ]. On output, X = [ p ]. [ d ] [ q ] This subroutine is designed for the condition number estimation in routine DTRSNA </td></tr>
<tr id="row_6_223_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laqz0.html" target="_self">laqz0</a></td><td class="desc">LAQZ0: computes the eigenvalues of a matrix pair (H,T), where H is an upper Hessenberg matrix and T is upper triangular, using the double-shift QZ method. Matrix pairs of this type are produced by the reduction to generalized upper Hessenberg form of a matrix pair (A,B): A = Q1*H*Z1**H, B = Q1*T*Z1**H, as computed by CGGHRD. If JOB='S', then the Hessenberg-triangular pair (H,T) is also reduced to generalized Schur form, H = Q*S*Z**H, T = Q*P*Z**H, where Q and Z are unitary matrices, P and S are an upper triangular matrices. Optionally, the unitary matrix Q from the generalized Schur factorization may be postmultiplied into an input matrix Q1, and the unitary matrix Z may be postmultiplied into an input matrix Z1. If Q1 and Z1 are the unitary matrices from CGGHRD that reduced the matrix pair (A,B) to generalized upper Hessenberg form, then the output matrices Q1*Q and Z1*Z are the unitary factors from the generalized Schur factorization of (A,B): A = (Q1*Q)*S*(Z1*Z)**H, B = (Q1*Q)*P*(Z1*Z)**H. To avoid overflow, eigenvalues of the matrix pair (H,T) (equivalently, of (A,B)) are computed as a pair of values (alpha,beta), where alpha is complex and beta real. If beta is nonzero, lambda = alpha / beta is an eigenvalue of the generalized nonsymmetric eigenvalue problem (GNEP) A*x = lambda*B*x and if alpha is nonzero, mu = beta / alpha is an eigenvalue of the alternate form of the GNEP mu*A*y = B*y. Eigenvalues can be read directly from the generalized Schur form: alpha = S(i,i), beta = P(i,i). Ref: C.B. Moler Eigenvalue Problems", SIAM J. Numer. Anal., 10(1973),
 pp. 241&amp;ndash;256.
 Ref: B. Kagstrom, D. Kressner, "Multishift Variants of the QZ Algorithm with Aggressive Early Deflation", SIAM J. Numer.
 Anal., 29(2006), pp. 199&amp;ndash;227.
 Ref: T. Steel, D. Camps, K. Meerbergen, R. Vandebril "A multishift, multipole rational QZ method with agressive early deflation" </td></tr>
<tr id="row_6_224_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laqz1.html" target="_self">laqz1</a></td><td class="desc">LAQZ1: chases a 1x1 shift bulge in a matrix pencil down a single position </td></tr>
<tr id="row_6_225_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laqz4.html" target="_self">laqz4</a></td><td class="desc">LAQZ4: Executes a single multishift QZ sweep </td></tr>
<tr id="row_6_226_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lar1v.html" target="_self">lar1v</a></td><td class="desc">LAR1V: computes the (scaled) r-th column of the inverse of the sumbmatrix in rows B1 through BN of the tridiagonal matrix L D L**T - sigma I. When sigma is close to an eigenvalue, the computed vector is an accurate eigenvector. Usually, r corresponds to the index where the eigenvector is largest in magnitude. The following steps accomplish this computation : (a) Stationary qd transform, L D L**T - sigma I = L(+) D(+) L(+)**T, (b) Progressive qd transform, L D L**T - sigma I = U(-) D(-) U(-)**T, (c) Computation of the diagonal elements of the inverse of L D L**T - sigma I by combining the above transforms, and choosing r as the index where the diagonal of the inverse is (one of the) largest in magnitude. (d) Computation of the (scaled) r-th column of the inverse using the twisted factorization obtained by combining the top part of the the stationary and the bottom part of the progressive transform </td></tr>
<tr id="row_6_227_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lar2v.html" target="_self">lar2v</a></td><td class="desc">LAR2V: applies a vector of complex plane rotations with real cosines from both sides to a sequence of 2-by-2 complex Hermitian matrices, defined by the elements of the vectors x, y and z. For i = 1,2,...,n ( x(i) z(i) ) := ( conjg(z(i)) y(i) ) ( c(i) conjg(s(i)) ) ( x(i) z(i) ) ( c(i) -conjg(s(i)) ) ( -s(i) c(i) ) ( conjg(z(i)) y(i) ) ( s(i) c(i) ) </td></tr>
<tr id="row_6_228_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1larcm.html" target="_self">larcm</a></td><td class="desc">LARCM: performs a very simple matrix-matrix multiplication: C := A * B, where A is M by M and real; B is M by N and complex; C is M by N and complex </td></tr>
<tr id="row_6_229_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1larf.html" target="_self">larf</a></td><td class="desc">LARF: applies a complex elementary reflector H to a complex M-by-N matrix C, from either the left or the right. H is represented in the form H = I - tau * v * v**H where tau is a complex scalar and v is a complex vector. If tau = 0, then H is taken to be the unit matrix. To apply H**H (the conjugate transpose of H), supply conjg(tau) instead tau </td></tr>
<tr id="row_6_230_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1larfb.html" target="_self">larfb</a></td><td class="desc">LARFB: applies a complex block reflector H or its transpose H**H to a complex M-by-N matrix C, from either the left or the right </td></tr>
<tr id="row_6_231_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1larfb__gett.html" target="_self">larfb_gett</a></td><td class="desc">LARFB_GETT: applies a complex Householder block reflector H from the left to a complex (K+M)-by-N "triangular-pentagonal" matrix composed of two block matrices: an upper trapezoidal K-by-N matrix A stored in the array A, and a rectangular M-by-(N-K) matrix B, stored in the array B. The block reflector H is stored in a compact WY-representation, where the elementary reflectors are in the arrays A, B and T. See Further Details section </td></tr>
<tr id="row_6_232_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1larfg.html" target="_self">larfg</a></td><td class="desc">LARFG: generates a complex elementary reflector H of order n, such that H**H * ( alpha ) = ( beta ), H**H * H = I. ( x ) ( 0 ) where alpha and beta are scalars, with beta real, and x is an (n-1)-element complex vector. H is represented in the form H = I - tau * ( 1 ) * ( 1 v**H ) , ( v ) where tau is a complex scalar and v is a complex (n-1)-element vector. Note that H is not hermitian. If the elements of x are all zero and alpha is real, then tau = 0 and H is taken to be the unit matrix. Otherwise 1 &lt;= real(tau) &lt;= 2 and abs(tau-1) &lt;= 1 </td></tr>
<tr id="row_6_233_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1larfgp.html" target="_self">larfgp</a></td><td class="desc">LARFGP: generates a complex elementary reflector H of order n, such that H**H * ( alpha ) = ( beta ), H**H * H = I. ( x ) ( 0 ) where alpha and beta are scalars, beta is real and non-negative, and x is an (n-1)-element complex vector. H is represented in the form H = I - tau * ( 1 ) * ( 1 v**H ) , ( v ) where tau is a complex scalar and v is a complex (n-1)-element vector. Note that H is not hermitian. If the elements of x are all zero and alpha is real, then tau = 0 and H is taken to be the unit matrix </td></tr>
<tr id="row_6_234_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1larft.html" target="_self">larft</a></td><td class="desc">LARFT: forms the triangular factor T of a complex block reflector H of order n, which is defined as a product of k elementary reflectors. If DIRECT = 'F', H = H(1) H(2) . . . H(k) and T is upper triangular; If DIRECT = 'B', H = H(k) . . . H(2) H(1) and T is lower triangular. If STOREV = 'C', the vector which defines the elementary reflector H(i) is stored in the i-th column of the array V, and H = I - V * T * V**H If STOREV = 'R', the vector which defines the elementary reflector H(i) is stored in the i-th row of the array V, and H = I - V**H * T * V </td></tr>
<tr id="row_6_235_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1larfy.html" target="_self">larfy</a></td><td class="desc">LARFY: applies an elementary reflector, or Householder matrix, H, to an n x n Hermitian matrix C, from both the left and the right. H is represented in the form H = I - tau * v * v' where tau is a scalar and v is a vector. If tau is zero, then H is taken to be the unit matrix </td></tr>
<tr id="row_6_236_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1largv.html" target="_self">largv</a></td><td class="desc">LARGV: generates a vector of complex plane rotations with real cosines, determined by elements of the complex vectors x and y. For i = 1,2,...,n ( c(i) s(i) ) ( x(i) ) = ( r(i) ) ( -conjg(s(i)) c(i) ) ( y(i) ) = ( 0 ) where c(i)**2 + ABS(s(i))**2 = 1 The following conventions are used (these are the same as in CLARTG, but differ from the BLAS1 routine CROTG): If y(i)=0, then c(i)=1 and s(i)=0. If x(i)=0, then c(i)=0 and s(i) is chosen so that r(i) is real </td></tr>
<tr id="row_6_237_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1larnv.html" target="_self">larnv</a></td><td class="desc">LARNV: returns a vector of n random complex numbers from a uniform or normal distribution </td></tr>
<tr id="row_6_238_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1larra.html" target="_self">larra</a></td><td class="desc">Compute the splitting points with threshold SPLTOL. LARRA: sets any "small" off-diagonal elements to zero </td></tr>
<tr id="row_6_239_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1larrb.html" target="_self">larrb</a></td><td class="desc">Given the relatively robust representation(RRR) L D L^T, LARRB: does "limited" bisection to refine the eigenvalues of L D L^T, W( IFIRST-OFFSET ) through W( ILAST-OFFSET ), to more accuracy. Initial guesses for these eigenvalues are input in W, the corresponding estimate of the error in these guesses and their gaps are input in WERR and WGAP, respectively. During bisection, intervals [left, right] are maintained by storing their mid-points and semi-widths in the arrays W and WERR respectively </td></tr>
<tr id="row_6_240_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1larrc.html" target="_self">larrc</a></td><td class="desc">Find the number of eigenvalues of the symmetric tridiagonal matrix T that are in the interval (VL,VU] if JOBT = 'T', and of L D L^T if JOBT = 'L' </td></tr>
<tr id="row_6_241_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1larrd.html" target="_self">larrd</a></td><td class="desc">LARRD: computes the eigenvalues of a symmetric tridiagonal matrix T to suitable accuracy. This is an auxiliary code to be called from DSTEMR. The user may ask for all eigenvalues, all eigenvalues in the half-open interval (VL, VU], or the IL-th through IU-th eigenvalues. To avoid overflow, the matrix must be scaled so that its largest element is no greater than overflow**(1/2) * underflow**(1/4) in absolute value, and for greatest accuracy, it should not be much smaller than that. See W. Kahan "Accurate Eigenvalues of a Symmetric Tridiagonal
 Matrix", Report CS41, Computer Science Dept., Stanford University, July 21, 1966 </td></tr>
<tr id="row_6_242_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1larre.html" target="_self">larre</a></td><td class="desc">To find the desired eigenvalues of a given real symmetric tridiagonal matrix T, LARRE: sets any "small" off-diagonal elements to zero, and for each unreduced block T_i, it finds (a) a suitable shift at one end of the block's spectrum, (b) the base representation, T_i - sigma_i I = L_i D_i L_i^T, and (c) eigenvalues of each L_i D_i L_i^T. The representations and eigenvalues found are then used by DSTEMR to compute the eigenvectors of T. The accuracy varies depending on whether bisection is used to find a few eigenvalues or the dqds algorithm (subroutine DLASQ2) to conpute all and then discard any unwanted one. As an added benefit, LARRE also outputs the n Gerschgorin intervals for the matrices L_i D_i L_i^T </td></tr>
<tr id="row_6_243_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1larrf.html" target="_self">larrf</a></td><td class="desc">Given the initial representation L D L^T and its cluster of close eigenvalues (in a relative measure), W( CLSTRT ), W( CLSTRT+1 ), ... W( CLEND ), LARRF: finds a new relatively robust representation L D L^T - SIGMA I = L(+) D(+) L(+)^T such that at least one of the eigenvalues of L(+) D(+) L(+)^T is relatively isolated </td></tr>
<tr id="row_6_244_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1larrj.html" target="_self">larrj</a></td><td class="desc">Given the initial eigenvalue approximations of T, LARRJ: does bisection to refine the eigenvalues of T, W( IFIRST-OFFSET ) through W( ILAST-OFFSET ), to more accuracy. Initial guesses for these eigenvalues are input in W, the corresponding estimate of the error in these guesses in WERR. During bisection, intervals [left, right] are maintained by storing their mid-points and semi-widths in the arrays W and WERR respectively </td></tr>
<tr id="row_6_245_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1larrk.html" target="_self">larrk</a></td><td class="desc">LARRK: computes one eigenvalue of a symmetric tridiagonal matrix T to suitable accuracy. This is an auxiliary code to be called from DSTEMR. To avoid overflow, the matrix must be scaled so that its largest element is no greater than overflow**(1/2) * underflow**(1/4) in absolute value, and for greatest accuracy, it should not be much smaller than that. See W. Kahan "Accurate Eigenvalues of a Symmetric Tridiagonal
 Matrix", Report CS41, Computer Science Dept., Stanford University, July 21, 1966 </td></tr>
<tr id="row_6_246_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1larrr.html" target="_self">larrr</a></td><td class="desc">Perform tests to decide whether the symmetric tridiagonal matrix T warrants expensive computations which guarantee high relative accuracy in the eigenvalues </td></tr>
<tr id="row_6_247_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1larrv.html" target="_self">larrv</a></td><td class="desc">LARRV: computes the eigenvectors of the tridiagonal matrix T = L D L**T given L, D and APPROXIMATIONS to the eigenvalues of L D L**T. The input eigenvalues should have been computed by SLARRE </td></tr>
<tr id="row_6_248_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lartg.html" target="_self">lartg</a></td><td class="desc">! </td></tr>
<tr id="row_6_249_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lartgp.html" target="_self">lartgp</a></td><td class="desc">LARTGP: generates a plane rotation so that [ CS SN ] . [ F ] = [ R ] where CS**2 + SN**2 = 1. [ -SN CS ] [ G ] [ 0 ] This is a slower, more accurate version of the Level 1 BLAS routine DROTG, with the following other differences: F and G are unchanged on return. If G=0, then CS=(+/-)1 and SN=0. If F=0 and (G .ne. 0), then CS=0 and SN=(+/-)1. The sign is chosen so that R &gt;= 0 </td></tr>
<tr id="row_6_250_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lartgs.html" target="_self">lartgs</a></td><td class="desc">LARTGS: generates a plane rotation designed to introduce a bulge in Golub-Reinsch-style implicit QR iteration for the bidiagonal SVD problem. X and Y are the top-row entries, and SIGMA is the shift. The computed CS and SN define a plane rotation satisfying [ CS SN ] . [ X^2 - SIGMA ] = [ R ], [ -SN CS ] [ X * Y ] [ 0 ] with R nonnegative. If X^2 - SIGMA and X * Y are 0, then the rotation is by PI/2 </td></tr>
<tr id="row_6_251_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lartv.html" target="_self">lartv</a></td><td class="desc">LARTV: applies a vector of complex plane rotations with real cosines to elements of the complex vectors x and y. For i = 1,2,...,n ( x(i) ) := ( c(i) s(i) ) ( x(i) ) ( y(i) ) ( -conjg(s(i)) c(i) ) ( y(i) ) </td></tr>
<tr id="row_6_252_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laruv.html" target="_self">laruv</a></td><td class="desc">LARUV: returns a vector of n random real numbers from a uniform (0,1) distribution (n &lt;= 128). This is an auxiliary routine called by DLARNV and ZLARNV </td></tr>
<tr id="row_6_253_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1larz.html" target="_self">larz</a></td><td class="desc">LARZ: applies a complex elementary reflector H to a complex M-by-N matrix C, from either the left or the right. H is represented in the form H = I - tau * v * v**H where tau is a complex scalar and v is a complex vector. If tau = 0, then H is taken to be the unit matrix. To apply H**H (the conjugate transpose of H), supply conjg(tau) instead tau. H is a product of k elementary reflectors as returned by CTZRZF </td></tr>
<tr id="row_6_254_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1larzb.html" target="_self">larzb</a></td><td class="desc">LARZB: applies a complex block reflector H or its transpose H**H to a complex distributed M-by-N C from the left or the right. Currently, only STOREV = 'R' and DIRECT = 'B' are supported </td></tr>
<tr id="row_6_255_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1larzt.html" target="_self">larzt</a></td><td class="desc">LARZT: forms the triangular factor T of a complex block reflector H of order &gt; n, which is defined as a product of k elementary reflectors. If DIRECT = 'F', H = H(1) H(2) . . . H(k) and T is upper triangular; If DIRECT = 'B', H = H(k) . . . H(2) H(1) and T is lower triangular. If STOREV = 'C', the vector which defines the elementary reflector H(i) is stored in the i-th column of the array V, and H = I - V * T * V**H If STOREV = 'R', the vector which defines the elementary reflector H(i) is stored in the i-th row of the array V, and H = I - V**H * T * V Currently, only STOREV = 'R' and DIRECT = 'B' are supported </td></tr>
<tr id="row_6_256_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lascl.html" target="_self">lascl</a></td><td class="desc">LASCL: multiplies the M by N complex matrix A by the real scalar CTO/CFROM. This is done without over/underflow as long as the final result CTO*A(I,J)/CFROM does not over/underflow. TYPE specifies that A may be full, upper triangular, lower triangular, upper Hessenberg, or banded </td></tr>
<tr id="row_6_257_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lasd0.html" target="_self">lasd0</a></td><td class="desc">Using a divide and conquer approach, LASD0: computes the singular value decomposition (SVD) of a real upper bidiagonal N-by-M matrix B with diagonal D and offdiagonal E, where M = N + SQRE. The algorithm computes orthogonal matrices U and VT such that B = U * S * VT. The singular values S are overwritten on D. A related subroutine, DLASDA, computes only the singular values, and optionally, the singular vectors in compact form </td></tr>
<tr id="row_6_258_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lasd1.html" target="_self">lasd1</a></td><td class="desc">LASD1: computes the SVD of an upper bidiagonal N-by-M matrix B, where N = NL + NR + 1 and M = N + SQRE. LASD1 is called from DLASD0. A related subroutine DLASD7 handles the case in which the singular values (and the singular vectors in factored form) are desired. LASD1 computes the SVD as follows: ( D1(in) 0 0 0 ) B = U(in) * ( Z1**T a Z2**T b ) * VT(in) ( 0 0 D2(in) 0 ) = U(out) * ( D(out) 0) * VT(out) where Z**T = (Z1**T a Z2**T b) = u**T VT**T, and u is a vector of dimension M with ALPHA and BETA in the NL+1 and NL+2 th entries and zeros elsewhere; and the entry b is empty if SQRE = 0. The left singular vectors of the original matrix are stored in U, and the transpose of the right singular vectors are stored in VT, and the singular values are in D. The algorithm consists of three stages: The first stage consists of deflating the size of the problem when there are multiple singular values or when there are zeros in the Z vector. For each such occurrence the dimension of the secular equation problem is reduced by one. This stage is performed by the routine DLASD2. The second stage consists of calculating the updated singular values. This is done by finding the square roots of the roots of the secular equation via the routine DLASD4 (as called by DLASD3). This routine also calculates the singular vectors of the current problem. The final stage consists of computing the updated singular vectors directly using the updated singular values. The singular vectors for the current problem are multiplied with the singular vectors from the overall problem </td></tr>
<tr id="row_6_259_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lasd4.html" target="_self">lasd4</a></td><td class="desc">This subroutine computes the square root of the I-th updated eigenvalue of a positive symmetric rank-one modification to a positive diagonal matrix whose entries are given as the squares of the corresponding entries in the array d, and that 0 &lt;= D(i) &lt; D(j) for i &lt; j and that RHO &gt; 0. This is arranged by the calling routine, and is no loss in generality. The rank-one modified system is thus diag( D ) * diag( D ) + RHO * Z * Z_transpose. where we assume the Euclidean norm of Z is 1. The method consists of approximating the rational functions in the secular equation by simpler interpolating rational functions </td></tr>
<tr id="row_6_260_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lasd5.html" target="_self">lasd5</a></td><td class="desc">This subroutine computes the square root of the I-th eigenvalue of a positive symmetric rank-one modification of a 2-by-2 diagonal matrix diag( D ) * diag( D ) + RHO * Z * transpose(Z) . The diagonal entries in the array D are assumed to satisfy 0 &lt;= D(i) &lt; D(j) for i &lt; j . We also assume RHO &gt; 0 and that the Euclidean norm of the vector Z is one </td></tr>
<tr id="row_6_261_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lasd6.html" target="_self">lasd6</a></td><td class="desc">LASD6: computes the SVD of an updated upper bidiagonal matrix B obtained by merging two smaller ones by appending a row. This routine is used only for the problem which requires all singular values and optionally singular vector matrices in factored form. B is an N-by-M matrix with N = NL + NR + 1 and M = N + SQRE. A related subroutine, DLASD1, handles the case in which all singular values and singular vectors of the bidiagonal matrix are desired. LASD6 computes the SVD as follows: ( D1(in) 0 0 0 ) B = U(in) * ( Z1**T a Z2**T b ) * VT(in) ( 0 0 D2(in) 0 ) = U(out) * ( D(out) 0) * VT(out) where Z**T = (Z1**T a Z2**T b) = u**T VT**T, and u is a vector of dimension M with ALPHA and BETA in the NL+1 and NL+2 th entries and zeros elsewhere; and the entry b is empty if SQRE = 0. The singular values of B can be computed using D1, D2, the first components of all the right singular vectors of the lower block, and the last components of all the right singular vectors of the upper block. These components are stored and updated in VF and VL, respectively, in LASD6. Hence U and VT are not explicitly referenced. The singular values are stored in D. The algorithm consists of two stages: The first stage consists of deflating the size of the problem when there are multiple singular values or if there is a zero in the Z vector. For each such occurrence the dimension of the secular equation problem is reduced by one. This stage is performed by the routine DLASD7. The second stage consists of calculating the updated singular values. This is done by finding the roots of the secular equation via the routine DLASD4 (as called by DLASD8). This routine also updates VF and VL and computes the distances between the updated singular values and the old singular values. LASD6 is called from DLASDA </td></tr>
<tr id="row_6_262_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lasd7.html" target="_self">lasd7</a></td><td class="desc">LASD7: merges the two sets of singular values together into a single sorted set. Then it tries to deflate the size of the problem. There are two ways in which deflation can occur: when two or more singular values are close together or if there is a tiny entry in the Z vector. For each such occurrence the order of the related secular equation problem is reduced by one. LASD7 is called from DLASD6 </td></tr>
<tr id="row_6_263_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lasd8.html" target="_self">lasd8</a></td><td class="desc">LASD8: finds the square roots of the roots of the secular equation, as defined by the values in DSIGMA and Z. It makes the appropriate calls to DLASD4, and stores, for each element in D, the distance to its two nearest poles (elements in DSIGMA). It also updates the arrays VF and VL, the first and last components of all the right singular vectors of the original bidiagonal matrix. LASD8 is called from DLASD6 </td></tr>
<tr id="row_6_264_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lasda.html" target="_self">lasda</a></td><td class="desc">Using a divide and conquer approach, LASDA: computes the singular value decomposition (SVD) of a real upper bidiagonal N-by-M matrix B with diagonal D and offdiagonal E, where M = N + SQRE. The algorithm computes the singular values in the SVD B = U * S * VT. The orthogonal matrices U and VT are optionally computed in compact form. A related subroutine, DLASD0, computes the singular values and the singular vectors in explicit form </td></tr>
<tr id="row_6_265_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lasdq.html" target="_self">lasdq</a></td><td class="desc">LASDQ: computes the singular value decomposition (SVD) of a real (upper or lower) bidiagonal matrix with diagonal D and offdiagonal E, accumulating the transformations if desired. Letting B denote the input bidiagonal matrix, the algorithm computes orthogonal matrices Q and P such that B = Q * S * P**T (P**T denotes the transpose of P). The singular values S are overwritten on D. The input matrix U is changed to U * Q if desired. The input matrix VT is changed to P**T * VT if desired. The input matrix C is changed to Q**T * C if desired. See "Computing  Small Singular Values of Bidiagonal Matrices With
 Guaranteed High Relative Accuracy," by J. Demmel and W. Kahan, LAPACK Working Note #3, for a detailed description of the algorithm </td></tr>
<tr id="row_6_266_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laset.html" target="_self">laset</a></td><td class="desc">LASET: initializes a 2-D array A to BETA on the diagonal and ALPHA on the offdiagonals </td></tr>
<tr id="row_6_267_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lasq1.html" target="_self">lasq1</a></td><td class="desc">LASQ1: computes the singular values of a real N-by-N bidiagonal matrix with diagonal D and off-diagonal E. The singular values are computed to high relative accuracy, in the absence of denormalization, underflow and overflow. The algorithm was first presented in "Accurate singular values and differential qd algorithms" by K. V. Fernando and B. N. Parlett, Numer. Math., Vol-67, No. 2, pp. 191-230, 1994, and the present implementation is described in "An implementation of
 the dqds Algorithm (Positive Case)", LAPACK Working Note </td></tr>
<tr id="row_6_268_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lasq4.html" target="_self">lasq4</a></td><td class="desc">LASQ4: computes an approximation TAU to the smallest eigenvalue using values of d from the previous transform </td></tr>
<tr id="row_6_269_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lasq5.html" target="_self">lasq5</a></td><td class="desc">LASQ5: computes one dqds transform in ping-pong form, one version for IEEE machines another for non IEEE machines </td></tr>
<tr id="row_6_270_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lasq6.html" target="_self">lasq6</a></td><td class="desc">LASQ6: computes one dqd (shift equal to zero) transform in ping-pong form, with protection against underflow and overflow </td></tr>
<tr id="row_6_271_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lasr.html" target="_self">lasr</a></td><td class="desc">LASR: applies a sequence of real plane rotations to a complex matrix A, from either the left or the right. When SIDE = 'L', the transformation takes the form A := P*A and when SIDE = 'R', the transformation takes the form A := A*P**T where P is an orthogonal matrix consisting of a sequence of z plane rotations, with z = M when SIDE = 'L' and z = N when SIDE = 'R', and P**T is the transpose of P. When DIRECT = 'F' (Forward sequence), then P = P(z-1) * ... * P(2) * P(1) and when DIRECT = 'B' (Backward sequence), then P = P(1) * P(2) * ... * P(z-1) where P(k) is a plane rotation matrix defined by the 2-by-2 rotation R(k) = ( c(k) s(k) ) = ( -s(k) c(k) ). When PIVOT = 'V' (Variable pivot), the rotation is performed for the plane (k,k+1), i.e., P(k) has the form P(k) = ( 1 ) ( ... ) ( 1 ) ( c(k) s(k) ) ( -s(k) c(k) ) ( 1 ) ( ... ) ( 1 ) where R(k) appears as a rank-2 modification to the identity matrix in rows and columns k and k+1. When PIVOT = 'T' (Top pivot), the rotation is performed for the plane (1,k+1), so P(k) has the form P(k) = ( c(k) s(k) ) ( 1 ) ( ... ) ( 1 ) ( -s(k) c(k) ) ( 1 ) ( ... ) ( 1 ) where R(k) appears in rows and columns 1 and k+1. Similarly, when PIVOT = 'B' (Bottom pivot), the rotation is performed for the plane (k,z), giving P(k) the form P(k) = ( 1 ) ( ... ) ( 1 ) ( c(k) s(k) ) ( 1 ) ( ... ) ( 1 ) ( -s(k) c(k) ) where R(k) appears in rows and columns k and z. The rotations are performed without ever forming P(k) explicitly </td></tr>
<tr id="row_6_272_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lasrt.html" target="_self">lasrt</a></td><td class="desc">Sort the numbers in D in increasing order (if ID = 'I') or in decreasing order (if ID = 'D' ). Use Quick Sort, reverting to Insertion sort on arrays of size &lt;= 20. Dimension of STACK limits N to about 2**32 </td></tr>
<tr id="row_6_273_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lassq.html" target="_self">lassq</a></td><td class="desc">! </td></tr>
<tr id="row_6_274_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laswlq.html" target="_self">laswlq</a></td><td class="desc">LASWLQ: computes a blocked Tall-Skinny LQ factorization of a complex M-by-N matrix A for M &lt;= N: A = ( L 0 ) * Q, where: Q is a n-by-N orthogonal matrix, stored on exit in an implicit form in the elements above the diagonal of the array A and in the elements of the array T; L is a lower-triangular M-by-M matrix stored on exit in the elements on and below the diagonal of the array A. 0 is a M-by-(N-M) zero matrix, if M &lt; N, and is not stored </td></tr>
<tr id="row_6_275_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1laswp.html" target="_self">laswp</a></td><td class="desc">LASWP: performs a series of row interchanges on the matrix A. One row interchange is initiated for each of rows K1 through K2 of A </td></tr>
<tr id="row_6_276_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lasyf.html" target="_self">lasyf</a></td><td class="desc">LASYF: computes a partial factorization of a complex symmetric matrix A using the Bunch-Kaufman diagonal pivoting method. The partial factorization has the form: A = ( I U12 ) ( A11 0 ) ( I 0 ) if UPLO = 'U', or: ( 0 U22 ) ( 0 D ) ( U12**T U22**T ) A = ( L11 0 ) ( D 0 ) ( L11**T L21**T ) if UPLO = 'L' ( L21 I ) ( 0 A22 ) ( 0 I ) where the order of D is at most NB. The actual order is returned in the argument KB, and is either NB or NB-1, or N if N &lt;= NB. Note that U**T denotes the transpose of U. LASYF is an auxiliary routine called by CSYTRF. It uses blocked code (calling Level 3 BLAS) to update the submatrix A11 (if UPLO = 'U') or A22 (if UPLO = 'L') </td></tr>
<tr id="row_6_277_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lasyf__aa.html" target="_self">lasyf_aa</a></td><td class="desc">DLATRF_AA factorizes a panel of a complex symmetric matrix A using the Aasen's algorithm. The panel consists of a set of NB rows of A when UPLO is U, or a set of NB columns when UPLO is L. In order to factorize the panel, the Aasen's algorithm requires the last row, or column, of the previous panel. The first row, or column, of A is set to be the first row, or column, of an identity matrix, which is used to factorize the first panel. The resulting J-th row of U, or J-th column of L, is stored in the (J-1)-th row, or column, of A (without the unit diagonals), while the diagonal and subdiagonal of A are overwritten by those of T </td></tr>
<tr id="row_6_278_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lasyf__rk.html" target="_self">lasyf_rk</a></td><td class="desc">LASYF_RK: computes a partial factorization of a complex symmetric matrix A using the bounded Bunch-Kaufman (rook) diagonal pivoting method. The partial factorization has the form: A = ( I U12 ) ( A11 0 ) ( I 0 ) if UPLO = 'U', or: ( 0 U22 ) ( 0 D ) ( U12**T U22**T ) A = ( L11 0 ) ( D 0 ) ( L11**T L21**T ) if UPLO = 'L', ( L21 I ) ( 0 A22 ) ( 0 I ) where the order of D is at most NB. The actual order is returned in the argument KB, and is either NB or NB-1, or N if N &lt;= NB. LASYF_RK is an auxiliary routine called by CSYTRF_RK. It uses blocked code (calling Level 3 BLAS) to update the submatrix A11 (if UPLO = 'U') or A22 (if UPLO = 'L') </td></tr>
<tr id="row_6_279_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lasyf__rook.html" target="_self">lasyf_rook</a></td><td class="desc">LASYF_ROOK: computes a partial factorization of a complex symmetric matrix A using the bounded Bunch-Kaufman ("rook") diagonal pivoting method. The partial factorization has the form: A = ( I U12 ) ( A11 0 ) ( I 0 ) if UPLO = 'U', or: ( 0 U22 ) ( 0 D ) ( U12**T U22**T ) A = ( L11 0 ) ( D 0 ) ( L11**T L21**T ) if UPLO = 'L' ( L21 I ) ( 0 A22 ) ( 0 I ) where the order of D is at most NB. The actual order is returned in the argument KB, and is either NB or NB-1, or N if N &lt;= NB. LASYF_ROOK is an auxiliary routine called by CSYTRF_ROOK. It uses blocked code (calling Level 3 BLAS) to update the submatrix A11 (if UPLO = 'U') or A22 (if UPLO = 'L') </td></tr>
<tr id="row_6_280_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1latbs.html" target="_self">latbs</a></td><td class="desc">LATBS: solves one of the triangular systems A * x = s*b, A**T * x = s*b, or A**H * x = s*b, with scaling to prevent overflow, where A is an upper or lower triangular band matrix. Here A**T denotes the transpose of A, x and b are n-element vectors, and s is a scaling factor, usually less than or equal to 1, chosen so that the components of x will be less than the overflow threshold. If the unscaled problem will not cause overflow, the Level 2 BLAS routine CTBSV is called. If the matrix A is singular (A(j,j) = 0 for some j), then s is set to 0 and a non-trivial solution to A*x = 0 is returned </td></tr>
<tr id="row_6_281_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1latdf.html" target="_self">latdf</a></td><td class="desc">LATDF: computes the contribution to the reciprocal Dif-estimate by solving for x in Z * x = b, where b is chosen such that the norm of x is as large as possible. It is assumed that LU decomposition of Z has been computed by CGETC2. On entry RHS = f holds the contribution from earlier solved sub-systems, and on return RHS = x. The factorization of Z returned by CGETC2 has the form Z = P * L * U * Q, where P and Q are permutation matrices. L is lower triangular with unit diagonal elements and U is upper triangular </td></tr>
<tr id="row_6_282_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1latps.html" target="_self">latps</a></td><td class="desc">LATPS: solves one of the triangular systems A * x = s*b, A**T * x = s*b, or A**H * x = s*b, with scaling to prevent overflow, where A is an upper or lower triangular matrix stored in packed form. Here A**T denotes the transpose of A, A**H denotes the conjugate transpose of A, x and b are n-element vectors, and s is a scaling factor, usually less than or equal to 1, chosen so that the components of x will be less than the overflow threshold. If the unscaled problem will not cause overflow, the Level 2 BLAS routine CTPSV is called. If the matrix A is singular (A(j,j) = 0 for some j), then s is set to 0 and a non-trivial solution to A*x = 0 is returned </td></tr>
<tr id="row_6_283_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1latrd.html" target="_self">latrd</a></td><td class="desc">LATRD: reduces NB rows and columns of a complex Hermitian matrix A to Hermitian tridiagonal form by a unitary similarity transformation Q**H * A * Q, and returns the matrices V and W which are needed to apply the transformation to the unreduced part of A. If UPLO = 'U', LATRD reduces the last NB rows and columns of a matrix, of which the upper triangle is supplied; if UPLO = 'L', LATRD reduces the first NB rows and columns of a matrix, of which the lower triangle is supplied. This is an auxiliary routine called by CHETRD </td></tr>
<tr id="row_6_284_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1latrs.html" target="_self">latrs</a></td><td class="desc">LATRS: solves one of the triangular systems A * x = s*b, A**T * x = s*b, or A**H * x = s*b, with scaling to prevent overflow. Here A is an upper or lower triangular matrix, A**T denotes the transpose of A, A**H denotes the conjugate transpose of A, x and b are n-element vectors, and s is a scaling factor, usually less than or equal to 1, chosen so that the components of x will be less than the overflow threshold. If the unscaled problem will not cause overflow, the Level 2 BLAS routine CTRSV is called. If the matrix A is singular (A(j,j) = 0 for some j), then s is set to 0 and a non-trivial solution to A*x = 0 is returned </td></tr>
<tr id="row_6_285_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1latrz.html" target="_self">latrz</a></td><td class="desc">LATRZ: factors the M-by-(M+L) complex upper trapezoidal matrix [ A1 A2 ] = [ A(1:M,1:M) A(1:M,N-L+1:N) ] as ( R 0 ) * Z by means of unitary transformations, where Z is an (M+L)-by-(M+L) unitary matrix and, R and A1 are M-by-M upper triangular matrices </td></tr>
<tr id="row_6_286_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1latsqr.html" target="_self">latsqr</a></td><td class="desc">LATSQR: computes a blocked Tall-Skinny QR factorization of a complex M-by-N matrix A for M &gt;= N: A = Q * ( R ), ( 0 ) where: Q is a M-by-M orthogonal matrix, stored on exit in an implicit form in the elements below the diagonal of the array A and in the elements of the array T; R is an upper-triangular N-by-N matrix, stored on exit in the elements on and above the diagonal of the array A. 0 is a (M-N)-by-N zero matrix, and is not stored </td></tr>
<tr id="row_6_287_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1launhr__col__getrfnp.html" target="_self">launhr_col_getrfnp</a></td><td class="desc">LAUNHR_COL_GETRFNP: computes the modified LU factorization without pivoting of a complex general M-by-N matrix A. The factorization has the form: A - S = L * U, where: S is a m-by-n diagonal sign matrix with the diagonal D, so that D(i) = S(i,i), 1 &lt;= i &lt;= min(M,N). The diagonal D is constructed as D(i)=-SIGN(A(i,i)), where A(i,i) is the value after performing i-1 steps of Gaussian elimination. This means that the diagonal element at each step of "modified" Gaussian elimination is at least one in absolute value (so that division-by-zero not not possible during the division by the diagonal element); L is a M-by-N lower triangular matrix with unit diagonal elements (lower trapezoidal if M &gt; N); and U is a M-by-N upper triangular matrix (upper trapezoidal if M &lt; N). This routine is an auxiliary routine used in the Householder reconstruction routine CUNHR_COL. In CUNHR_COL, this routine is applied to an M-by-N matrix A with orthonormal columns, where each element is bounded by one in absolute value. With the choice of the matrix S above, one can show that the diagonal element at each step of Gaussian elimination is the largest (in absolute value) in the column on or below the diagonal, so that no pivoting is required for numerical stability [1]. For more details on the Householder reconstruction algorithm, including the modified LU factorization, see [1]. This is the blocked right-looking version of the algorithm, calling Level 3 BLAS to update the submatrix. To factorize a block, this routine calls the recursive routine LAUNHR_COL_GETRFNP2. [1] "Reconstructing Householder vectors from tall-skinny QR", G. Ballard, J. Demmel, L. Grigori, M. Jacquelin, H.D. Nguyen, E. Solomonik, J. Parallel Distrib. Comput., vol. 85, pp. 3-31, 2015 </td></tr>
<tr id="row_6_288_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1launhr__col__getrfnp2.html" target="_self">launhr_col_getrfnp2</a></td><td class="desc">LAUNHR_COL_GETRFNP2: computes the modified LU factorization without pivoting of a complex general M-by-N matrix A. The factorization has the form: A - S = L * U, where: S is a m-by-n diagonal sign matrix with the diagonal D, so that D(i) = S(i,i), 1 &lt;= i &lt;= min(M,N). The diagonal D is constructed as D(i)=-SIGN(A(i,i)), where A(i,i) is the value after performing i-1 steps of Gaussian elimination. This means that the diagonal element at each step of "modified" Gaussian elimination is at least one in absolute value (so that division-by-zero not possible during the division by the diagonal element); L is a M-by-N lower triangular matrix with unit diagonal elements (lower trapezoidal if M &gt; N); and U is a M-by-N upper triangular matrix (upper trapezoidal if M &lt; N). This routine is an auxiliary routine used in the Householder reconstruction routine CUNHR_COL. In CUNHR_COL, this routine is applied to an M-by-N matrix A with orthonormal columns, where each element is bounded by one in absolute value. With the choice of the matrix S above, one can show that the diagonal element at each step of Gaussian elimination is the largest (in absolute value) in the column on or below the diagonal, so that no pivoting is required for numerical stability [1]. For more details on the Householder reconstruction algorithm, including the modified LU factorization, see [1]. This is the recursive version of the LU factorization algorithm. Denote A - S by B. The algorithm divides the matrix B into four submatrices: [ B11 | B12 ] where B11 is n1 by n1, B = [ --&mdash;|--&mdash; ] B21 is (m-n1) by n1, [ B21 | B22 ] B12 is n1 by n2, B22 is (m-n1) by n2, with n1 = min(m,n)/2, n2 = n-n1. The subroutine calls itself to factor B11, solves for B21, solves for B12, updates B22, then calls itself to factor B22. For more details on the recursive LU algorithm, see [2]. LAUNHR_COL_GETRFNP2 is called to factorize a block by the blocked routine CLAUNHR_COL_GETRFNP, which uses blocked code calling Level 3 BLAS to update the submatrix. However, LAUNHR_COL_GETRFNP2 is self-sufficient and can be used without CLAUNHR_COL_GETRFNP. [1] "Reconstructing Householder vectors from tall-skinny QR", G. Ballard, J. Demmel, L. Grigori, M. Jacquelin, H.D. Nguyen, E. Solomonik, J. Parallel Distrib. Comput., vol. 85, pp. 3-31, 2015. [2] "Recursion leads to automatic variable blocking for dense linear
 algebra algorithms", F. Gustavson, IBM J. of Res. and Dev., vol. 41, no. 6, pp. 737-755, 1997 </td></tr>
<tr id="row_6_289_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1lauum.html" target="_self">lauum</a></td><td class="desc">LAUUM: computes the product U * U**H or L**H * L, where the triangular factor U or L is stored in the upper or lower triangular part of the array A. If UPLO = 'U' or 'u' then the upper triangle of the result is stored, overwriting the factor U in A. If UPLO = 'L' or 'l' then the lower triangle of the result is stored, overwriting the factor L in A. This is the blocked form of the algorithm, calling Level 3 BLAS </td></tr>
<tr id="row_6_290_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1opgtr.html" target="_self">opgtr</a></td><td class="desc">OPGTR: generates a real orthogonal matrix Q which is defined as the product of n-1 elementary reflectors H(i) of order n, as returned by DSPTRD using packed storage: if UPLO = 'U', Q = H(n-1) . . . H(2) H(1), if UPLO = 'L', Q = H(1) H(2) . . . H(n-1) </td></tr>
<tr id="row_6_291_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1opmtr.html" target="_self">opmtr</a></td><td class="desc">OPMTR: overwrites the general real M-by-N matrix C with SIDE = 'L' SIDE = 'R' TRANS = 'N': Q * C C * Q TRANS = 'T': Q**T * C C * Q**T where Q is a real orthogonal matrix of order nq, with nq = m if SIDE = 'L' and nq = n if SIDE = 'R'. Q is defined as the product of nq-1 elementary reflectors, as returned by DSPTRD using packed storage: if UPLO = 'U', Q = H(nq-1) . . . H(2) H(1); if UPLO = 'L', Q = H(1) H(2) . . . H(nq-1) </td></tr>
<tr id="row_6_292_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1orbdb.html" target="_self">orbdb</a></td><td class="desc">ORBDB: simultaneously bidiagonalizes the blocks of an M-by-M partitioned orthogonal matrix X: [ B11 | B12 0 0 ] [ X11 | X12 ] [ P1 | ] [ 0 | 0 -I 0 ] [ Q1 | ]**T X = [--------&mdash;] = [------&mdash;] [-------------&mdash;] [------&mdash;] . [ X21 | X22 ] [ | P2 ] [ B21 | B22 0 0 ] [ | Q2 ] [ 0 | 0 0 I ] X11 is P-by-Q. Q must be no larger than P, M-P, or M-Q. (If this is not the case, then X must be transposed and/or permuted. This can be done in constant time using the TRANS and SIGNS options. See DORCSD for details.) The orthogonal matrices P1, P2, Q1, and Q2 are P-by-P, (M-P)-by- (M-P), Q-by-Q, and (M-Q)-by-(M-Q), respectively. They are represented implicitly by Householder vectors. B11, B12, B21, and B22 are Q-by-Q bidiagonal matrices represented implicitly by angles THETA, PHI </td></tr>
<tr id="row_6_293_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1orbdb1.html" target="_self">orbdb1</a></td><td class="desc">ORBDB1: simultaneously bidiagonalizes the blocks of a tall and skinny matrix X with orthonomal columns: [ B11 ] [ X11 ] [ P1 | ] [ 0 ] [--&mdash;] = [------&mdash;] [--&mdash;] Q1**T . [ X21 ] [ | P2 ] [ B21 ] [ 0 ] X11 is P-by-Q, and X21 is (M-P)-by-Q. Q must be no larger than P, M-P, or M-Q. Routines DORBDB2, DORBDB3, and DORBDB4 handle cases in which Q is not the minimum dimension. The orthogonal matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P), and (M-Q)-by-(M-Q), respectively. They are represented implicitly by Householder vectors. B11 and B12 are Q-by-Q bidiagonal matrices represented implicitly by angles THETA, PHI </td></tr>
<tr id="row_6_294_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1orbdb2.html" target="_self">orbdb2</a></td><td class="desc">ORBDB2: simultaneously bidiagonalizes the blocks of a tall and skinny matrix X with orthonomal columns: [ B11 ] [ X11 ] [ P1 | ] [ 0 ] [--&mdash;] = [------&mdash;] [--&mdash;] Q1**T . [ X21 ] [ | P2 ] [ B21 ] [ 0 ] X11 is P-by-Q, and X21 is (M-P)-by-Q. P must be no larger than M-P, Q, or M-Q. Routines DORBDB1, DORBDB3, and DORBDB4 handle cases in which P is not the minimum dimension. The orthogonal matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P), and (M-Q)-by-(M-Q), respectively. They are represented implicitly by Householder vectors. B11 and B12 are P-by-P bidiagonal matrices represented implicitly by angles THETA, PHI </td></tr>
<tr id="row_6_295_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1orbdb3.html" target="_self">orbdb3</a></td><td class="desc">ORBDB3: simultaneously bidiagonalizes the blocks of a tall and skinny matrix X with orthonomal columns: [ B11 ] [ X11 ] [ P1 | ] [ 0 ] [--&mdash;] = [------&mdash;] [--&mdash;] Q1**T . [ X21 ] [ | P2 ] [ B21 ] [ 0 ] X11 is P-by-Q, and X21 is (M-P)-by-Q. M-P must be no larger than P, Q, or M-Q. Routines DORBDB1, DORBDB2, and DORBDB4 handle cases in which M-P is not the minimum dimension. The orthogonal matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P), and (M-Q)-by-(M-Q), respectively. They are represented implicitly by Householder vectors. B11 and B12 are (M-P)-by-(M-P) bidiagonal matrices represented implicitly by angles THETA, PHI </td></tr>
<tr id="row_6_296_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1orbdb4.html" target="_self">orbdb4</a></td><td class="desc">ORBDB4: simultaneously bidiagonalizes the blocks of a tall and skinny matrix X with orthonomal columns: [ B11 ] [ X11 ] [ P1 | ] [ 0 ] [--&mdash;] = [------&mdash;] [--&mdash;] Q1**T . [ X21 ] [ | P2 ] [ B21 ] [ 0 ] X11 is P-by-Q, and X21 is (M-P)-by-Q. M-Q must be no larger than P, M-P, or Q. Routines DORBDB1, DORBDB2, and DORBDB3 handle cases in which M-Q is not the minimum dimension. The orthogonal matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P), and (M-Q)-by-(M-Q), respectively. They are represented implicitly by Householder vectors. B11 and B12 are (M-Q)-by-(M-Q) bidiagonal matrices represented implicitly by angles THETA, PHI </td></tr>
<tr id="row_6_297_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1orbdb5.html" target="_self">orbdb5</a></td><td class="desc">ORBDB5: orthogonalizes the column vector X = [ X1 ] [ X2 ] with respect to the columns of Q = [ Q1 ] . [ Q2 ] The columns of Q must be orthonormal. If the projection is zero according to Kahan's "twice is enough" criterion, then some other vector from the orthogonal complement is returned. This vector is chosen in an arbitrary but deterministic way </td></tr>
<tr id="row_6_298_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1orbdb6.html" target="_self">orbdb6</a></td><td class="desc">ORBDB6: orthogonalizes the column vector X = [ X1 ] [ X2 ] with respect to the columns of Q = [ Q1 ] . [ Q2 ] The columns of Q must be orthonormal. If the projection is zero according to Kahan's "twice is enough" criterion, then the zero vector is returned </td></tr>
<tr id="row_6_299_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1orcsd.html" target="_self">orcsd</a></td><td class="desc">ORCSD: computes the CS decomposition of an M-by-M partitioned orthogonal matrix X: [ I 0 0 | 0 0 0 ] [ 0 C 0 | 0 -S 0 ] [ X11 | X12 ] [ U1 | ] [ 0 0 0 | 0 0 -I ] [ V1 | ]**T X = [--------&mdash;] = [------&mdash;] [------------------&mdash;] [------&mdash;] . [ X21 | X22 ] [ | U2 ] [ 0 0 0 | I 0 0 ] [ | V2 ] [ 0 S 0 | 0 C 0 ] [ 0 0 I | 0 0 0 ] X11 is P-by-Q. The orthogonal matrices U1, U2, V1, and V2 are P-by-P, (M-P)-by-(M-P), Q-by-Q, and (M-Q)-by-(M-Q), respectively. C and S are R-by-R nonnegative diagonal matrices satisfying C^2 + S^2 = I, in which R = MIN(P,M-P,Q,M-Q) </td></tr>
<tr id="row_6_300_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1orcsd2by1.html" target="_self">orcsd2by1</a></td><td class="desc">ORCSD2BY1: computes the CS decomposition of an M-by-Q matrix X with orthonormal columns that has been partitioned into a 2-by-1 block structure: [ I1 0 0 ] [ 0 C 0 ] [ X11 ] [ U1 | ] [ 0 0 0 ] X = [--&mdash;] = [------&mdash;] [-------&mdash;] V1**T . [ X21 ] [ | U2 ] [ 0 0 0 ] [ 0 S 0 ] [ 0 0 I2] X11 is P-by-Q. The orthogonal matrices U1, U2, and V1 are P-by-P, (M-P)-by-(M-P), and Q-by-Q, respectively. C and S are R-by-R nonnegative diagonal matrices satisfying C^2 + S^2 = I, in which R = MIN(P,M-P,Q,M-Q). I1 is a K1-by-K1 identity matrix and I2 is a K2-by-K2 identity matrix, where K1 = MAX(Q+P-M,0), K2 = MAX(Q-P,0) </td></tr>
<tr id="row_6_301_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1org2l.html" target="_self">org2l</a></td><td class="desc">ORG2L: generates an m by n real matrix Q with orthonormal columns, which is defined as the last n columns of a product of k elementary reflectors of order m Q = H(k) . . . H(2) H(1) as returned by DGEQLF </td></tr>
<tr id="row_6_302_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1org2r.html" target="_self">org2r</a></td><td class="desc">ORG2R: generates an m by n real matrix Q with orthonormal columns, which is defined as the first n columns of a product of k elementary reflectors of order m Q = H(1) H(2) . . . H(k) as returned by DGEQRF </td></tr>
<tr id="row_6_303_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1orgbr.html" target="_self">orgbr</a></td><td class="desc">ORGBR: generates one of the real orthogonal matrices Q or P**T determined by DGEBRD when reducing a real matrix A to bidiagonal form: A = Q * B * P**T. Q and P**T are defined as products of elementary reflectors H(i) or G(i) respectively. If VECT = 'Q', A is assumed to have been an M-by-K matrix, and Q is of order M: if m &gt;= k, Q = H(1) H(2) . . . H(k) and ORGBR returns the first n columns of Q, where m &gt;= n &gt;= k; if m &lt; k, Q = H(1) H(2) . . . H(m-1) and ORGBR returns Q as an M-by-M matrix. If VECT = 'P', A is assumed to have been a K-by-N matrix, and P**T is of order N: if k &lt; n, P**T = G(k) . . . G(2) G(1) and ORGBR returns the first m rows of P**T, where n &gt;= m &gt;= k; if k &gt;= n, P**T = G(n-1) . . . G(2) G(1) and ORGBR returns P**T as an N-by-N matrix </td></tr>
<tr id="row_6_304_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1orghr.html" target="_self">orghr</a></td><td class="desc">ORGHR: generates a real orthogonal matrix Q which is defined as the product of IHI-ILO elementary reflectors of order N, as returned by DGEHRD: Q = H(ilo) H(ilo+1) . . . H(ihi-1) </td></tr>
<tr id="row_6_305_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1orglq.html" target="_self">orglq</a></td><td class="desc">ORGLQ: generates an M-by-N real matrix Q with orthonormal rows, which is defined as the first M rows of a product of K elementary reflectors of order N Q = H(k) . . . H(2) H(1) as returned by DGELQF </td></tr>
<tr id="row_6_306_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1orgql.html" target="_self">orgql</a></td><td class="desc">ORGQL: generates an M-by-N real matrix Q with orthonormal columns, which is defined as the last N columns of a product of K elementary reflectors of order M Q = H(k) . . . H(2) H(1) as returned by DGEQLF </td></tr>
<tr id="row_6_307_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1orgqr.html" target="_self">orgqr</a></td><td class="desc">ORGQR: generates an M-by-N real matrix Q with orthonormal columns, which is defined as the first N columns of a product of K elementary reflectors of order M Q = H(1) H(2) . . . H(k) as returned by GEQRF </td></tr>
<tr id="row_6_308_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1orgrq.html" target="_self">orgrq</a></td><td class="desc">ORGRQ: generates an M-by-N real matrix Q with orthonormal rows, which is defined as the last M rows of a product of K elementary reflectors of order N Q = H(1) H(2) . . . H(k) as returned by DGERQF </td></tr>
<tr id="row_6_309_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1orgtr.html" target="_self">orgtr</a></td><td class="desc">ORGTR: generates a real orthogonal matrix Q which is defined as the product of n-1 elementary reflectors of order N, as returned by DSYTRD: if UPLO = 'U', Q = H(n-1) . . . H(2) H(1), if UPLO = 'L', Q = H(1) H(2) . . . H(n-1) </td></tr>
<tr id="row_6_310_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1orgtsqr.html" target="_self">orgtsqr</a></td><td class="desc">ORGTSQR: generates an M-by-N real matrix Q_out with orthonormal columns, which are the first N columns of a product of real orthogonal matrices of order M which are returned by DLATSQR Q_out = first_N_columns_of( Q(1)_in * Q(2)_in * ... * Q(k)_in ). See the documentation for DLATSQR </td></tr>
<tr id="row_6_311_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1orgtsqr__row.html" target="_self">orgtsqr_row</a></td><td class="desc">ORGTSQR_ROW: generates an M-by-N real matrix Q_out with orthonormal columns from the output of DLATSQR. These N orthonormal columns are the first N columns of a product of complex unitary matrices Q(k)_in of order M, which are returned by DLATSQR in a special format. Q_out = first_N_columns_of( Q(1)_in * Q(2)_in * ... * Q(k)_in ). The input matrices Q(k)_in are stored in row and column blocks in A. See the documentation of DLATSQR for more details on the format of Q(k)_in, where each Q(k)_in is represented by block Householder transformations. This routine calls an auxiliary routine DLARFB_GETT, where the computation is performed on each individual block. The algorithm first sweeps NB-sized column blocks from the right to left starting in the bottom row block and continues to the top row block (hence _ROW in the routine name). This sweep is in reverse order of the order in which DLATSQR generates the output blocks </td></tr>
<tr id="row_6_312_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1orhr__col.html" target="_self">orhr_col</a></td><td class="desc">ORHR_COL: takes an M-by-N real matrix Q_in with orthonormal columns as input, stored in A, and performs Householder Reconstruction (HR), i.e. reconstructs Householder vectors V(i) implicitly representing another M-by-N matrix Q_out, with the property that Q_in = Q_out*S, where S is an N-by-N diagonal matrix with diagonal entries equal to +1 or -1. The Householder vectors (columns V(i) of V) are stored in A on output, and the diagonal entries of S are stored in D. Block reflectors are also returned in T (same output format as DGEQRT) </td></tr>
<tr id="row_6_313_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1orm2l.html" target="_self">orm2l</a></td><td class="desc">ORM2L: overwrites the general real m by n matrix C with Q * C if SIDE = 'L' and TRANS = 'N', or Q**T * C if SIDE = 'L' and TRANS = 'T', or C * Q if SIDE = 'R' and TRANS = 'N', or C * Q**T if SIDE = 'R' and TRANS = 'T', where Q is a real orthogonal matrix defined as the product of k elementary reflectors Q = H(k) . . . H(2) H(1) as returned by DGEQLF. Q is of order m if SIDE = 'L' and of order n if SIDE = 'R' </td></tr>
<tr id="row_6_314_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1orm2r.html" target="_self">orm2r</a></td><td class="desc">ORM2R: overwrites the general real m by n matrix C with Q * C if SIDE = 'L' and TRANS = 'N', or Q**T* C if SIDE = 'L' and TRANS = 'T', or C * Q if SIDE = 'R' and TRANS = 'N', or C * Q**T if SIDE = 'R' and TRANS = 'T', where Q is a real orthogonal matrix defined as the product of k elementary reflectors Q = H(1) H(2) . . . H(k) as returned by DGEQRF. Q is of order m if SIDE = 'L' and of order n if SIDE = 'R' </td></tr>
<tr id="row_6_315_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ormbr.html" target="_self">ormbr</a></td><td class="desc">If VECT = 'Q', ORMBR: overwrites the general real M-by-N matrix C with SIDE = 'L' SIDE = 'R' TRANS = 'N': Q * C C * Q TRANS = 'T': Q**T * C C * Q**T If VECT = 'P', ORMBR overwrites the general real M-by-N matrix C with SIDE = 'L' SIDE = 'R' TRANS = 'N': P * C C * P TRANS = 'T': P**T * C C * P**T Here Q and P**T are the orthogonal matrices determined by DGEBRD when reducing a real matrix A to bidiagonal form: A = Q * B * P**T. Q and P**T are defined as products of elementary reflectors H(i) and G(i) respectively. Let nq = m if SIDE = 'L' and nq = n if SIDE = 'R'. Thus nq is the order of the orthogonal matrix Q or P**T that is applied. If VECT = 'Q', A is assumed to have been an NQ-by-K matrix: if nq &gt;= k, Q = H(1) H(2) . . . H(k); if nq &lt; k, Q = H(1) H(2) . . . H(nq-1). If VECT = 'P', A is assumed to have been a K-by-NQ matrix: if k &lt; nq, P = G(1) G(2) . . . G(k); if k &gt;= nq, P = G(1) G(2) . . . G(nq-1) </td></tr>
<tr id="row_6_316_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ormhr.html" target="_self">ormhr</a></td><td class="desc">ORMHR: overwrites the general real M-by-N matrix C with SIDE = 'L' SIDE = 'R' TRANS = 'N': Q * C C * Q TRANS = 'T': Q**T * C C * Q**T where Q is a real orthogonal matrix of order nq, with nq = m if SIDE = 'L' and nq = n if SIDE = 'R'. Q is defined as the product of IHI-ILO elementary reflectors, as returned by DGEHRD: Q = H(ilo) H(ilo+1) . . . H(ihi-1) </td></tr>
<tr id="row_6_317_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ormlq.html" target="_self">ormlq</a></td><td class="desc">ORMLQ: overwrites the general real M-by-N matrix C with SIDE = 'L' SIDE = 'R' TRANS = 'N': Q * C C * Q TRANS = 'T': Q**T * C C * Q**T where Q is a real orthogonal matrix defined as the product of k elementary reflectors Q = H(k) . . . H(2) H(1) as returned by DGELQF. Q is of order M if SIDE = 'L' and of order N if SIDE = 'R' </td></tr>
<tr id="row_6_318_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ormql.html" target="_self">ormql</a></td><td class="desc">ORMQL: overwrites the general real M-by-N matrix C with SIDE = 'L' SIDE = 'R' TRANS = 'N': Q * C C * Q TRANS = 'T': Q**T * C C * Q**T where Q is a real orthogonal matrix defined as the product of k elementary reflectors Q = H(k) . . . H(2) H(1) as returned by DGEQLF. Q is of order M if SIDE = 'L' and of order N if SIDE = 'R' </td></tr>
<tr id="row_6_319_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ormqr.html" target="_self">ormqr</a></td><td class="desc">ORMQR: overwrites the general real M-by-N matrix C with SIDE = 'L' SIDE = 'R' TRANS = 'N': Q * C C * Q TRANS = 'T': Q**T * C C * Q**T where Q is a real orthogonal matrix defined as the product of k elementary reflectors Q = H(1) H(2) . . . H(k) as returned by DGEQRF. Q is of order M if SIDE = 'L' and of order N if SIDE = 'R' </td></tr>
<tr id="row_6_320_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ormrq.html" target="_self">ormrq</a></td><td class="desc">ORMRQ: overwrites the general real M-by-N matrix C with SIDE = 'L' SIDE = 'R' TRANS = 'N': Q * C C * Q TRANS = 'T': Q**T * C C * Q**T where Q is a real orthogonal matrix defined as the product of k elementary reflectors Q = H(1) H(2) . . . H(k) as returned by DGERQF. Q is of order M if SIDE = 'L' and of order N if SIDE = 'R' </td></tr>
<tr id="row_6_321_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ormrz.html" target="_self">ormrz</a></td><td class="desc">ORMRZ: overwrites the general real M-by-N matrix C with SIDE = 'L' SIDE = 'R' TRANS = 'N': Q * C C * Q TRANS = 'T': Q**T * C C * Q**T where Q is a real orthogonal matrix defined as the product of k elementary reflectors Q = H(1) H(2) . . . H(k) as returned by DTZRZF. Q is of order M if SIDE = 'L' and of order N if SIDE = 'R' </td></tr>
<tr id="row_6_322_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ormtr.html" target="_self">ormtr</a></td><td class="desc">ORMTR: overwrites the general real M-by-N matrix C with SIDE = 'L' SIDE = 'R' TRANS = 'N': Q * C C * Q TRANS = 'T': Q**T * C C * Q**T where Q is a real orthogonal matrix of order nq, with nq = m if SIDE = 'L' and nq = n if SIDE = 'R'. Q is defined as the product of nq-1 elementary reflectors, as returned by DSYTRD: if UPLO = 'U', Q = H(nq-1) . . . H(2) H(1); if UPLO = 'L', Q = H(1) H(2) . . . H(nq-1) </td></tr>
<tr id="row_6_323_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1pbcon.html" target="_self">pbcon</a></td><td class="desc">PBCON: estimates the reciprocal of the condition number (in the 1-norm) of a complex Hermitian positive definite band matrix using the Cholesky factorization A = U**H*U or A = L*L**H computed by CPBTRF. An estimate is obtained for norm(inv(A)), and the reciprocal of the condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))) </td></tr>
<tr id="row_6_324_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1pbequ.html" target="_self">pbequ</a></td><td class="desc">PBEQU: computes row and column scalings intended to equilibrate a Hermitian positive definite band matrix A and reduce its condition number (with respect to the two-norm). S contains the scale factors, S(i) = 1/sqrt(A(i,i)), chosen so that the scaled matrix B with elements B(i,j) = S(i)*A(i,j)*S(j) has ones on the diagonal. This choice of S puts the condition number of B within a factor N of the smallest possible condition number over all possible diagonal scalings </td></tr>
<tr id="row_6_325_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1pbrfs.html" target="_self">pbrfs</a></td><td class="desc">PBRFS: improves the computed solution to a system of linear equations when the coefficient matrix is Hermitian positive definite and banded, and provides error bounds and backward error estimates for the solution </td></tr>
<tr id="row_6_326_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1pbstf.html" target="_self">pbstf</a></td><td class="desc">PBSTF: computes a split Cholesky factorization of a complex Hermitian positive definite band matrix A. This routine is designed to be used in conjunction with CHBGST. The factorization has the form A = S**H*S where S is a band matrix of the same bandwidth as A and the following structure: S = ( U ) ( M L ) where U is upper triangular of order m = (n+kd)/2, and L is lower triangular of order n-m </td></tr>
<tr id="row_6_327_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1pbsv.html" target="_self">pbsv</a></td><td class="desc">PBSV: computes the solution to a complex system of linear equations A * X = B, where A is an N-by-N Hermitian positive definite band matrix and X and B are N-by-NRHS matrices. The Cholesky decomposition is used to factor A as A = U**H * U, if UPLO = 'U', or A = L * L**H, if UPLO = 'L', where U is an upper triangular band matrix, and L is a lower triangular band matrix, with the same number of superdiagonals or subdiagonals as A. The factored form of A is then used to solve the system of equations A * X = B </td></tr>
<tr id="row_6_328_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1pbtrf.html" target="_self">pbtrf</a></td><td class="desc">PBTRF: computes the Cholesky factorization of a complex Hermitian positive definite band matrix A. The factorization has the form A = U**H * U, if UPLO = 'U', or A = L * L**H, if UPLO = 'L', where U is an upper triangular matrix and L is lower triangular </td></tr>
<tr id="row_6_329_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1pbtrs.html" target="_self">pbtrs</a></td><td class="desc">PBTRS: solves a system of linear equations A*X = B with a Hermitian positive definite band matrix A using the Cholesky factorization A = U**H*U or A = L*L**H computed by CPBTRF </td></tr>
<tr id="row_6_330_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1pftrf.html" target="_self">pftrf</a></td><td class="desc">PFTRF: computes the Cholesky factorization of a complex Hermitian positive definite matrix A. The factorization has the form A = U**H * U, if UPLO = 'U', or A = L * L**H, if UPLO = 'L', where U is an upper triangular matrix and L is lower triangular. This is the block version of the algorithm, calling Level 3 BLAS </td></tr>
<tr id="row_6_331_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1pftri.html" target="_self">pftri</a></td><td class="desc">PFTRI: computes the inverse of a complex Hermitian positive definite matrix A using the Cholesky factorization A = U**H*U or A = L*L**H computed by CPFTRF </td></tr>
<tr id="row_6_332_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1pftrs.html" target="_self">pftrs</a></td><td class="desc">PFTRS: solves a system of linear equations A*X = B with a Hermitian positive definite matrix A using the Cholesky factorization A = U**H*U or A = L*L**H computed by CPFTRF </td></tr>
<tr id="row_6_333_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1pocon.html" target="_self">pocon</a></td><td class="desc">POCON: estimates the reciprocal of the condition number (in the 1-norm) of a complex Hermitian positive definite matrix using the Cholesky factorization A = U**H*U or A = L*L**H computed by CPOTRF. An estimate is obtained for norm(inv(A)), and the reciprocal of the condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))) </td></tr>
<tr id="row_6_334_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1poequ.html" target="_self">poequ</a></td><td class="desc">POEQU: computes row and column scalings intended to equilibrate a Hermitian positive definite matrix A and reduce its condition number (with respect to the two-norm). S contains the scale factors, S(i) = 1/sqrt(A(i,i)), chosen so that the scaled matrix B with elements B(i,j) = S(i)*A(i,j)*S(j) has ones on the diagonal. This choice of S puts the condition number of B within a factor N of the smallest possible condition number over all possible diagonal scalings </td></tr>
<tr id="row_6_335_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1poequb.html" target="_self">poequb</a></td><td class="desc">POEQUB: computes row and column scalings intended to equilibrate a Hermitian positive definite matrix A and reduce its condition number (with respect to the two-norm). S contains the scale factors, S(i) = 1/sqrt(A(i,i)), chosen so that the scaled matrix B with elements B(i,j) = S(i)*A(i,j)*S(j) has ones on the diagonal. This choice of S puts the condition number of B within a factor N of the smallest possible condition number over all possible diagonal scalings. This routine differs from CPOEQU by restricting the scaling factors to a power of the radix. Barring over- and underflow, scaling by these factors introduces no additional rounding errors. However, the scaled diagonal entries are no longer approximately 1 but lie between sqrt(radix) and 1/sqrt(radix) </td></tr>
<tr id="row_6_336_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1porfs.html" target="_self">porfs</a></td><td class="desc">PORFS: improves the computed solution to a system of linear equations when the coefficient matrix is Hermitian positive definite, and provides error bounds and backward error estimates for the solution </td></tr>
<tr id="row_6_337_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1posv.html" target="_self">posv</a></td><td class="desc">POSV: computes the solution to a complex system of linear equations A * X = B, where A is an N-by-N Hermitian positive definite matrix and X and B are N-by-NRHS matrices. The Cholesky decomposition is used to factor A as A = U**H* U, if UPLO = 'U', or A = L * L**H, if UPLO = 'L', where U is an upper triangular matrix and L is a lower triangular matrix. The factored form of A is then used to solve the system of equations A * X = B </td></tr>
<tr id="row_6_338_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1potrf.html" target="_self">potrf</a></td><td class="desc">POTRF: computes the Cholesky factorization of a complex Hermitian positive definite matrix A. The factorization has the form A = U**H * U, if UPLO = 'U', or A = L * L**H, if UPLO = 'L', where U is an upper triangular matrix and L is lower triangular. This is the block version of the algorithm, calling Level 3 BLAS </td></tr>
<tr id="row_6_339_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1potrf2.html" target="_self">potrf2</a></td><td class="desc">POTRF2: computes the Cholesky factorization of a Hermitian positive definite matrix A using the recursive algorithm. The factorization has the form A = U**H * U, if UPLO = 'U', or A = L * L**H, if UPLO = 'L', where U is an upper triangular matrix and L is lower triangular. This is the recursive version of the algorithm. It divides the matrix into four submatrices: [ A11 | A12 ] where A11 is n1 by n1 and A22 is n2 by n2 A = [ --&mdash;|--&mdash; ] with n1 = n/2 [ A21 | A22 ] n2 = n-n1 The subroutine calls itself to factor A11. Update and scale A21 or A12, update A22 then calls itself to factor A22 </td></tr>
<tr id="row_6_340_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1potri.html" target="_self">potri</a></td><td class="desc">POTRI: computes the inverse of a complex Hermitian positive definite matrix A using the Cholesky factorization A = U**H*U or A = L*L**H computed by CPOTRF </td></tr>
<tr id="row_6_341_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1potrs.html" target="_self">potrs</a></td><td class="desc">POTRS: solves a system of linear equations A*X = B with a Hermitian positive definite matrix A using the Cholesky factorization A = U**H*U or A = L*L**H computed by CPOTRF </td></tr>
<tr id="row_6_342_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ppcon.html" target="_self">ppcon</a></td><td class="desc">PPCON: estimates the reciprocal of the condition number (in the 1-norm) of a complex Hermitian positive definite packed matrix using the Cholesky factorization A = U**H*U or A = L*L**H computed by CPPTRF. An estimate is obtained for norm(inv(A)), and the reciprocal of the condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))) </td></tr>
<tr id="row_6_343_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ppequ.html" target="_self">ppequ</a></td><td class="desc">PPEQU: computes row and column scalings intended to equilibrate a Hermitian positive definite matrix A in packed storage and reduce its condition number (with respect to the two-norm). S contains the scale factors, S(i)=1/sqrt(A(i,i)), chosen so that the scaled matrix B with elements B(i,j)=S(i)*A(i,j)*S(j) has ones on the diagonal. This choice of S puts the condition number of B within a factor N of the smallest possible condition number over all possible diagonal scalings </td></tr>
<tr id="row_6_344_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1pprfs.html" target="_self">pprfs</a></td><td class="desc">PPRFS: improves the computed solution to a system of linear equations when the coefficient matrix is Hermitian positive definite and packed, and provides error bounds and backward error estimates for the solution </td></tr>
<tr id="row_6_345_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ppsv.html" target="_self">ppsv</a></td><td class="desc">PPSV: computes the solution to a complex system of linear equations A * X = B, where A is an N-by-N Hermitian positive definite matrix stored in packed format and X and B are N-by-NRHS matrices. The Cholesky decomposition is used to factor A as A = U**H * U, if UPLO = 'U', or A = L * L**H, if UPLO = 'L', where U is an upper triangular matrix and L is a lower triangular matrix. The factored form of A is then used to solve the system of equations A * X = B </td></tr>
<tr id="row_6_346_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1pptrf.html" target="_self">pptrf</a></td><td class="desc">PPTRF: computes the Cholesky factorization of a complex Hermitian positive definite matrix A stored in packed format. The factorization has the form A = U**H * U, if UPLO = 'U', or A = L * L**H, if UPLO = 'L', where U is an upper triangular matrix and L is lower triangular </td></tr>
<tr id="row_6_347_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1pptri.html" target="_self">pptri</a></td><td class="desc">PPTRI: computes the inverse of a complex Hermitian positive definite matrix A using the Cholesky factorization A = U**H*U or A = L*L**H computed by CPPTRF </td></tr>
<tr id="row_6_348_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1pptrs.html" target="_self">pptrs</a></td><td class="desc">PPTRS: solves a system of linear equations A*X = B with a Hermitian positive definite matrix A in packed storage using the Cholesky factorization A = U**H*U or A = L*L**H computed by CPPTRF </td></tr>
<tr id="row_6_349_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1pstrf.html" target="_self">pstrf</a></td><td class="desc">PSTRF: computes the Cholesky factorization with complete pivoting of a complex Hermitian positive semidefinite matrix A. The factorization has the form P**T * A * P = U**H * U , if UPLO = 'U', P**T * A * P = L * L**H, if UPLO = 'L', where U is an upper triangular matrix and L is lower triangular, and P is stored as vector PIV. This algorithm does not attempt to check that A is positive semidefinite. This version of the algorithm calls level 3 BLAS </td></tr>
<tr id="row_6_350_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ptcon.html" target="_self">ptcon</a></td><td class="desc">PTCON: computes the reciprocal of the condition number (in the 1-norm) of a complex Hermitian positive definite tridiagonal matrix using the factorization A = L*D*L**H or A = U**H*D*U computed by CPTTRF. Norm(inv(A)) is computed by a direct method, and the reciprocal of the condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))) </td></tr>
<tr id="row_6_351_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1pteqr.html" target="_self">pteqr</a></td><td class="desc">PTEQR: computes all eigenvalues and, optionally, eigenvectors of a symmetric positive definite tridiagonal matrix by first factoring the matrix using SPTTRF and then calling CBDSQR to compute the singular values of the bidiagonal factor. This routine computes the eigenvalues of the positive definite tridiagonal matrix to high relative accuracy. This means that if the eigenvalues range over many orders of magnitude in size, then the small eigenvalues and corresponding eigenvectors will be computed more accurately than, for example, with the standard QR method. The eigenvectors of a full or band positive definite Hermitian matrix can also be found if CHETRD, CHPTRD, or CHBTRD has been used to reduce this matrix to tridiagonal form. (The reduction to tridiagonal form, however, may preclude the possibility of obtaining high relative accuracy in the small eigenvalues of the original matrix, if these eigenvalues range over many orders of magnitude.) </td></tr>
<tr id="row_6_352_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ptrfs.html" target="_self">ptrfs</a></td><td class="desc">PTRFS: improves the computed solution to a system of linear equations when the coefficient matrix is Hermitian positive definite and tridiagonal, and provides error bounds and backward error estimates for the solution </td></tr>
<tr id="row_6_353_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ptsv.html" target="_self">ptsv</a></td><td class="desc">PTSV: computes the solution to a complex system of linear equations A*X = B, where A is an N-by-N Hermitian positive definite tridiagonal matrix, and X and B are N-by-NRHS matrices. A is factored as A = L*D*L**H, and the factored form of A is then used to solve the system of equations </td></tr>
<tr id="row_6_354_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1pttrf.html" target="_self">pttrf</a></td><td class="desc">PTTRF: computes the L*D*L**H factorization of a complex Hermitian positive definite tridiagonal matrix A. The factorization may also be regarded as having the form A = U**H *D*U </td></tr>
<tr id="row_6_355_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1pttrs.html" target="_self">pttrs</a></td><td class="desc">PTTRS: solves a tridiagonal system of the form A * X = B using the factorization A = U**H*D*U or A = L*D*L**H computed by CPTTRF. D is a diagonal matrix specified in the vector D, U (or L) is a unit bidiagonal matrix whose superdiagonal (subdiagonal) is specified in the vector E, and X and B are N by NRHS matrices </td></tr>
<tr id="row_6_356_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1rot.html" target="_self">rot</a></td><td class="desc">ROT: applies a plane rotation, where the cos (C) is real and the sin (S) is complex, and the vectors CX and CY are complex </td></tr>
<tr id="row_6_357_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1rscl.html" target="_self">rscl</a></td><td class="desc">RSCL: multiplies an n-element real vector x by the real scalar 1/a. This is done without overflow or underflow as long as the final result x/a does not overflow or underflow </td></tr>
<tr id="row_6_358_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sb2st__kernels.html" target="_self">sb2st_kernels</a></td><td class="desc">SB2ST_KERNELS: is an internal routine used by the DSYTRD_SB2ST subroutine </td></tr>
<tr id="row_6_359_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sbev.html" target="_self">sbev</a></td><td class="desc">SBEV: computes all the eigenvalues and, optionally, eigenvectors of a real symmetric band matrix A </td></tr>
<tr id="row_6_360_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sbevd.html" target="_self">sbevd</a></td><td class="desc">SBEVD: computes all the eigenvalues and, optionally, eigenvectors of a real symmetric band matrix A. If eigenvectors are desired, it uses a divide and conquer algorithm. The divide and conquer algorithm makes very mild assumptions about floating point arithmetic. It will work on machines with a guard digit in add/subtract, or on those binary machines without guard digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2. It could conceivably fail on hexadecimal or decimal machines without guard digits, but we know of none </td></tr>
<tr id="row_6_361_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sbgst.html" target="_self">sbgst</a></td><td class="desc">SBGST: reduces a real symmetric-definite banded generalized eigenproblem A*x = lambda*B*x to standard form C*y = lambda*y, such that C has the same bandwidth as A. B must have been previously factorized as S**T*S by DPBSTF, using a split Cholesky factorization. A is overwritten by C = X**T*A*X, where X = S**(-1)*Q and Q is an orthogonal matrix chosen to preserve the bandwidth of A </td></tr>
<tr id="row_6_362_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sbgv.html" target="_self">sbgv</a></td><td class="desc">SBGV: computes all the eigenvalues, and optionally, the eigenvectors of a real generalized symmetric-definite banded eigenproblem, of the form A*x=(lambda)*B*x. Here A and B are assumed to be symmetric and banded, and B is also positive definite </td></tr>
<tr id="row_6_363_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sbgvd.html" target="_self">sbgvd</a></td><td class="desc">SBGVD: computes all the eigenvalues, and optionally, the eigenvectors of a real generalized symmetric-definite banded eigenproblem, of the form A*x=(lambda)*B*x. Here A and B are assumed to be symmetric and banded, and B is also positive definite. If eigenvectors are desired, it uses a divide and conquer algorithm. The divide and conquer algorithm makes very mild assumptions about floating point arithmetic. It will work on machines with a guard digit in add/subtract, or on those binary machines without guard digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2. It could conceivably fail on hexadecimal or decimal machines without guard digits, but we know of none </td></tr>
<tr id="row_6_364_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sbtrd.html" target="_self">sbtrd</a></td><td class="desc">SBTRD: reduces a real symmetric band matrix A to symmetric tridiagonal form T by an orthogonal similarity transformation: Q**T * A * Q = T </td></tr>
<tr id="row_6_365_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sfrk.html" target="_self">sfrk</a></td><td class="desc">Level 3 BLAS like routine for C in RFP Format. SFRK: performs one of the symmetric rank&ndash;k operations C := alpha*A*A**T + beta*C, or C := alpha*A**T*A + beta*C, where alpha and beta are real scalars, C is an n&ndash;by&ndash;n symmetric matrix and A is an n&ndash;by&ndash;k matrix in the first case and a k&ndash;by&ndash;n matrix in the second case </td></tr>
<tr id="row_6_366_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1spcon.html" target="_self">spcon</a></td><td class="desc">SPCON: estimates the reciprocal of the condition number (in the 1-norm) of a complex symmetric packed matrix A using the factorization A = U*D*U**T or A = L*D*L**T computed by CSPTRF. An estimate is obtained for norm(inv(A)), and the reciprocal of the condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))) </td></tr>
<tr id="row_6_367_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1spev.html" target="_self">spev</a></td><td class="desc">SPEV: computes all the eigenvalues and, optionally, eigenvectors of a real symmetric matrix A in packed storage </td></tr>
<tr id="row_6_368_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1spevd.html" target="_self">spevd</a></td><td class="desc">SPEVD: computes all the eigenvalues and, optionally, eigenvectors of a real symmetric matrix A in packed storage. If eigenvectors are desired, it uses a divide and conquer algorithm. The divide and conquer algorithm makes very mild assumptions about floating point arithmetic. It will work on machines with a guard digit in add/subtract, or on those binary machines without guard digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2. It could conceivably fail on hexadecimal or decimal machines without guard digits, but we know of none </td></tr>
<tr id="row_6_369_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1spgst.html" target="_self">spgst</a></td><td class="desc">SPGST: reduces a real symmetric-definite generalized eigenproblem to standard form, using packed storage. If ITYPE = 1, the problem is A*x = lambda*B*x, and A is overwritten by inv(U**T)*A*inv(U) or inv(L)*A*inv(L**T) If ITYPE = 2 or 3, the problem is A*B*x = lambda*x or B*A*x = lambda*x, and A is overwritten by U*A*U**T or L**T*A*L. B must have been previously factorized as U**T*U or L*L**T by DPPTRF </td></tr>
<tr id="row_6_370_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1spgv.html" target="_self">spgv</a></td><td class="desc">SPGV: computes all the eigenvalues and, optionally, the eigenvectors of a real generalized symmetric-definite eigenproblem, of the form A*x=(lambda)*B*x, A*Bx=(lambda)*x, or B*A*x=(lambda)*x. Here A and B are assumed to be symmetric, stored in packed format, and B is also positive definite </td></tr>
<tr id="row_6_371_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1spgvd.html" target="_self">spgvd</a></td><td class="desc">SPGVD: computes all the eigenvalues, and optionally, the eigenvectors of a real generalized symmetric-definite eigenproblem, of the form A*x=(lambda)*B*x, A*Bx=(lambda)*x, or B*A*x=(lambda)*x. Here A and B are assumed to be symmetric, stored in packed format, and B is also positive definite. If eigenvectors are desired, it uses a divide and conquer algorithm. The divide and conquer algorithm makes very mild assumptions about floating point arithmetic. It will work on machines with a guard digit in add/subtract, or on those binary machines without guard digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2. It could conceivably fail on hexadecimal or decimal machines without guard digits, but we know of none </td></tr>
<tr id="row_6_372_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1spmv.html" target="_self">spmv</a></td><td class="desc">SPMV: performs the matrix-vector operation y := alpha*A*x + beta*y, where alpha and beta are scalars, x and y are n element vectors and A is an n by n symmetric matrix, supplied in packed form </td></tr>
<tr id="row_6_373_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1spr.html" target="_self">spr</a></td><td class="desc">SPR: performs the symmetric rank 1 operation A := alpha*x*x**H + A, where alpha is a complex scalar, x is an n element vector and A is an n by n symmetric matrix, supplied in packed form </td></tr>
<tr id="row_6_374_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sprfs.html" target="_self">sprfs</a></td><td class="desc">SPRFS: improves the computed solution to a system of linear equations when the coefficient matrix is symmetric indefinite and packed, and provides error bounds and backward error estimates for the solution </td></tr>
<tr id="row_6_375_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1spsv.html" target="_self">spsv</a></td><td class="desc">SPSV: computes the solution to a complex system of linear equations A * X = B, where A is an N-by-N symmetric matrix stored in packed format and X and B are N-by-NRHS matrices. The diagonal pivoting method is used to factor A as A = U * D * U**T, if UPLO = 'U', or A = L * D * L**T, if UPLO = 'L', where U (or L) is a product of permutation and unit upper (lower) triangular matrices, D is symmetric and block diagonal with 1-by-1 and 2-by-2 diagonal blocks. The factored form of A is then used to solve the system of equations A * X = B </td></tr>
<tr id="row_6_376_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sptrd.html" target="_self">sptrd</a></td><td class="desc">SPTRD: reduces a real symmetric matrix A stored in packed form to symmetric tridiagonal form T by an orthogonal similarity transformation: Q**T * A * Q = T </td></tr>
<tr id="row_6_377_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sptrf.html" target="_self">sptrf</a></td><td class="desc">SPTRF: computes the factorization of a complex symmetric matrix A stored in packed format using the Bunch-Kaufman diagonal pivoting method: A = U*D*U**T or A = L*D*L**T where U (or L) is a product of permutation and unit upper (lower) triangular matrices, and D is symmetric and block diagonal with 1-by-1 and 2-by-2 diagonal blocks </td></tr>
<tr id="row_6_378_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sptri.html" target="_self">sptri</a></td><td class="desc">SPTRI: computes the inverse of a complex symmetric indefinite matrix A in packed storage using the factorization A = U*D*U**T or A = L*D*L**T computed by CSPTRF </td></tr>
<tr id="row_6_379_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sptrs.html" target="_self">sptrs</a></td><td class="desc">SPTRS: solves a system of linear equations A*X = B with a complex symmetric matrix A stored in packed format using the factorization A = U*D*U**T or A = L*D*L**T computed by CSPTRF </td></tr>
<tr id="row_6_380_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1stebz.html" target="_self">stebz</a></td><td class="desc">STEBZ: computes the eigenvalues of a symmetric tridiagonal matrix T. The user may ask for all eigenvalues, all eigenvalues in the half-open interval (VL, VU], or the IL-th through IU-th eigenvalues. To avoid overflow, the matrix must be scaled so that its largest element is no greater than overflow**(1/2) * underflow**(1/4) in absolute value, and for greatest accuracy, it should not be much smaller than that. See W. Kahan "Accurate Eigenvalues of a Symmetric Tridiagonal
 Matrix", Report CS41, Computer Science Dept., Stanford University, July 21, 1966 </td></tr>
<tr id="row_6_381_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1stedc.html" target="_self">stedc</a></td><td class="desc">STEDC: computes all eigenvalues and, optionally, eigenvectors of a symmetric tridiagonal matrix using the divide and conquer method. The eigenvectors of a full or band complex Hermitian matrix can also be found if CHETRD or CHPTRD or CHBTRD has been used to reduce this matrix to tridiagonal form. This code makes very mild assumptions about floating point arithmetic. It will work on machines with a guard digit in add/subtract, or on those binary machines without guard digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2. It could conceivably fail on hexadecimal or decimal machines without guard digits, but we know of none. See SLAED3 for details </td></tr>
<tr id="row_6_382_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1stegr.html" target="_self">stegr</a></td><td class="desc">STEGR: computes selected eigenvalues and, optionally, eigenvectors of a real symmetric tridiagonal matrix T. Any such unreduced matrix has a well defined set of pairwise different real eigenvalues, the corresponding real eigenvectors are pairwise orthogonal. The spectrum may be computed either completely or partially by specifying either an interval (VL,VU] or a range of indices IL:IU for the desired eigenvalues. STEGR is a compatibility wrapper around the improved CSTEMR routine. See SSTEMR for further details. One important change is that the ABSTOL parameter no longer provides any benefit and hence is no longer used. Note : STEGR and CSTEMR work only on machines which follow IEEE-754 floating-point standard in their handling of infinities and NaNs. Normal execution may create these exceptiona values and hence may abort due to a floating point exception in environments which do not conform to the IEEE-754 standard </td></tr>
<tr id="row_6_383_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1stein.html" target="_self">stein</a></td><td class="desc">STEIN: computes the eigenvectors of a real symmetric tridiagonal matrix T corresponding to specified eigenvalues, using inverse iteration. The maximum number of iterations allowed for each eigenvector is specified by an internal parameter MAXITS (currently set to 5). Although the eigenvectors are real, they are stored in a complex array, which may be passed to CUNMTR or CUPMTR for back transformation to the eigenvectors of a complex Hermitian matrix which was reduced to tridiagonal form </td></tr>
<tr id="row_6_384_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1stemr.html" target="_self">stemr</a></td><td class="desc">STEMR: computes selected eigenvalues and, optionally, eigenvectors of a real symmetric tridiagonal matrix T. Any such unreduced matrix has a well defined set of pairwise different real eigenvalues, the corresponding real eigenvectors are pairwise orthogonal. The spectrum may be computed either completely or partially by specifying either an interval (VL,VU] or a range of indices IL:IU for the desired eigenvalues. Depending on the number of desired eigenvalues, these are computed either by bisection or the dqds algorithm. Numerically orthogonal eigenvectors are computed by the use of various suitable L D L^T factorizations near clusters of close eigenvalues (referred to as RRRs, Relatively Robust Representations). An informal sketch of the algorithm follows. For each unreduced block (submatrix) of T, (a) Compute T - sigma I = L D L^T, so that L and D define all the wanted eigenvalues to high relative accuracy. This means that small relative changes in the entries of D and L cause only small relative changes in the eigenvalues and eigenvectors. The standard (unfactored) representation of the tridiagonal matrix T does not have this property in general. (b) Compute the eigenvalues to suitable accuracy. If the eigenvectors are desired, the algorithm attains full accuracy of the computed eigenvalues only right before the corresponding vectors have to be computed, see steps c) and d). (c) For each cluster of close eigenvalues, select a new shift close to the cluster, find a new factorization, and refine the shifted eigenvalues to suitable accuracy. (d) For each eigenvalue with a large enough relative separation compute the corresponding eigenvector by forming a rank revealing twisted factorization. Go back to (c) for any clusters that remain. For more details, see: </td></tr>
<tr id="row_6_385_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1steqr.html" target="_self">steqr</a></td><td class="desc">STEQR: computes all eigenvalues and, optionally, eigenvectors of a symmetric tridiagonal matrix using the implicit QL or QR method. The eigenvectors of a full or band complex Hermitian matrix can also be found if CHETRD or CHPTRD or CHBTRD has been used to reduce this matrix to tridiagonal form </td></tr>
<tr id="row_6_386_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sterf.html" target="_self">sterf</a></td><td class="desc">STERF: computes all eigenvalues of a symmetric tridiagonal matrix using the Pal-Walker-Kahan variant of the QL or QR algorithm </td></tr>
<tr id="row_6_387_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1stev.html" target="_self">stev</a></td><td class="desc">STEV: computes all eigenvalues and, optionally, eigenvectors of a real symmetric tridiagonal matrix A </td></tr>
<tr id="row_6_388_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1stevd.html" target="_self">stevd</a></td><td class="desc">STEVD: computes all eigenvalues and, optionally, eigenvectors of a real symmetric tridiagonal matrix. If eigenvectors are desired, it uses a divide and conquer algorithm. The divide and conquer algorithm makes very mild assumptions about floating point arithmetic. It will work on machines with a guard digit in add/subtract, or on those binary machines without guard digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2. It could conceivably fail on hexadecimal or decimal machines without guard digits, but we know of none </td></tr>
<tr id="row_6_389_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1stevr.html" target="_self">stevr</a></td><td class="desc">STEVR: computes selected eigenvalues and, optionally, eigenvectors of a real symmetric tridiagonal matrix T. Eigenvalues and eigenvectors can be selected by specifying either a range of values or a range of indices for the desired eigenvalues. Whenever possible, STEVR calls DSTEMR to compute the eigenspectrum using Relatively Robust Representations. DSTEMR computes eigenvalues by the dqds algorithm, while orthogonal eigenvectors are computed from various "good" L D L^T representations (also known as Relatively Robust Representations). Gram-Schmidt orthogonalization is avoided as far as possible. More specifically, the various steps of the algorithm are as follows. For the i-th unreduced block of T, (a) Compute T - sigma_i = L_i D_i L_i^T, such that L_i D_i L_i^T is a relatively robust representation, (b) Compute the eigenvalues, lambda_j, of L_i D_i L_i^T to high relative accuracy by the dqds algorithm, (c) If there is a cluster of close eigenvalues, "choose" sigma_i close to the cluster, and go to step (a), (d) Given the approximate eigenvalue lambda_j of L_i D_i L_i^T, compute the corresponding eigenvector by forming a rank-revealing twisted factorization. The desired accuracy of the output can be specified by the input parameter ABSTOL. For more details, see "A new O(n^2) algorithm for the symmetric
 tridiagonal eigenvalue/eigenvector problem", by Inderjit Dhillon, Computer Science Division Technical Report No. UCB//CSD-97-971, UC Berkeley, May 1997. Note 1 : STEVR calls DSTEMR when the full spectrum is requested on machines which conform to the ieee-754 floating point standard. STEVR calls DSTEBZ and DSTEIN on non-ieee machines and when partial spectrum requests are made. Normal execution of DSTEMR may create NaNs and infinities and hence may abort due to a floating point exception in environments which do not handle NaNs and infinities in the ieee standard default manner </td></tr>
<tr id="row_6_390_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sycon.html" target="_self">sycon</a></td><td class="desc">SYCON: estimates the reciprocal of the condition number (in the 1-norm) of a complex symmetric matrix A using the factorization A = U*D*U**T or A = L*D*L**T computed by CSYTRF. An estimate is obtained for norm(inv(A)), and the reciprocal of the condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))) </td></tr>
<tr id="row_6_391_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sycon__rook.html" target="_self">sycon_rook</a></td><td class="desc">SYCON_ROOK: estimates the reciprocal of the condition number (in the 1-norm) of a complex symmetric matrix A using the factorization A = U*D*U**T or A = L*D*L**T computed by CSYTRF_ROOK. An estimate is obtained for norm(inv(A)), and the reciprocal of the condition number is computed as RCOND = 1 / (ANORM * norm(inv(A))) </td></tr>
<tr id="row_6_392_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1syconv.html" target="_self">syconv</a></td><td class="desc">SYCONV: convert A given by TRF into L and D and vice-versa. Get Non-diag elements of D (returned in workspace) and apply or reverse permutation done in TRF </td></tr>
<tr id="row_6_393_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1syconvf.html" target="_self">syconvf</a></td><td class="desc">If parameter WAY = 'C': SYCONVF: converts the factorization output format used in CSYTRF provided on entry in parameter A into the factorization output format used in CSYTRF_RK (or CSYTRF_BK) that is stored on exit in parameters A and E. It also converts in place details of the intechanges stored in IPIV from the format used in CSYTRF into the format used in CSYTRF_RK (or CSYTRF_BK). If parameter WAY = 'R': SYCONVF performs the conversion in reverse direction, i.e. converts the factorization output format used in CSYTRF_RK (or CSYTRF_BK) provided on entry in parameters A and E into the factorization output format used in CSYTRF that is stored on exit in parameter A. It also converts in place details of the intechanges stored in IPIV from the format used in CSYTRF_RK (or CSYTRF_BK) into the format used in CSYTRF. SYCONVF can also convert in Hermitian matrix case, i.e. between formats used in CHETRF and CHETRF_RK (or CHETRF_BK) </td></tr>
<tr id="row_6_394_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1syconvf__rook.html" target="_self">syconvf_rook</a></td><td class="desc">If parameter WAY = 'C': SYCONVF_ROOK: converts the factorization output format used in CSYTRF_ROOK provided on entry in parameter A into the factorization output format used in CSYTRF_RK (or CSYTRF_BK) that is stored on exit in parameters A and E. IPIV format for CSYTRF_ROOK and CSYTRF_RK (or CSYTRF_BK) is the same and is not converted. If parameter WAY = 'R': SYCONVF_ROOK performs the conversion in reverse direction, i.e. converts the factorization output format used in CSYTRF_RK (or CSYTRF_BK) provided on entry in parameters A and E into the factorization output format used in CSYTRF_ROOK that is stored on exit in parameter A. IPIV format for CSYTRF_ROOK and CSYTRF_RK (or CSYTRF_BK) is the same and is not converted. SYCONVF_ROOK can also convert in Hermitian matrix case, i.e. between formats used in CHETRF_ROOK and CHETRF_RK (or CHETRF_BK) </td></tr>
<tr id="row_6_395_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1syequb.html" target="_self">syequb</a></td><td class="desc">SYEQUB: computes row and column scalings intended to equilibrate a symmetric matrix A (with respect to the Euclidean norm) and reduce its condition number. The scale factors S are computed by the BIN algorithm (see references) so that the scaled matrix B with elements B(i,j) = S(i)*A(i,j)*S(j) has a condition number within a factor N of the smallest possible condition number over all possible diagonal scalings </td></tr>
<tr id="row_6_396_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1syev.html" target="_self">syev</a></td><td class="desc">SYEV: computes all eigenvalues and, optionally, eigenvectors of a real symmetric matrix A </td></tr>
<tr id="row_6_397_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1syevd.html" target="_self">syevd</a></td><td class="desc">SYEVD: computes all eigenvalues and, optionally, eigenvectors of a real symmetric matrix A. If eigenvectors are desired, it uses a divide and conquer algorithm. The divide and conquer algorithm makes very mild assumptions about floating point arithmetic. It will work on machines with a guard digit in add/subtract, or on those binary machines without guard digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2. It could conceivably fail on hexadecimal or decimal machines without guard digits, but we know of none. Because of large use of BLAS of level 3, SYEVD needs N**2 more workspace than DSYEVX </td></tr>
<tr id="row_6_398_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1syevr.html" target="_self">syevr</a></td><td class="desc">SYEVR: computes selected eigenvalues and, optionally, eigenvectors of a real symmetric matrix A. Eigenvalues and eigenvectors can be selected by specifying either a range of values or a range of indices for the desired eigenvalues. SYEVR first reduces the matrix A to tridiagonal form T with a call to DSYTRD. Then, whenever possible, SYEVR calls DSTEMR to compute the eigenspectrum using Relatively Robust Representations. DSTEMR computes eigenvalues by the dqds algorithm, while orthogonal eigenvectors are computed from various "good" L D L^T representations (also known as Relatively Robust Representations). Gram-Schmidt orthogonalization is avoided as far as possible. More specifically, the various steps of the algorithm are as follows. For each unreduced block (submatrix) of T, (a) Compute T - sigma I = L D L^T, so that L and D define all the wanted eigenvalues to high relative accuracy. This means that small relative changes in the entries of D and L cause only small relative changes in the eigenvalues and eigenvectors. The standard (unfactored) representation of the tridiagonal matrix T does not have this property in general. (b) Compute the eigenvalues to suitable accuracy. If the eigenvectors are desired, the algorithm attains full accuracy of the computed eigenvalues only right before the corresponding vectors have to be computed, see steps c) and d). (c) For each cluster of close eigenvalues, select a new shift close to the cluster, find a new factorization, and refine the shifted eigenvalues to suitable accuracy. (d) For each eigenvalue with a large enough relative separation compute the corresponding eigenvector by forming a rank revealing twisted factorization. Go back to (c) for any clusters that remain. The desired accuracy of the output can be specified by the input parameter ABSTOL. For more details, see DSTEMR's documentation and: </td></tr>
<tr id="row_6_399_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sygst.html" target="_self">sygst</a></td><td class="desc">SYGST: reduces a real symmetric-definite generalized eigenproblem to standard form. If ITYPE = 1, the problem is A*x = lambda*B*x, and A is overwritten by inv(U**T)*A*inv(U) or inv(L)*A*inv(L**T) If ITYPE = 2 or 3, the problem is A*B*x = lambda*x or B*A*x = lambda*x, and A is overwritten by U*A*U**T or L**T*A*L. B must have been previously factorized as U**T*U or L*L**T by DPOTRF </td></tr>
<tr id="row_6_400_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sygv.html" target="_self">sygv</a></td><td class="desc">SYGV: computes all the eigenvalues, and optionally, the eigenvectors of a real generalized symmetric-definite eigenproblem, of the form A*x=(lambda)*B*x, A*Bx=(lambda)*x, or B*A*x=(lambda)*x. Here A and B are assumed to be symmetric and B is also positive definite </td></tr>
<tr id="row_6_401_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sygvd.html" target="_self">sygvd</a></td><td class="desc">SYGVD: computes all the eigenvalues, and optionally, the eigenvectors of a real generalized symmetric-definite eigenproblem, of the form A*x=(lambda)*B*x, A*Bx=(lambda)*x, or B*A*x=(lambda)*x. Here A and B are assumed to be symmetric and B is also positive definite. If eigenvectors are desired, it uses a divide and conquer algorithm. The divide and conquer algorithm makes very mild assumptions about floating point arithmetic. It will work on machines with a guard digit in add/subtract, or on those binary machines without guard digits which subtract like the Cray X-MP, Cray Y-MP, Cray C-90, or Cray-2. It could conceivably fail on hexadecimal or decimal machines without guard digits, but we know of none </td></tr>
<tr id="row_6_402_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1symv.html" target="_self">symv</a></td><td class="desc">SYMV: performs the matrix-vector operation y := alpha*A*x + beta*y, where alpha and beta are scalars, x and y are n element vectors and A is an n by n symmetric matrix </td></tr>
<tr id="row_6_403_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1syr.html" target="_self">syr</a></td><td class="desc">SYR: performs the symmetric rank 1 operation A := alpha*x*x**H + A, where alpha is a complex scalar, x is an n element vector and A is an n by n symmetric matrix </td></tr>
<tr id="row_6_404_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1syrfs.html" target="_self">syrfs</a></td><td class="desc">SYRFS: improves the computed solution to a system of linear equations when the coefficient matrix is symmetric indefinite, and provides error bounds and backward error estimates for the solution </td></tr>
<tr id="row_6_405_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sysv.html" target="_self">sysv</a></td><td class="desc">SYSV: computes the solution to a complex system of linear equations A * X = B, where A is an N-by-N symmetric matrix and X and B are N-by-NRHS matrices. The diagonal pivoting method is used to factor A as A = U * D * U**T, if UPLO = 'U', or A = L * D * L**T, if UPLO = 'L', where U (or L) is a product of permutation and unit upper (lower) triangular matrices, and D is symmetric and block diagonal with 1-by-1 and 2-by-2 diagonal blocks. The factored form of A is then used to solve the system of equations A * X = B </td></tr>
<tr id="row_6_406_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sysv__aa.html" target="_self">sysv_aa</a></td><td class="desc">CSYSV computes the solution to a complex system of linear equations A * X = B, where A is an N-by-N symmetric matrix and X and B are N-by-NRHS matrices. Aasen's algorithm is used to factor A as A = U**T * T * U, if UPLO = 'U', or A = L * T * L**T, if UPLO = 'L', where U (or L) is a product of permutation and unit upper (lower) triangular matrices, and T is symmetric tridiagonal. The factored form of A is then used to solve the system of equations A * X = B </td></tr>
<tr id="row_6_407_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sysv__rk.html" target="_self">sysv_rk</a></td><td class="desc">SYSV_RK: computes the solution to a complex system of linear equations A * X = B, where A is an N-by-N symmetric matrix and X and B are N-by-NRHS matrices. The bounded Bunch-Kaufman (rook) diagonal pivoting method is used to factor A as A = P*U*D*(U**T)*(P**T), if UPLO = 'U', or A = P*L*D*(L**T)*(P**T), if UPLO = 'L', where U (or L) is unit upper (or lower) triangular matrix, U**T (or L**T) is the transpose of U (or L), P is a permutation matrix, P**T is the transpose of P, and D is symmetric and block diagonal with 1-by-1 and 2-by-2 diagonal blocks. CSYTRF_RK is called to compute the factorization of a complex symmetric matrix. The factored form of A is then used to solve the system of equations A * X = B by calling BLAS3 routine CSYTRS_3 </td></tr>
<tr id="row_6_408_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sysv__rook.html" target="_self">sysv_rook</a></td><td class="desc">SYSV_ROOK: computes the solution to a complex system of linear equations A * X = B, where A is an N-by-N symmetric matrix and X and B are N-by-NRHS matrices. The diagonal pivoting method is used to factor A as A = U * D * U**T, if UPLO = 'U', or A = L * D * L**T, if UPLO = 'L', where U (or L) is a product of permutation and unit upper (lower) triangular matrices, and D is symmetric and block diagonal with 1-by-1 and 2-by-2 diagonal blocks. CSYTRF_ROOK is called to compute the factorization of a complex symmetric matrix A using the bounded Bunch-Kaufman ("rook") diagonal pivoting method. The factored form of A is then used to solve the system of equations A * X = B by calling CSYTRS_ROOK </td></tr>
<tr id="row_6_409_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1syswapr.html" target="_self">syswapr</a></td><td class="desc">SYSWAPR: applies an elementary permutation on the rows and the columns of a symmetric matrix </td></tr>
<tr id="row_6_410_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sytf2__rk.html" target="_self">sytf2_rk</a></td><td class="desc">SYTF2_RK: computes the factorization of a complex symmetric matrix A using the bounded Bunch-Kaufman (rook) diagonal pivoting method: A = P*U*D*(U**T)*(P**T) or A = P*L*D*(L**T)*(P**T), where U (or L) is unit upper (or lower) triangular matrix, U**T (or L**T) is the transpose of U (or L), P is a permutation matrix, P**T is the transpose of P, and D is symmetric and block diagonal with 1-by-1 and 2-by-2 diagonal blocks. This is the unblocked version of the algorithm, calling Level 2 BLAS. For more information see Further Details section </td></tr>
<tr id="row_6_411_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sytf2__rook.html" target="_self">sytf2_rook</a></td><td class="desc">SYTF2_ROOK: computes the factorization of a complex symmetric matrix A using the bounded Bunch-Kaufman ("rook") diagonal pivoting method: A = U*D*U**T or A = L*D*L**T where U (or L) is a product of permutation and unit upper (lower) triangular matrices, U**T is the transpose of U, and D is symmetric and block diagonal with 1-by-1 and 2-by-2 diagonal blocks. This is the unblocked version of the algorithm, calling Level 2 BLAS </td></tr>
<tr id="row_6_412_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sytrd.html" target="_self">sytrd</a></td><td class="desc">SYTRD: reduces a real symmetric matrix A to real symmetric tridiagonal form T by an orthogonal similarity transformation: Q**T * A * Q = T </td></tr>
<tr id="row_6_413_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sytrd__sb2st.html" target="_self">sytrd_sb2st</a></td><td class="desc">SYTRD_SB2ST: reduces a real symmetric band matrix A to real symmetric tridiagonal form T by a orthogonal similarity transformation: Q**T * A * Q = T </td></tr>
<tr id="row_6_414_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sytrd__sy2sb.html" target="_self">sytrd_sy2sb</a></td><td class="desc">SYTRD_SY2SB: reduces a real symmetric matrix A to real symmetric band-diagonal form AB by a orthogonal similarity transformation: Q**T * A * Q = AB </td></tr>
<tr id="row_6_415_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sytrf.html" target="_self">sytrf</a></td><td class="desc">SYTRF: computes the factorization of a complex symmetric matrix A using the Bunch-Kaufman diagonal pivoting method. The form of the factorization is A = U*D*U**T or A = L*D*L**T where U (or L) is a product of permutation and unit upper (lower) triangular matrices, and D is symmetric and block diagonal with 1-by-1 and 2-by-2 diagonal blocks. This is the blocked version of the algorithm, calling Level 3 BLAS </td></tr>
<tr id="row_6_416_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sytrf__aa.html" target="_self">sytrf_aa</a></td><td class="desc">SYTRF_AA: computes the factorization of a complex symmetric matrix A using the Aasen's algorithm. The form of the factorization is A = U**T*T*U or A = L*T*L**T where U (or L) is a product of permutation and unit upper (lower) triangular matrices, and T is a complex symmetric tridiagonal matrix. This is the blocked version of the algorithm, calling Level 3 BLAS </td></tr>
<tr id="row_6_417_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sytrf__rk.html" target="_self">sytrf_rk</a></td><td class="desc">SYTRF_RK: computes the factorization of a complex symmetric matrix A using the bounded Bunch-Kaufman (rook) diagonal pivoting method: A = P*U*D*(U**T)*(P**T) or A = P*L*D*(L**T)*(P**T), where U (or L) is unit upper (or lower) triangular matrix, U**T (or L**T) is the transpose of U (or L), P is a permutation matrix, P**T is the transpose of P, and D is symmetric and block diagonal with 1-by-1 and 2-by-2 diagonal blocks. This is the blocked version of the algorithm, calling Level 3 BLAS. For more information see Further Details section </td></tr>
<tr id="row_6_418_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sytrf__rook.html" target="_self">sytrf_rook</a></td><td class="desc">SYTRF_ROOK: computes the factorization of a complex symmetric matrix A using the bounded Bunch-Kaufman ("rook") diagonal pivoting method. The form of the factorization is A = U*D*U**T or A = L*D*L**T where U (or L) is a product of permutation and unit upper (lower) triangular matrices, and D is symmetric and block diagonal with 1-by-1 and 2-by-2 diagonal blocks. This is the blocked version of the algorithm, calling Level 3 BLAS </td></tr>
<tr id="row_6_419_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sytri.html" target="_self">sytri</a></td><td class="desc">SYTRI: computes the inverse of a complex symmetric indefinite matrix A using the factorization A = U*D*U**T or A = L*D*L**T computed by CSYTRF </td></tr>
<tr id="row_6_420_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sytri__rook.html" target="_self">sytri_rook</a></td><td class="desc">SYTRI_ROOK: computes the inverse of a complex symmetric matrix A using the factorization A = U*D*U**T or A = L*D*L**T computed by CSYTRF_ROOK </td></tr>
<tr id="row_6_421_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sytrs.html" target="_self">sytrs</a></td><td class="desc">SYTRS: solves a system of linear equations A*X = B with a complex symmetric matrix A using the factorization A = U*D*U**T or A = L*D*L**T computed by CSYTRF </td></tr>
<tr id="row_6_422_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sytrs2.html" target="_self">sytrs2</a></td><td class="desc">SYTRS2: solves a system of linear equations A*X = B with a complex symmetric matrix A using the factorization A = U*D*U**T or A = L*D*L**T computed by CSYTRF and converted by CSYCONV </td></tr>
<tr id="row_6_423_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sytrs__3.html" target="_self">sytrs_3</a></td><td class="desc">SYTRS_3: solves a system of linear equations A * X = B with a complex symmetric matrix A using the factorization computed by CSYTRF_RK or CSYTRF_BK: A = P*U*D*(U**T)*(P**T) or A = P*L*D*(L**T)*(P**T), where U (or L) is unit upper (or lower) triangular matrix, U**T (or L**T) is the transpose of U (or L), P is a permutation matrix, P**T is the transpose of P, and D is symmetric and block diagonal with 1-by-1 and 2-by-2 diagonal blocks. This algorithm is using Level 3 BLAS </td></tr>
<tr id="row_6_424_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sytrs__aa.html" target="_self">sytrs_aa</a></td><td class="desc">SYTRS_AA: solves a system of linear equations A*X = B with a complex symmetric matrix A using the factorization A = U**T*T*U or A = L*T*L**T computed by CSYTRF_AA </td></tr>
<tr id="row_6_425_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1sytrs__rook.html" target="_self">sytrs_rook</a></td><td class="desc">SYTRS_ROOK: solves a system of linear equations A*X = B with a complex symmetric matrix A using the factorization A = U*D*U**T or A = L*D*L**T computed by CSYTRF_ROOK </td></tr>
<tr id="row_6_426_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tbcon.html" target="_self">tbcon</a></td><td class="desc">TBCON: estimates the reciprocal of the condition number of a triangular band matrix A, in either the 1-norm or the infinity-norm. The norm of A is computed and an estimate is obtained for norm(inv(A)), then the reciprocal of the condition number is computed as RCOND = 1 / ( norm(A) * norm(inv(A)) ) </td></tr>
<tr id="row_6_427_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tbrfs.html" target="_self">tbrfs</a></td><td class="desc">TBRFS: provides error bounds and backward error estimates for the solution to a system of linear equations with a triangular band coefficient matrix. The solution matrix X must be computed by CTBTRS or some other means before entering this routine. TBRFS does not do iterative refinement because doing so cannot improve the backward error </td></tr>
<tr id="row_6_428_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tbtrs.html" target="_self">tbtrs</a></td><td class="desc">TBTRS: solves a triangular system of the form A * X = B, A**T * X = B, or A**H * X = B, where A is a triangular band matrix of order N, and B is an N-by-NRHS matrix. A check is made to verify that A is nonsingular </td></tr>
<tr id="row_6_429_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tfsm.html" target="_self">tfsm</a></td><td class="desc">Level 3 BLAS like routine for A in RFP Format. TFSM: solves the matrix equation op( A )*X = alpha*B or X*op( A ) = alpha*B where alpha is a scalar, X and B are m by n matrices, A is a unit, or non-unit, upper or lower triangular matrix and op( A ) is one of op( A ) = A or op( A ) = A**H. A is in Rectangular Full Packed (RFP) Format. The matrix X is overwritten on B </td></tr>
<tr id="row_6_430_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tftri.html" target="_self">tftri</a></td><td class="desc">TFTRI: computes the inverse of a triangular matrix A stored in RFP format. This is a Level 3 BLAS version of the algorithm </td></tr>
<tr id="row_6_431_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tfttp.html" target="_self">tfttp</a></td><td class="desc">TFTTP: copies a triangular matrix A from rectangular full packed format (TF) to standard packed format (TP) </td></tr>
<tr id="row_6_432_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tfttr.html" target="_self">tfttr</a></td><td class="desc">TFTTR: copies a triangular matrix A from rectangular full packed format (TF) to standard full format (TR) </td></tr>
<tr id="row_6_433_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tgevc.html" target="_self">tgevc</a></td><td class="desc">TGEVC: computes some or all of the right and/or left eigenvectors of a pair of complex matrices (S,P), where S and P are upper triangular. Matrix pairs of this type are produced by the generalized Schur factorization of a complex matrix pair (A,B): A = Q*S*Z**H, B = Q*P*Z**H as computed by CGGHRD + CHGEQZ. The right eigenvector x and the left eigenvector y of (S,P) corresponding to an eigenvalue w are defined by: S*x = w*P*x, (y**H)*S = w*(y**H)*P, where y**H denotes the conjugate tranpose of y. The eigenvalues are not input to this routine, but are computed directly from the diagonal elements of S and P. This routine returns the matrices X and/or Y of right and left eigenvectors of (S,P), or the products Z*X and/or Q*Y, where Z and Q are input matrices. If Q and Z are the unitary factors from the generalized Schur factorization of a matrix pair (A,B), then Z*X and Q*Y are the matrices of right and left eigenvectors of (A,B) </td></tr>
<tr id="row_6_434_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tgexc.html" target="_self">tgexc</a></td><td class="desc">TGEXC: reorders the generalized Schur decomposition of a complex matrix pair (A,B), using an unitary equivalence transformation (A, B) := Q * (A, B) * Z**H, so that the diagonal block of (A, B) with row index IFST is moved to row ILST. (A, B) must be in generalized Schur canonical form, that is, A and B are both upper triangular. Optionally, the matrices Q and Z of generalized Schur vectors are updated. Q(in) * A(in) * Z(in)**H = Q(out) * A(out) * Z(out)**H Q(in) * B(in) * Z(in)**H = Q(out) * B(out) * Z(out)**H </td></tr>
<tr id="row_6_435_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tgsen.html" target="_self">tgsen</a></td><td class="desc">TGSEN: reorders the generalized Schur decomposition of a complex matrix pair (A, B) (in terms of an unitary equivalence trans- formation Q**H * (A, B) * Z), so that a selected cluster of eigenvalues appears in the leading diagonal blocks of the pair (A,B). The leading columns of Q and Z form unitary bases of the corresponding left and right eigenspaces (deflating subspaces). (A, B) must be in generalized Schur canonical form, that is, A and B are both upper triangular. TGSEN also computes the generalized eigenvalues w(j)= ALPHA(j) / BETA(j) of the reordered matrix pair (A, B). Optionally, the routine computes estimates of reciprocal condition numbers for eigenvalues and eigenspaces. These are Difu[(A11,B11), (A22,B22)] and Difl[(A11,B11), (A22,B22)], i.e. the separation(s) between the matrix pairs (A11, B11) and (A22,B22) that correspond to the selected cluster and the eigenvalues outside the cluster, resp., and norms of "projections" onto left and right eigenspaces w.r.t. the selected cluster in the (1,1)-block </td></tr>
<tr id="row_6_436_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tgsja.html" target="_self">tgsja</a></td><td class="desc">TGSJA: computes the generalized singular value decomposition (GSVD) of two complex upper triangular (or trapezoidal) matrices A and B. On entry, it is assumed that matrices A and B have the following forms, which may be obtained by the preprocessing subroutine CGGSVP from a general M-by-N matrix A and P-by-N matrix B: N-K-L K L A = K ( 0 A12 A13 ) if M-K-L &gt;= 0; L ( 0 0 A23 ) M-K-L ( 0 0 0 ) N-K-L K L A = K ( 0 A12 A13 ) if M-K-L &lt; 0; M-K ( 0 0 A23 ) N-K-L K L B = L ( 0 0 B13 ) P-L ( 0 0 0 ) where the K-by-K matrix A12 and L-by-L matrix B13 are nonsingular upper triangular; A23 is L-by-L upper triangular if M-K-L &gt;= 0, otherwise A23 is (M-K)-by-L upper trapezoidal. On exit, U**H <em>A*Q = D1</em>( 0 R ), V**H <em>B*Q = D2</em>( 0 R ), where U, V and Q are unitary matrices. R is a nonsingular upper triangular matrix, and D1 and D2 are `&lsquo;diagonal&rsquo;' matrices, which are of the following structures: If M-K-L &gt;= 0, K L D1 = K ( I 0 ) L ( 0 C ) M-K-L ( 0 0 ) K L D2 = L ( 0 S ) P-L ( 0 0 ) N-K-L K L ( 0 R ) = K ( 0 R11 R12 ) K L ( 0 0 R22 ) L where C = diag( ALPHA(K+1), ... , ALPHA(K+L) ), S = diag( BETA(K+1), ... , BETA(K+L) ), C**2 + S**2 = I. R is stored in A(1:K+L,N-K-L+1:N) on exit. If M-K-L &lt; 0, K M-K K+L-M D1 = K ( I 0 0 ) M-K ( 0 C 0 ) K M-K K+L-M D2 = M-K ( 0 S 0 ) K+L-M ( 0 0 I ) P-L ( 0 0 0 ) N-K-L K M-K K+L-M ( 0 R ) = K ( 0 R11 R12 R13 ) M-K ( 0 0 R22 R23 ) K+L-M ( 0 0 0 R33 ) where C = diag( ALPHA(K+1), ... , ALPHA(M) ), S = diag( BETA(K+1), ... , BETA(M) ), C**2 + S**2 = I. R = ( R11 R12 R13 ) is stored in A(1:M, N-K-L+1:N) and R33 is stored ( 0 R22 R23 ) in B(M-K+1:L,N+M-K-L+1:N) on exit. The computation of the unitary transformation matrices U, V or Q is optional. These matrices may either be formed explicitly, or they may be postmultiplied into input matrices U1, V1, or Q1 </td></tr>
<tr id="row_6_437_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tgsna.html" target="_self">tgsna</a></td><td class="desc">TGSNA: estimates reciprocal condition numbers for specified eigenvalues and/or eigenvectors of a matrix pair (A, B). (A, B) must be in generalized Schur canonical form, that is, A and B are both upper triangular </td></tr>
<tr id="row_6_438_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tgsyl.html" target="_self">tgsyl</a></td><td class="desc">TGSYL: solves the generalized Sylvester equation: A * R - L * B = scale * C (1) D * R - L * E = scale * F where R and L are unknown m-by-n matrices, (A, D), (B, E) and (C, F) are given matrix pairs of size m-by-m, n-by-n and m-by-n, respectively, with complex entries. A, B, D and E are upper triangular (i.e., (A,D) and (B,E) in generalized Schur form). The solution (R, L) overwrites (C, F). 0 &lt;= SCALE &lt;= 1 is an output scaling factor chosen to avoid overflow. In matrix notation (1) is equivalent to solve Zx = scale*b, where Z is defined as Z = [ kron(In, A) -kron(B**H, Im) ] (2) [ kron(In, D) -kron(E**H, Im) ], Here Ix is the identity matrix of size x and X**H is the conjugate transpose of X. Kron(X, Y) is the Kronecker product between the matrices X and Y. If TRANS = 'C', y in the conjugate transposed system Z**H *y = scale*b is solved for, which is equivalent to solve for R and L in A**H * R + D**H * L = scale * C (3) R * B**H + L * E**H = scale * -F This case (TRANS = 'C') is used to compute an one-norm-based estimate of Dif[(A,D), (B,E)], the separation between the matrix pairs (A,D) and (B,E), using CLACON. If IJOB &gt;= 1, TGSYL computes a Frobenius norm-based estimate of Dif[(A,D),(B,E)]. That is, the reciprocal of a lower bound on the reciprocal of the smallest singular value of Z. This is a level-3 BLAS algorithm </td></tr>
<tr id="row_6_439_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tpcon.html" target="_self">tpcon</a></td><td class="desc">TPCON: estimates the reciprocal of the condition number of a packed triangular matrix A, in either the 1-norm or the infinity-norm. The norm of A is computed and an estimate is obtained for norm(inv(A)), then the reciprocal of the condition number is computed as RCOND = 1 / ( norm(A) * norm(inv(A)) ) </td></tr>
<tr id="row_6_440_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tplqt.html" target="_self">tplqt</a></td><td class="desc">TPLQT: computes a blocked LQ factorization of a complex "triangular-pentagonal" matrix C, which is composed of a triangular block A and pentagonal block B, using the compact WY representation for Q </td></tr>
<tr id="row_6_441_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tplqt2.html" target="_self">tplqt2</a></td><td class="desc">TPLQT2: computes a LQ a factorization of a complex "triangular-pentagonal" matrix C, which is composed of a triangular block A and pentagonal block B, using the compact WY representation for Q </td></tr>
<tr id="row_6_442_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tpmlqt.html" target="_self">tpmlqt</a></td><td class="desc">TPMLQT: applies a complex unitary matrix Q obtained from a "triangular-pentagonal" complex block reflector H to a general complex matrix C, which consists of two blocks A and B </td></tr>
<tr id="row_6_443_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tpmqrt.html" target="_self">tpmqrt</a></td><td class="desc">TPMQRT: applies a complex orthogonal matrix Q obtained from a "triangular-pentagonal" complex block reflector H to a general complex matrix C, which consists of two blocks A and B </td></tr>
<tr id="row_6_444_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tpqrt.html" target="_self">tpqrt</a></td><td class="desc">TPQRT: computes a blocked QR factorization of a complex "triangular-pentagonal" matrix C, which is composed of a triangular block A and pentagonal block B, using the compact WY representation for Q </td></tr>
<tr id="row_6_445_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tpqrt2.html" target="_self">tpqrt2</a></td><td class="desc">TPQRT2: computes a QR factorization of a complex "triangular-pentagonal" matrix C, which is composed of a triangular block A and pentagonal block B, using the compact WY representation for Q </td></tr>
<tr id="row_6_446_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tprfb.html" target="_self">tprfb</a></td><td class="desc">TPRFB: applies a complex "triangular-pentagonal" block reflector H or its conjugate transpose H**H to a complex matrix C, which is composed of two blocks A and B, either from the left or right </td></tr>
<tr id="row_6_447_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tprfs.html" target="_self">tprfs</a></td><td class="desc">TPRFS: provides error bounds and backward error estimates for the solution to a system of linear equations with a triangular packed coefficient matrix. The solution matrix X must be computed by CTPTRS or some other means before entering this routine. TPRFS does not do iterative refinement because doing so cannot improve the backward error </td></tr>
<tr id="row_6_448_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tptri.html" target="_self">tptri</a></td><td class="desc">TPTRI: computes the inverse of a complex upper or lower triangular matrix A stored in packed format </td></tr>
<tr id="row_6_449_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tptrs.html" target="_self">tptrs</a></td><td class="desc">TPTRS: solves a triangular system of the form A * X = B, A**T * X = B, or A**H * X = B, where A is a triangular matrix of order N stored in packed format, and B is an N-by-NRHS matrix. A check is made to verify that A is nonsingular </td></tr>
<tr id="row_6_450_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tpttf.html" target="_self">tpttf</a></td><td class="desc">TPTTF: copies a triangular matrix A from standard packed format (TP) to rectangular full packed format (TF) </td></tr>
<tr id="row_6_451_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tpttr.html" target="_self">tpttr</a></td><td class="desc">TPTTR: copies a triangular matrix A from standard packed format (TP) to standard full format (TR) </td></tr>
<tr id="row_6_452_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1trcon.html" target="_self">trcon</a></td><td class="desc">TRCON: estimates the reciprocal of the condition number of a triangular matrix A, in either the 1-norm or the infinity-norm. The norm of A is computed and an estimate is obtained for norm(inv(A)), then the reciprocal of the condition number is computed as RCOND = 1 / ( norm(A) * norm(inv(A)) ) </td></tr>
<tr id="row_6_453_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1trevc.html" target="_self">trevc</a></td><td class="desc">TREVC: computes some or all of the right and/or left eigenvectors of a complex upper triangular matrix T. Matrices of this type are produced by the Schur factorization of a complex general matrix: A = Q*T*Q**H, as computed by CHSEQR. The right eigenvector x and the left eigenvector y of T corresponding to an eigenvalue w are defined by: T*x = w*x, (y**H)*T = w*(y**H) where y**H denotes the conjugate transpose of the vector y. The eigenvalues are not input to this routine, but are read directly from the diagonal of T. This routine returns the matrices X and/or Y of right and left eigenvectors of T, or the products Q*X and/or Q*Y, where Q is an input matrix. If Q is the unitary factor that reduces a matrix A to Schur form T, then Q*X and Q*Y are the matrices of right and left eigenvectors of A </td></tr>
<tr id="row_6_454_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1trevc3.html" target="_self">trevc3</a></td><td class="desc">TREVC3: computes some or all of the right and/or left eigenvectors of a complex upper triangular matrix T. Matrices of this type are produced by the Schur factorization of a complex general matrix: A = Q*T*Q**H, as computed by CHSEQR. The right eigenvector x and the left eigenvector y of T corresponding to an eigenvalue w are defined by: T*x = w*x, (y**H)*T = w*(y**H) where y**H denotes the conjugate transpose of the vector y. The eigenvalues are not input to this routine, but are read directly from the diagonal of T. This routine returns the matrices X and/or Y of right and left eigenvectors of T, or the products Q*X and/or Q*Y, where Q is an input matrix. If Q is the unitary factor that reduces a matrix A to Schur form T, then Q*X and Q*Y are the matrices of right and left eigenvectors of A. This uses a Level 3 BLAS version of the back transformation </td></tr>
<tr id="row_6_455_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1trexc.html" target="_self">trexc</a></td><td class="desc">TREXC: reorders the Schur factorization of a complex matrix A = Q*T*Q**H, so that the diagonal element of T with row index IFST is moved to row ILST. The Schur form T is reordered by a unitary similarity transformation Z**H*T*Z, and optionally the matrix Q of Schur vectors is updated by postmultplying it with Z </td></tr>
<tr id="row_6_456_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1trrfs.html" target="_self">trrfs</a></td><td class="desc">TRRFS: provides error bounds and backward error estimates for the solution to a system of linear equations with a triangular coefficient matrix. The solution matrix X must be computed by CTRTRS or some other means before entering this routine. TRRFS does not do iterative refinement because doing so cannot improve the backward error </td></tr>
<tr id="row_6_457_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1trsen.html" target="_self">trsen</a></td><td class="desc">TRSEN: reorders the Schur factorization of a complex matrix A = Q*T*Q**H, so that a selected cluster of eigenvalues appears in the leading positions on the diagonal of the upper triangular matrix T, and the leading columns of Q form an orthonormal basis of the corresponding right invariant subspace. Optionally the routine computes the reciprocal condition numbers of the cluster of eigenvalues and/or the invariant subspace </td></tr>
<tr id="row_6_458_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1trsna.html" target="_self">trsna</a></td><td class="desc">TRSNA: estimates reciprocal condition numbers for specified eigenvalues and/or right eigenvectors of a complex upper triangular matrix T (or of any matrix Q*T*Q**H with Q unitary) </td></tr>
<tr id="row_6_459_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1trsyl.html" target="_self">trsyl</a></td><td class="desc">TRSYL: solves the complex Sylvester matrix equation: op(A)*X + X*op(B) = scale*C or op(A)*X - X*op(B) = scale*C, where op(A) = A or A**H, and A and B are both upper triangular. A is M-by-M and B is N-by-N; the right hand side C and the solution X are M-by-N; and scale is an output scale factor, set &lt;= 1 to avoid overflow in X </td></tr>
<tr id="row_6_460_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1trtri.html" target="_self">trtri</a></td><td class="desc">TRTRI: computes the inverse of a complex upper or lower triangular matrix A. This is the Level 3 BLAS version of the algorithm </td></tr>
<tr id="row_6_461_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1trtrs.html" target="_self">trtrs</a></td><td class="desc">TRTRS: solves a triangular system of the form A * X = B, A**T * X = B, or A**H * X = B, where A is a triangular matrix of order N, and B is an N-by-NRHS matrix. A check is made to verify that A is nonsingular </td></tr>
<tr id="row_6_462_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1trttf.html" target="_self">trttf</a></td><td class="desc">TRTTF: copies a triangular matrix A from standard full format (TR) to rectangular full packed format (TF) </td></tr>
<tr id="row_6_463_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1trttp.html" target="_self">trttp</a></td><td class="desc">TRTTP: copies a triangular matrix A from full format (TR) to standard packed format (TP) </td></tr>
<tr id="row_6_464_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1tzrzf.html" target="_self">tzrzf</a></td><td class="desc">TZRZF: reduces the M-by-N ( M&lt;=N ) complex upper trapezoidal matrix A to upper triangular form by means of unitary transformations. The upper trapezoidal matrix A is factored as A = ( R 0 ) * Z, where Z is an N-by-N unitary matrix and R is an M-by-M upper triangular matrix </td></tr>
<tr id="row_6_465_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1unbdb.html" target="_self">unbdb</a></td><td class="desc">UNBDB: simultaneously bidiagonalizes the blocks of an M-by-M partitioned unitary matrix X: [ B11 | B12 0 0 ] [ X11 | X12 ] [ P1 | ] [ 0 | 0 -I 0 ] [ Q1 | ]**H X = [--------&mdash;] = [------&mdash;] [-------------&mdash;] [------&mdash;] . [ X21 | X22 ] [ | P2 ] [ B21 | B22 0 0 ] [ | Q2 ] [ 0 | 0 0 I ] X11 is P-by-Q. Q must be no larger than P, M-P, or M-Q. (If this is not the case, then X must be transposed and/or permuted. This can be done in constant time using the TRANS and SIGNS options. See CUNCSD for details.) The unitary matrices P1, P2, Q1, and Q2 are P-by-P, (M-P)-by- (M-P), Q-by-Q, and (M-Q)-by-(M-Q), respectively. They are represented implicitly by Householder vectors. B11, B12, B21, and B22 are Q-by-Q bidiagonal matrices represented implicitly by angles THETA, PHI </td></tr>
<tr id="row_6_466_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1unbdb1.html" target="_self">unbdb1</a></td><td class="desc">UNBDB1: simultaneously bidiagonalizes the blocks of a tall and skinny matrix X with orthonomal columns: [ B11 ] [ X11 ] [ P1 | ] [ 0 ] [--&mdash;] = [------&mdash;] [--&mdash;] Q1**T . [ X21 ] [ | P2 ] [ B21 ] [ 0 ] X11 is P-by-Q, and X21 is (M-P)-by-Q. Q must be no larger than P, M-P, or M-Q. Routines CUNBDB2, CUNBDB3, and CUNBDB4 handle cases in which Q is not the minimum dimension. The unitary matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P), and (M-Q)-by-(M-Q), respectively. They are represented implicitly by Householder vectors. B11 and B12 are Q-by-Q bidiagonal matrices represented implicitly by angles THETA, PHI </td></tr>
<tr id="row_6_467_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1unbdb2.html" target="_self">unbdb2</a></td><td class="desc">UNBDB2: simultaneously bidiagonalizes the blocks of a tall and skinny matrix X with orthonomal columns: [ B11 ] [ X11 ] [ P1 | ] [ 0 ] [--&mdash;] = [------&mdash;] [--&mdash;] Q1**T . [ X21 ] [ | P2 ] [ B21 ] [ 0 ] X11 is P-by-Q, and X21 is (M-P)-by-Q. P must be no larger than M-P, Q, or M-Q. Routines CUNBDB1, CUNBDB3, and CUNBDB4 handle cases in which P is not the minimum dimension. The unitary matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P), and (M-Q)-by-(M-Q), respectively. They are represented implicitly by Householder vectors. B11 and B12 are P-by-P bidiagonal matrices represented implicitly by angles THETA, PHI </td></tr>
<tr id="row_6_468_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1unbdb3.html" target="_self">unbdb3</a></td><td class="desc">UNBDB3: simultaneously bidiagonalizes the blocks of a tall and skinny matrix X with orthonomal columns: [ B11 ] [ X11 ] [ P1 | ] [ 0 ] [--&mdash;] = [------&mdash;] [--&mdash;] Q1**T . [ X21 ] [ | P2 ] [ B21 ] [ 0 ] X11 is P-by-Q, and X21 is (M-P)-by-Q. M-P must be no larger than P, Q, or M-Q. Routines CUNBDB1, CUNBDB2, and CUNBDB4 handle cases in which M-P is not the minimum dimension. The unitary matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P), and (M-Q)-by-(M-Q), respectively. They are represented implicitly by Householder vectors. B11 and B12 are (M-P)-by-(M-P) bidiagonal matrices represented implicitly by angles THETA, PHI </td></tr>
<tr id="row_6_469_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1unbdb4.html" target="_self">unbdb4</a></td><td class="desc">UNBDB4: simultaneously bidiagonalizes the blocks of a tall and skinny matrix X with orthonomal columns: [ B11 ] [ X11 ] [ P1 | ] [ 0 ] [--&mdash;] = [------&mdash;] [--&mdash;] Q1**T . [ X21 ] [ | P2 ] [ B21 ] [ 0 ] X11 is P-by-Q, and X21 is (M-P)-by-Q. M-Q must be no larger than P, M-P, or Q. Routines CUNBDB1, CUNBDB2, and CUNBDB3 handle cases in which M-Q is not the minimum dimension. The unitary matrices P1, P2, and Q1 are P-by-P, (M-P)-by-(M-P), and (M-Q)-by-(M-Q), respectively. They are represented implicitly by Householder vectors. B11 and B12 are (M-Q)-by-(M-Q) bidiagonal matrices represented implicitly by angles THETA, PHI </td></tr>
<tr id="row_6_470_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1unbdb5.html" target="_self">unbdb5</a></td><td class="desc">UNBDB5: orthogonalizes the column vector X = [ X1 ] [ X2 ] with respect to the columns of Q = [ Q1 ] . [ Q2 ] The columns of Q must be orthonormal. If the projection is zero according to Kahan's "twice is enough" criterion, then some other vector from the orthogonal complement is returned. This vector is chosen in an arbitrary but deterministic way </td></tr>
<tr id="row_6_471_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1unbdb6.html" target="_self">unbdb6</a></td><td class="desc">UNBDB6: orthogonalizes the column vector X = [ X1 ] [ X2 ] with respect to the columns of Q = [ Q1 ] . [ Q2 ] The columns of Q must be orthonormal. If the projection is zero according to Kahan's "twice is enough" criterion, then the zero vector is returned </td></tr>
<tr id="row_6_472_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1uncsd.html" target="_self">uncsd</a></td><td class="desc">UNCSD: computes the CS decomposition of an M-by-M partitioned unitary matrix X: [ I 0 0 | 0 0 0 ] [ 0 C 0 | 0 -S 0 ] [ X11 | X12 ] [ U1 | ] [ 0 0 0 | 0 0 -I ] [ V1 | ]**H X = [--------&mdash;] = [------&mdash;] [------------------&mdash;] [------&mdash;] . [ X21 | X22 ] [ | U2 ] [ 0 0 0 | I 0 0 ] [ | V2 ] [ 0 S 0 | 0 C 0 ] [ 0 0 I | 0 0 0 ] X11 is P-by-Q. The unitary matrices U1, U2, V1, and V2 are P-by-P, (M-P)-by-(M-P), Q-by-Q, and (M-Q)-by-(M-Q), respectively. C and S are R-by-R nonnegative diagonal matrices satisfying C^2 + S^2 = I, in which R = MIN(P,M-P,Q,M-Q) </td></tr>
<tr id="row_6_473_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1uncsd2by1.html" target="_self">uncsd2by1</a></td><td class="desc">UNCSD2BY1: computes the CS decomposition of an M-by-Q matrix X with orthonormal columns that has been partitioned into a 2-by-1 block structure: [ I1 0 0 ] [ 0 C 0 ] [ X11 ] [ U1 | ] [ 0 0 0 ] X = [--&mdash;] = [------&mdash;] [-------&mdash;] V1**T . [ X21 ] [ | U2 ] [ 0 0 0 ] [ 0 S 0 ] [ 0 0 I2] X11 is P-by-Q. The unitary matrices U1, U2, and V1 are P-by-P, (M-P)-by-(M-P), and Q-by-Q, respectively. C and S are R-by-R nonnegative diagonal matrices satisfying C^2 + S^2 = I, in which R = MIN(P,M-P,Q,M-Q). I1 is a K1-by-K1 identity matrix and I2 is a K2-by-K2 identity matrix, where K1 = MAX(Q+P-M,0), K2 = MAX(Q-P,0) </td></tr>
<tr id="row_6_474_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ung2l.html" target="_self">ung2l</a></td><td class="desc">UNG2L: generates an m by n complex matrix Q with orthonormal columns, which is defined as the last n columns of a product of k elementary reflectors of order m Q = H(k) . . . H(2) H(1) as returned by CGEQLF </td></tr>
<tr id="row_6_475_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ung2r.html" target="_self">ung2r</a></td><td class="desc">UNG2R: generates an m by n complex matrix Q with orthonormal columns, which is defined as the first n columns of a product of k elementary reflectors of order m Q = H(1) H(2) . . . H(k) as returned by CGEQRF </td></tr>
<tr id="row_6_476_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ungbr.html" target="_self">ungbr</a></td><td class="desc">UNGBR: generates one of the complex unitary matrices Q or P**H determined by CGEBRD when reducing a complex matrix A to bidiagonal form: A = Q * B * P**H. Q and P**H are defined as products of elementary reflectors H(i) or G(i) respectively. If VECT = 'Q', A is assumed to have been an M-by-K matrix, and Q is of order M: if m &gt;= k, Q = H(1) H(2) . . . H(k) and UNGBR returns the first n columns of Q, where m &gt;= n &gt;= k; if m &lt; k, Q = H(1) H(2) . . . H(m-1) and UNGBR returns Q as an M-by-M matrix. If VECT = 'P', A is assumed to have been a K-by-N matrix, and P**H is of order N: if k &lt; n, P**H = G(k) . . . G(2) G(1) and UNGBR returns the first m rows of P**H, where n &gt;= m &gt;= k; if k &gt;= n, P**H = G(n-1) . . . G(2) G(1) and UNGBR returns P**H as an N-by-N matrix </td></tr>
<tr id="row_6_477_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1unghr.html" target="_self">unghr</a></td><td class="desc">UNGHR: generates a complex unitary matrix Q which is defined as the product of IHI-ILO elementary reflectors of order N, as returned by CGEHRD: Q = H(ilo) H(ilo+1) . . . H(ihi-1) </td></tr>
<tr id="row_6_478_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1unglq.html" target="_self">unglq</a></td><td class="desc">UNGLQ: generates an M-by-N complex matrix Q with orthonormal rows, which is defined as the first M rows of a product of K elementary reflectors of order N Q = H(k)**H . . . H(2)**H H(1)**H as returned by CGELQF </td></tr>
<tr id="row_6_479_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ungql.html" target="_self">ungql</a></td><td class="desc">UNGQL: generates an M-by-N complex matrix Q with orthonormal columns, which is defined as the last N columns of a product of K elementary reflectors of order M Q = H(k) . . . H(2) H(1) as returned by CGEQLF </td></tr>
<tr id="row_6_480_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ungqr.html" target="_self">ungqr</a></td><td class="desc">UNGQR: generates an M-by-N complex matrix Q with orthonormal columns, which is defined as the first N columns of a product of K elementary reflectors of order M Q = H(1) H(2) . . . H(k) as returned by CGEQRF </td></tr>
<tr id="row_6_481_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ungrq.html" target="_self">ungrq</a></td><td class="desc">UNGRQ: generates an M-by-N complex matrix Q with orthonormal rows, which is defined as the last M rows of a product of K elementary reflectors of order N Q = H(1)**H H(2)**H . . . H(k)**H as returned by CGERQF </td></tr>
<tr id="row_6_482_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ungtr.html" target="_self">ungtr</a></td><td class="desc">UNGTR: generates a complex unitary matrix Q which is defined as the product of n-1 elementary reflectors of order N, as returned by CHETRD: if UPLO = 'U', Q = H(n-1) . . . H(2) H(1), if UPLO = 'L', Q = H(1) H(2) . . . H(n-1) </td></tr>
<tr id="row_6_483_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ungtsqr.html" target="_self">ungtsqr</a></td><td class="desc">UNGTSQR: generates an M-by-N complex matrix Q_out with orthonormal columns, which are the first N columns of a product of comlpex unitary matrices of order M which are returned by CLATSQR Q_out = first_N_columns_of( Q(1)_in * Q(2)_in * ... * Q(k)_in ). See the documentation for CLATSQR </td></tr>
<tr id="row_6_484_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1ungtsqr__row.html" target="_self">ungtsqr_row</a></td><td class="desc">UNGTSQR_ROW: generates an M-by-N complex matrix Q_out with orthonormal columns from the output of CLATSQR. These N orthonormal columns are the first N columns of a product of complex unitary matrices Q(k)_in of order M, which are returned by CLATSQR in a special format. Q_out = first_N_columns_of( Q(1)_in * Q(2)_in * ... * Q(k)_in ). The input matrices Q(k)_in are stored in row and column blocks in A. See the documentation of CLATSQR for more details on the format of Q(k)_in, where each Q(k)_in is represented by block Householder transformations. This routine calls an auxiliary routine CLARFB_GETT, where the computation is performed on each individual block. The algorithm first sweeps NB-sized column blocks from the right to left starting in the bottom row block and continues to the top row block (hence _ROW in the routine name). This sweep is in reverse order of the order in which CLATSQR generates the output blocks </td></tr>
<tr id="row_6_485_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1unhr__col.html" target="_self">unhr_col</a></td><td class="desc">UNHR_COL: takes an M-by-N complex matrix Q_in with orthonormal columns as input, stored in A, and performs Householder Reconstruction (HR), i.e. reconstructs Householder vectors V(i) implicitly representing another M-by-N matrix Q_out, with the property that Q_in = Q_out*S, where S is an N-by-N diagonal matrix with diagonal entries equal to +1 or -1. The Householder vectors (columns V(i) of V) are stored in A on output, and the diagonal entries of S are stored in D. Block reflectors are also returned in T (same output format as CGEQRT) </td></tr>
<tr id="row_6_486_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1unm2l.html" target="_self">unm2l</a></td><td class="desc">UNM2L: overwrites the general complex m-by-n matrix C with Q * C if SIDE = 'L' and TRANS = 'N', or Q**H* C if SIDE = 'L' and TRANS = 'C', or C * Q if SIDE = 'R' and TRANS = 'N', or C * Q**H if SIDE = 'R' and TRANS = 'C', where Q is a complex unitary matrix defined as the product of k elementary reflectors Q = H(k) . . . H(2) H(1) as returned by CGEQLF. Q is of order m if SIDE = 'L' and of order n if SIDE = 'R' </td></tr>
<tr id="row_6_487_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1unm2r.html" target="_self">unm2r</a></td><td class="desc">UNM2R: overwrites the general complex m-by-n matrix C with Q * C if SIDE = 'L' and TRANS = 'N', or Q**H* C if SIDE = 'L' and TRANS = 'C', or C * Q if SIDE = 'R' and TRANS = 'N', or C * Q**H if SIDE = 'R' and TRANS = 'C', where Q is a complex unitary matrix defined as the product of k elementary reflectors Q = H(1) H(2) . . . H(k) as returned by CGEQRF. Q is of order m if SIDE = 'L' and of order n if SIDE = 'R' </td></tr>
<tr id="row_6_488_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1unmbr.html" target="_self">unmbr</a></td><td class="desc">If VECT = 'Q', UNMBR: overwrites the general complex M-by-N matrix C with SIDE = 'L' SIDE = 'R' TRANS = 'N': Q * C C * Q TRANS = 'C': Q**H * C C * Q**H If VECT = 'P', UNMBR overwrites the general complex M-by-N matrix C with SIDE = 'L' SIDE = 'R' TRANS = 'N': P * C C * P TRANS = 'C': P**H * C C * P**H Here Q and P**H are the unitary matrices determined by CGEBRD when reducing a complex matrix A to bidiagonal form: A = Q * B * P**H. Q and P**H are defined as products of elementary reflectors H(i) and G(i) respectively. Let nq = m if SIDE = 'L' and nq = n if SIDE = 'R'. Thus nq is the order of the unitary matrix Q or P**H that is applied. If VECT = 'Q', A is assumed to have been an NQ-by-K matrix: if nq &gt;= k, Q = H(1) H(2) . . . H(k); if nq &lt; k, Q = H(1) H(2) . . . H(nq-1). If VECT = 'P', A is assumed to have been a K-by-NQ matrix: if k &lt; nq, P = G(1) G(2) . . . G(k); if k &gt;= nq, P = G(1) G(2) . . . G(nq-1) </td></tr>
<tr id="row_6_489_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1unmhr.html" target="_self">unmhr</a></td><td class="desc">UNMHR: overwrites the general complex M-by-N matrix C with SIDE = 'L' SIDE = 'R' TRANS = 'N': Q * C C * Q TRANS = 'C': Q**H * C C * Q**H where Q is a complex unitary matrix of order nq, with nq = m if SIDE = 'L' and nq = n if SIDE = 'R'. Q is defined as the product of IHI-ILO elementary reflectors, as returned by CGEHRD: Q = H(ilo) H(ilo+1) . . . H(ihi-1) </td></tr>
<tr id="row_6_490_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1unmlq.html" target="_self">unmlq</a></td><td class="desc">UNMLQ: overwrites the general complex M-by-N matrix C with SIDE = 'L' SIDE = 'R' TRANS = 'N': Q * C C * Q TRANS = 'C': Q**H * C C * Q**H where Q is a complex unitary matrix defined as the product of k elementary reflectors Q = H(k)**H . . . H(2)**H H(1)**H as returned by CGELQF. Q is of order M if SIDE = 'L' and of order N if SIDE = 'R' </td></tr>
<tr id="row_6_491_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1unmql.html" target="_self">unmql</a></td><td class="desc">UNMQL: overwrites the general complex M-by-N matrix C with SIDE = 'L' SIDE = 'R' TRANS = 'N': Q * C C * Q TRANS = 'C': Q**H * C C * Q**H where Q is a complex unitary matrix defined as the product of k elementary reflectors Q = H(k) . . . H(2) H(1) as returned by CGEQLF. Q is of order M if SIDE = 'L' and of order N if SIDE = 'R' </td></tr>
<tr id="row_6_492_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1unmqr.html" target="_self">unmqr</a></td><td class="desc">UNMQR: overwrites the general complex M-by-N matrix C with SIDE = 'L' SIDE = 'R' TRANS = 'N': Q * C C * Q TRANS = 'C': Q**H * C C * Q**H where Q is a complex unitary matrix defined as the product of k elementary reflectors Q = H(1) H(2) . . . H(k) as returned by CGEQRF. Q is of order M if SIDE = 'L' and of order N if SIDE = 'R' </td></tr>
<tr id="row_6_493_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1unmrq.html" target="_self">unmrq</a></td><td class="desc">UNMRQ: overwrites the general complex M-by-N matrix C with SIDE = 'L' SIDE = 'R' TRANS = 'N': Q * C C * Q TRANS = 'C': Q**H * C C * Q**H where Q is a complex unitary matrix defined as the product of k elementary reflectors Q = H(1)**H H(2)**H . . . H(k)**H as returned by CGERQF. Q is of order M if SIDE = 'L' and of order N if SIDE = 'R' </td></tr>
<tr id="row_6_494_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1unmrz.html" target="_self">unmrz</a></td><td class="desc">UNMRZ: overwrites the general complex M-by-N matrix C with SIDE = 'L' SIDE = 'R' TRANS = 'N': Q * C C * Q TRANS = 'C': Q**H * C C * Q**H where Q is a complex unitary matrix defined as the product of k elementary reflectors Q = H(1) H(2) . . . H(k) as returned by CTZRZF. Q is of order M if SIDE = 'L' and of order N if SIDE = 'R' </td></tr>
<tr id="row_6_495_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1unmtr.html" target="_self">unmtr</a></td><td class="desc">UNMTR: overwrites the general complex M-by-N matrix C with SIDE = 'L' SIDE = 'R' TRANS = 'N': Q * C C * Q TRANS = 'C': Q**H * C C * Q**H where Q is a complex unitary matrix of order nq, with nq = m if SIDE = 'L' and nq = n if SIDE = 'R'. Q is defined as the product of nq-1 elementary reflectors, as returned by CHETRD: if UPLO = 'U', Q = H(nq-1) . . . H(2) H(1); if UPLO = 'L', Q = H(1) H(2) . . . H(nq-1) </td></tr>
<tr id="row_6_496_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1upgtr.html" target="_self">upgtr</a></td><td class="desc">UPGTR: generates a complex unitary matrix Q which is defined as the product of n-1 elementary reflectors H(i) of order n, as returned by CHPTRD using packed storage: if UPLO = 'U', Q = H(n-1) . . . H(2) H(1), if UPLO = 'L', Q = H(1) H(2) . . . H(n-1) </td></tr>
<tr id="row_6_497_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__lapack_1_1upmtr.html" target="_self">upmtr</a></td><td class="desc">UPMTR: overwrites the general complex M-by-N matrix C with SIDE = 'L' SIDE = 'R' TRANS = 'N': Q * C C * Q TRANS = 'C': Q**H * C C * Q**H where Q is a complex unitary matrix of order nq, with nq = m if SIDE = 'L' and nq = n if SIDE = 'R'. Q is defined as the product of nq-1 elementary reflectors, as returned by CHPTRD using packed storage: if UPLO = 'U', Q = H(nq-1) . . . H(2) H(1); if UPLO = 'L', Q = H(1) H(2) . . . H(nq-1) </td></tr>
<tr id="row_7_" class="odd"><td class="entry"><span style="width:16px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">M</span></span><a class="el" href="namespacela__lapack__c.html" target="_self">la_lapack_c</a></td><td class="desc"></td></tr>
<tr id="row_8_" class="even"><td class="entry"><span style="width:16px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">M</span></span><a class="el" href="namespacela__lapack__d.html" target="_self">la_lapack_d</a></td><td class="desc"></td></tr>
<tr id="row_9_" class="odd"><td class="entry"><span style="width:16px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">M</span></span><a class="el" href="namespacela__lapack__q.html" target="_self">la_lapack_q</a></td><td class="desc"></td></tr>
<tr id="row_10_" class="even"><td class="entry"><span style="width:16px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">M</span></span><a class="el" href="namespacela__lapack__s.html" target="_self">la_lapack_s</a></td><td class="desc"></td></tr>
<tr id="row_11_" class="odd"><td class="entry"><span style="width:16px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">M</span></span><a class="el" href="namespacela__lapack__w.html" target="_self">la_lapack_w</a></td><td class="desc"></td></tr>
<tr id="row_12_" class="even"><td class="entry"><span style="width:16px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">M</span></span><a class="el" href="namespacela__lapack__z.html" target="_self">la_lapack_z</a></td><td class="desc"></td></tr>
<tr id="row_13_" class="odd"><td class="entry"><span style="width:0px;display:inline-block;">&#160;</span><span id="arr_13_" class="arrow" onclick="toggleFolder('13_')">&#9658;</span><span class="icona"><span class="icon">M</span></span><a class="el" href="namespacela__least__squares.html" target="_self">la_least_squares</a></td><td class="desc"></td></tr>
<tr id="row_13_0_" class="even" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__least__squares_1_1lstsq.html" target="_self">lstsq</a></td><td class="desc">Compute a least squares solution to system Ax=b, i.e. such that the 2-norm abs(b-Ax) is minimized </td></tr>
<tr id="row_14_" class="even"><td class="entry"><span style="width:0px;display:inline-block;">&#160;</span><span id="arr_14_" class="arrow" onclick="toggleFolder('14_')">&#9658;</span><span class="icona"><span class="icon">M</span></span><a class="el" href="namespacela__norms.html" target="_self">la_norms</a></td><td class="desc"></td></tr>
<tr id="row_14_0_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__norms_1_1get__norm.html" target="_self">get_norm</a></td><td class="desc">Vector norm: subroutine interface </td></tr>
<tr id="row_14_1_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__norms_1_1mnorm.html" target="_self">mnorm</a></td><td class="desc">Matrix norm: function interface </td></tr>
<tr id="row_14_2_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__norms_1_1norm.html" target="_self">norm</a></td><td class="desc">Vector norm: function interface </td></tr>
<tr id="row_15_" class="odd"><td class="entry"><span style="width:0px;display:inline-block;">&#160;</span><span id="arr_15_" class="arrow" onclick="toggleFolder('15_')">&#9658;</span><span class="icona"><span class="icon">M</span></span><a class="el" href="namespacela__pseudoinverse.html" target="_self">la_pseudoinverse</a></td><td class="desc"></td></tr>
<tr id="row_15_0_" class="even" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__pseudoinverse_1_1operator_07_8pinv_8_08.html" target="_self">operator(.pinv.)</a></td><td class="desc"></td></tr>
<tr id="row_15_1_" class="even" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__pseudoinverse_1_1pinv.html" target="_self">pinv</a></td><td class="desc">Pseudo-inverse: Function interface </td></tr>
<tr id="row_15_2_" class="even" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__pseudoinverse_1_1pseudoinvert.html" target="_self">pseudoinvert</a></td><td class="desc"></td></tr>
<tr id="row_16_" class="even"><td class="entry"><span style="width:0px;display:inline-block;">&#160;</span><span id="arr_16_" class="arrow" onclick="toggleFolder('16_')">&#9658;</span><span class="icona"><span class="icon">M</span></span><a class="el" href="namespacela__qr.html" target="_self">la_qr</a></td><td class="desc"></td></tr>
<tr id="row_16_0_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__qr_1_1qr.html" target="_self">qr</a></td><td class="desc">QR factorization of a matrix </td></tr>
<tr id="row_16_1_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__qr_1_1qr__space.html" target="_self">qr_space</a></td><td class="desc"></td></tr>
<tr id="row_17_" class="odd"><td class="entry"><span style="width:0px;display:inline-block;">&#160;</span><span id="arr_17_" class="arrow" onclick="toggleFolder('17_')">&#9658;</span><span class="icona"><span class="icon">M</span></span><a class="el" href="namespacela__schur.html" target="_self">la_schur</a></td><td class="desc"></td></tr>
<tr id="row_17_0_" class="even" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__schur_1_1schur.html" target="_self">schur</a></td><td class="desc"></td></tr>
<tr id="row_17_1_" class="even" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__schur_1_1schur__space.html" target="_self">schur_space</a></td><td class="desc"></td></tr>
<tr id="row_18_" class="even"><td class="entry"><span style="width:0px;display:inline-block;">&#160;</span><span id="arr_18_" class="arrow" onclick="toggleFolder('18_')">&#9658;</span><span class="icona"><span class="icon">M</span></span><a class="el" href="namespacela__solve.html" target="_self">la_solve</a></td><td class="desc"></td></tr>
<tr id="row_18_0_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__solve_1_1solve.html" target="_self">solve</a></td><td class="desc">Solve a linear system </td></tr>
<tr id="row_19_" class="odd"><td class="entry"><span style="width:0px;display:inline-block;">&#160;</span><span id="arr_19_" class="arrow" onclick="toggleFolder('19_')">&#9658;</span><span class="icona"><span class="icon">M</span></span><a class="el" href="namespacela__state__type.html" target="_self">la_state_type</a></td><td class="desc"></td></tr>
<tr id="row_19_0_" class="even" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structla__state__type_1_1la__state.html" target="_self">la_state</a></td><td class="desc"><code><a class="el" href="structla__state__type_1_1la__state.html" title="la_state defines a state return type for a linear algebra routine. State contains a status flag,...">la_state</a></code> defines a state return type for a linear algebra routine. State contains a status flag, a comment, and a procedure specifier that can be used to mark where the error happened </td></tr>
<tr id="row_19_1_" class="even" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__state__type_1_1operator_07_2_0a_08.html" target="_self">operator(/=)</a></td><td class="desc"></td></tr>
<tr id="row_19_2_" class="even" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__state__type_1_1operator_07_3_08.html" target="_self">operator(&lt;)</a></td><td class="desc"></td></tr>
<tr id="row_19_3_" class="even" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__state__type_1_1operator_07_3_0a_08.html" target="_self">operator(&lt;=)</a></td><td class="desc"></td></tr>
<tr id="row_19_4_" class="even" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__state__type_1_1operator_07_0a_0a_08.html" target="_self">operator(==)</a></td><td class="desc">Comparison operators </td></tr>
<tr id="row_19_5_" class="even" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__state__type_1_1operator_07_4_08.html" target="_self">operator(&gt;)</a></td><td class="desc"></td></tr>
<tr id="row_19_6_" class="even" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__state__type_1_1operator_07_4_0a_08.html" target="_self">operator(&gt;=)</a></td><td class="desc"></td></tr>
<tr id="row_20_" class="even"><td class="entry"><span style="width:0px;display:inline-block;">&#160;</span><span id="arr_20_" class="arrow" onclick="toggleFolder('20_')">&#9658;</span><span class="icona"><span class="icon">M</span></span><a class="el" href="namespacela__svd.html" target="_self">la_svd</a></td><td class="desc"></td></tr>
<tr id="row_20_0_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__svd_1_1svd.html" target="_self">svd</a></td><td class="desc">Singular value decomposition </td></tr>
<tr id="row_20_1_" class="odd" style="display:none;"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="interfacela__svd_1_1svdvals.html" target="_self">svdvals</a></td><td class="desc"></td></tr>
<tr id="row_21_" class="odd"><td class="entry"><span style="width:16px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">M</span></span><a class="el" href="namespacelinear__algebra.html" target="_self">linear_algebra</a></td><td class="desc"></td></tr>
</table>
</div><!-- directory -->
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Sat Jan 25 2025 16:42:15 for fortran-lapack by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8 </li>
  </ul>
</div>
</body>
</html>
